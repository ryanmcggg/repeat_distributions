{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0ba63-2e40-45e0-ba0f-4f96e006c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "import kaleido    # https://github.com/plotly/Kaleido\n",
    "import plotly     # https://plotly.com/python/getting-started/\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"none\"\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de93312-4b6e-443e-8815-d67daeadb587",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a559c6b-93c8-4b3e-89ef-296ae1fab722",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHM13_counts = pd.read_pickle('repeat_distributions/CHM13_counts.pickle')\n",
    "random_counts = pd.read_pickle('repeat_distributions/random_counts.pickle')\n",
    "subonly_counts = pd.read_pickle('repeat_distributions/subonly_counts.pickle')\n",
    "\n",
    "denovo_exp_rate = pd.read_pickle('denovo/denovo_exp_rate.pickle')\n",
    "denovo_con_rate = pd.read_pickle('denovo/denovo_con_rate.pickle')\n",
    "denovo_nonexp_rate = pd.read_pickle('denovo/denovo_nonexp_rate.pickle')\n",
    "denovo_substitution_context_rate = pd.read_pickle('denovo/denovo_mut_freq_triplets.pickle')\n",
    "decode_exp_rate = pd.read_pickle('decode/decode_expansion_rates.pickle')\n",
    "decode_con_rate = pd.read_pickle('decode/decode_contraction_rates.pickle')\n",
    "\n",
    "repeats_1_4 = ['A', 'C', 'AC', 'AT', 'AG', 'CG', 'AAT', 'AAG', 'AAC', 'ATC', 'ACT', 'AGG', 'AGC', 'ACG', 'ACC', 'CCG', 'AAAT', 'AAAG', 'AAAC', 'AATG', 'AATC', 'AAGT', 'AAGG', 'AAGC', 'AACT', 'AACG', 'AACC', 'AGAT', 'ACAT', 'ATCC', 'ACAG', 'ACTC', 'ACTG', 'ACCT', 'AGGG', 'AGGC', 'AGCC', 'ACGG', 'ACGC', 'ACCG', 'ACCC', 'AGCG', 'CCCG', 'AATT', 'ATGC', 'ATCG', 'AGCT', 'ACGT', 'CCGG']\n",
    "\n",
    "bootstrap_counts = pd.read_pickle('repeat_distributions/bootstrap_counts_1000.pickle').sort_index()\n",
    "bootstrap_counts_max = dict(); bootstrap_counts_min = dict(); bootstrap_counts_mean = dict()\n",
    "for motif in repeats_1_4:\n",
    "    bootstrap_counts_mean[motif] = bootstrap_counts.xs(motif, level=1, drop_level=True, axis=1).apply(lambda x: x.sort_values().head(975).tail(950).mean(), axis=1).sort_index().replace(0, np.nan).dropna()\n",
    "    bootstrap_counts_max[motif] = bootstrap_counts.xs(motif, level=1, drop_level=True, axis=1).apply(lambda x: x.sort_values().head(975).tail(950).max(), axis=1).reindex(bootstrap_counts_mean[motif].index)\n",
    "    bootstrap_counts_min[motif] = bootstrap_counts.xs(motif, level=1, drop_level=True, axis=1).apply(lambda x: x.sort_values().head(975).tail(950).min(), axis=1).reindex(bootstrap_counts_mean[motif].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfad0e4-21a0-49d2-9b43-70a48a7a5c97",
   "metadata": {},
   "source": [
    "## Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e37284-2b2b-4964-b3b4-0d6bc637e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(dna):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return ''.join([complement[base] for base in dna[::-1]])\n",
    "def make_colorscale(list_of_traces, opacity = 0.15):\n",
    "    current_colors = pd.Series(['rgb('+str(current/len(list_of_traces)*255) + ', 180, '+str((len(list_of_traces)-current)/len(list_of_traces)*255)+')' for current in range(len(list_of_traces))], index = list_of_traces)\n",
    "    return pd.Series(current_colors, index = list_of_traces), pd.Series(['rgba' + color[3:-1] + ', '+str(opacity)+')' for color in current_colors], index = list_of_traces)\n",
    "def loop_list(input_list, count):\n",
    "    return input_list * (count // len(input_list)) + input_list[:(count % len(input_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d509a57-6210-4a9d-b342-50713df0675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pseudocount to max_L bins, normalize, restrict to maxL bins\n",
    "def curve_metric_to_startend(dist_1, dist_2 = None, dist2_grid = False, to_start = 'start', min_L = 0, max_L = 200, pseudocount = 1, normalize = False, keepsign = False, check = False):\n",
    "    dist_1 = dist_1.dropna(how = 'all', axis=1).reindex(range(max_L)).fillna(0) + pseudocount\n",
    "    if normalize == True:\n",
    "        dist_1 = dist_1 / dist_1.sum()\n",
    "    if to_start == 'start':\n",
    "        dist_2 = dist_1[0]\n",
    "    if to_start == 'end':\n",
    "        dist_2 = dist_1[dist_1.columns.max()]\n",
    "    if dist2_grid == True:\n",
    "        dist_2 = dist_2.dropna(how = 'all', axis=1).reindex(range(max_L)).fillna(0) + pseudocount\n",
    "        if normalize == True:\n",
    "            dist_2 = dist_2 / dist_2.sum(axis=0)\n",
    "    if to_start == False:\n",
    "        if dist_2.index[0] == 1:\n",
    "            dist_2.index = dist_2.index - 1\n",
    "        dist_2 = dist_2.reindex(list(range(max_L))).fillna(0) + pseudocount\n",
    "        if normalize == True:\n",
    "            dist_2 = dist_2 / dist_2.sum()\n",
    "    dist_1 = dist_1.reindex(list(range(min_L, max_L)))\n",
    "    dist_2 = dist_2.reindex(list(range(min_L, max_L)))\n",
    "    if check == True:\n",
    "        print(dist_1)\n",
    "        print(dist_2)\n",
    "    if keepsign == False:\n",
    "        if dist2_grid == True:\n",
    "            return ((np.log(dist_1).sub(np.log(dist_2)))**2).sum(axis=0)\n",
    "        else:\n",
    "            return ((np.log(dist_1).sub(np.log(dist_2), axis=0))**2).sum()\n",
    "    if keepsign == True:\n",
    "        return (np.sign(dist_1.sub(dist_2, axis=0)) * ((np.log(dist_1).sub(np.log(dist_2), axis=0))**2)).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3bd52-5cc4-4325-8446-1ad343b201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolve function\n",
    "def mut_evolve_dist_AB(A_count_input, B_count_input, starting_conditions, boot = None, input_nuc = 'A', mut = True, mutonly = False, speedup_multiplier = 1, output_components = False, stochastics = None, reflective = True):\n",
    "    exp_rate_A_AA, con_rate_A_AA, nonexp_rate_A_AB, B_indel_rates = starting_conditions\n",
    "    A_count_output = A_count_input.copy(); B_count_output = B_count_input.copy()\n",
    "    A_bins = len(A_count_input)\n",
    "    B_bins = len(B_count_input)\n",
    "    A_length_array = np.array(range(1,A_bins+3))\n",
    "    A_length_array_bases = np.array(range(1,A_bins+3)) * len(input_nuc) ### including motif length\n",
    "    B_length_array = np.array(range(1,B_bins+3))\n",
    "    B_length_array_bases = np.array(range(1,B_bins+3)) * len(input_nuc) ### including motif length\n",
    "    A_count_input = np.insert(A_count_input, A_bins, [0,0])\n",
    "    B_count_input = np.insert(B_count_input, B_bins, [0,0])\n",
    "    #A_count_input = A_count_input.astype('int64')\n",
    "    #B_count_input = B_count_input.astype('int64')\n",
    "\n",
    "    if boot is None:\n",
    "        denovo_sub = denovo_substitution_context_rate.loc[input_nuc]\n",
    "    else:\n",
    "        denovo_sub = denovo_substitution_context_rate_poisson.loc[boot].loc[input_nuc]\n",
    "\n",
    "    # distribution info\n",
    "    total_B_bases = (B_count_input[:B_bins] * B_length_array_bases[:B_bins]).sum()\n",
    "    B_L1_base_portion = ((B_count_input[0] * len(input_nuc)) / (B_count_input[:B_bins]* B_length_array_bases[:B_bins]).sum()) ### including motif length\n",
    "    B_nonflank_base_portion = (B_count_input[2:B_bins+2] * B_length_array_bases[:B_bins]).sum() / total_B_bases  ### include portion of triplets 1nt away???\n",
    "    B_flank_base_portion = (B_count_input[1:B_bins] * 2 * len(input_nuc)).sum() / total_B_bases ### including motif length\n",
    "    \n",
    "    total_A_bases = (A_count_input[:A_bins] * A_length_array_bases[:A_bins]).sum()\n",
    "    A_nonflank_base_portion = (A_count_input[2:A_bins+2] * A_length_array_bases[:A_bins]).sum() / total_A_bases\n",
    "    A_flank_base_portion = (A_count_input[1:A_bins] * 2 * len(input_nuc)).sum() / total_A_bases ### including motif length\n",
    "    \n",
    "    total_A_change_in = np.array([0.0]*A_bins); total_B_change_in = np.array([0.0]*B_bins)\n",
    "    total_A_change_out = np.array([0.0]*A_bins); total_B_change_out = np.array([0.0]*B_bins)\n",
    "\n",
    "    if mut == True:\n",
    "        # A>B which adds to the A count locally. add these to A\n",
    "        A_mut_in_local_A_B = 2 * len(input_nuc) * denovo_sub['Acontraction'] * A_count_input[1:]\n",
    "        A_mut_out_local_A_B = -2 * len(input_nuc) * denovo_sub['Acontraction'] * A_count_input\n",
    "        A_mut_out_local_A_B[0] = -1 * len(input_nuc) * A_count_input[0] * denovo_sub['A10']\n",
    "        #A_mut_in_local_A_B = A_mut_out_local_A_B[1:]\n",
    "\n",
    "        # total number of A>B fission events\n",
    "        A_mut_out_fission = np.insert((-denovo_sub['Afission'] * A_count_input[2:] * A_length_array_bases[:A_bins]), 0, [0, 0]) # used to subtract from A_count, starting from L=3 (with 0 for L=1,2)\n",
    "        # each fission creates 2 As. add these to A\n",
    "        A_mut_in_fission =  np.array([np.sum(((2/A_length_array[:A_bins]) * -A_mut_out_fission[2:A_bins+2])[L-1:]) for L in A_length_array[:A_bins]]) ### use length_array_bases???\n",
    " \n",
    "        # B>A which adds to the A count locally (which must come from B_L>1)\n",
    "        # A from B>A leaving the -1 bin\n",
    "        A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "        A_mut_out_local_B_A = -denovo_sub['Aexpansion'] * B_flank_base_portion * total_B_bases * A_len_freq\n",
    "        # B>A creating A_L=1 from B_L>2\n",
    "        B_A_into_L1 = total_B_bases * B_nonflank_base_portion * denovo_sub['A01']\n",
    "        A_mut_in_local_B_A = np.insert(-A_mut_out_local_B_A, 0, B_A_into_L1)\n",
    "        \n",
    "        # fusion process for A\n",
    "        A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "        A_fusion_freq_in = np.bincount((np.add.outer(A_length_array[:A_bins], A_length_array[:A_bins])+1).ravel(), weights = np.outer(A_len_freq, A_len_freq).ravel())[1:]\n",
    "        A_mut_in_fusion_A_B = A_fusion_freq_in * denovo_sub['Afusion'] * B_L1_base_portion * total_B_bases\n",
    "        A_mut_out_fusion_A_B = (-2) *A_len_freq * denovo_sub['Afusion'] * B_L1_base_portion * total_B_bases\n",
    "        \n",
    "        \n",
    "        # total B>A\n",
    "        # B>A which adds to the B count locally. add these to B\n",
    "        B_mut_in_local_B_A = 2 * len(input_nuc) * denovo_sub['Aexpansion'] * B_count_input[1:]\n",
    "        B_mut_out_local_B_A = -2 * len(input_nuc) * denovo_sub['Aexpansion'] * B_count_input\n",
    "        B_mut_out_local_B_A[0] = -1 * B_L1_base_portion * total_B_bases * denovo_sub['Afusion']\n",
    "\n",
    "        # total number of B>A fission events\n",
    "        B_mut_out_fission = np.insert((-denovo_sub['A01'] * B_count_input[2:] * B_length_array_bases[:B_bins]), 0, [0, 0]) # used to subtract from B_count, starting from L=3 (with 0 for L=1,2)\n",
    "        # each fission creates 2 Bs. add these to B\n",
    "        B_mut_in_fission =  np.array([np.sum(((2/B_length_array[:B_bins]) * -B_mut_out_fission[2:B_bins+2])[L-1:]) for L in B_length_array[:B_bins]]) ### use length_array_bases???\n",
    "\n",
    "        # A>B which adds to the B count locally (which must come from A_L>1)\n",
    "        # B from A>B leaving the -1 bin\n",
    "        B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "        B_mut_out_local_A_B = -denovo_sub['Acontraction'] * A_flank_base_portion * total_A_bases * B_len_freq\n",
    "        # A>B creating B_L=1 from A_L>2\n",
    "        A_B_into_L1 = total_A_bases * A_nonflank_base_portion * denovo_sub['Afission']\n",
    "#        A_B_into_L1 = -A_mut_out_fission.sum()\n",
    "        B_mut_in_local_A_B = np.insert(-B_mut_out_local_A_B, 0, A_B_into_L1)\n",
    "        \n",
    "        # fusion process for B\n",
    "        B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "        B_fusion_freq_in = np.bincount((np.add.outer(B_length_array[:B_bins], B_length_array[:B_bins])+1).ravel(), weights = np.outer(B_len_freq, B_len_freq).ravel())[1:]\n",
    "        B_mut_in_fusion_B_A = B_fusion_freq_in * denovo_sub['A10'] * A_count_input[0] * len(input_nuc)\n",
    "        B_mut_out_fusion_B_A = (-2) * B_len_freq * denovo_sub['A10'] * A_count_input[0] * len(input_nuc)\n",
    "\n",
    "        # update counts for next round (with absorbing boundary)\n",
    "        total_A_change_in += A_mut_in_local_A_B[:A_bins] + A_mut_in_local_B_A[:A_bins] + A_mut_in_fission[:A_bins] + A_mut_in_fusion_A_B[:A_bins]\n",
    "        total_B_change_in += B_mut_in_local_B_A[:B_bins] + B_mut_in_local_A_B[:B_bins] + B_mut_in_fission[:B_bins] + B_mut_in_fusion_B_A[:B_bins]\n",
    "        total_A_change_out += A_mut_out_local_A_B[:A_bins] + A_mut_out_local_B_A[:A_bins] + A_mut_out_fission[:A_bins] + A_mut_out_fusion_A_B[:A_bins]\n",
    "        total_B_change_out += B_mut_out_local_B_A[:B_bins] + B_mut_out_local_A_B[:B_bins] + B_mut_out_fission[:B_bins] + B_mut_out_fusion_B_A[:B_bins]\n",
    "\n",
    "        # apply reflecting boundary\n",
    "        if reflective == True:\n",
    "            total_A_change_in[A_bins-1] += A_mut_in_local_A_B[A_bins:].sum() + A_mut_in_local_B_A[A_bins:].sum() + A_mut_in_fission[A_bins:].sum() + A_mut_in_fusion_A_B[A_bins:].sum()\n",
    "            total_B_change_in[B_bins-1] += B_mut_in_local_B_A[B_bins:].sum() + B_mut_in_local_A_B[B_bins:].sum() + B_mut_in_fission[B_bins:].sum() + B_mut_in_fusion_B_A[B_bins:].sum()\n",
    "            total_A_change_out[A_bins-1] += A_mut_out_local_A_B[A_bins:].sum() + A_mut_out_local_B_A[A_bins:].sum() + A_mut_out_fission[A_bins:].sum() + A_mut_out_fusion_A_B[A_bins:].sum()\n",
    "            total_B_change_out[B_bins-1] += B_mut_out_local_B_A[B_bins:].sum() + B_mut_out_local_A_B[B_bins:].sum() + B_mut_out_fission[B_bins:].sum() + B_mut_out_fusion_B_A[B_bins:].sum()\n",
    "           \n",
    "            \n",
    "    if mutonly == False:\n",
    "        # A expansions in and out\n",
    "        A_exp_out = A_count_input[:A_bins] * -exp_rate_A_AA[:A_bins]\n",
    "        A_exp_in = np.insert(-A_exp_out, 0, B_indel_rates[0]*total_B_bases)\n",
    "\n",
    "        # A contractions in and out\n",
    "        A_con_out = A_count_input[:A_bins+1] * -con_rate_A_AA[:A_bins+2]\n",
    "        A_con_in = -A_con_out[1:]\n",
    "\n",
    "        # A fusions from B1>B0 deletions\n",
    "        if (mut != True):\n",
    "            A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "            A_fusion_freq_in = np.bincount((np.add.outer(A_length_array[:A_bins], A_length_array[:A_bins])+1).ravel(), weights = np.outer(A_len_freq, A_len_freq).ravel())[1:]\n",
    "        A_mut_in_fusion_Bdel = A_fusion_freq_in[1:A_bins+1] * B_indel_rates[1] * B_L1_base_portion * total_B_bases\n",
    "        A_mut_out_fusion_Bdel = (-2) *A_len_freq * B_indel_rates[1] * B_L1_base_portion * total_B_bases\n",
    "\n",
    "        # A fission events from insertions\n",
    "        A_nonexp_fissions_out = -A_count_input * nonexp_rate_A_AB # used to calculate fission_in, starting with L=2 going to 2x L=1\n",
    "        # each fission creates 2 As. add these to A\n",
    "        A_nonexp_in_fission =  np.array([np.sum(((2/A_length_array[:A_bins]) * -A_nonexp_fissions_out[1:A_bins+1])[L-1:]) for L in A_length_array[:A_bins]])\n",
    "\n",
    "\n",
    "        # B expansions in and out\n",
    "        B_exp_out = B_count_input[:B_bins] * -B_indel_rates[2] * B_length_array[:B_bins] # B>BB rates are flat, per base\n",
    "        B_exp_in = np.insert(-B_exp_out, 0, A_nonexp_fissions_out.sum())\n",
    "\n",
    "        # B contractions in and out\n",
    "        B_con_out = B_count_input[:B_bins+1] * -B_indel_rates[1] * B_length_array[:B_bins+1] # B>_ rates are flat, per base\n",
    "        B_con_in = -B_con_out[1:]\n",
    "\n",
    "        # B fusions from A1>A0 deletions\n",
    "        if (mut != True):\n",
    "            B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "            B_fusion_freq_in = np.bincount((np.add.outer(B_length_array[:B_bins], B_length_array[:B_bins])+1).ravel(), weights = np.outer(B_len_freq, B_len_freq).ravel())[1:]\n",
    "        B_mut_in_fusion_Adel = B_fusion_freq_in[1:B_bins+1] * A_count_input[0] * con_rate_A_AA[0]\n",
    "        B_mut_out_fusion_Adel = 2 *B_len_freq * A_count_input[0] * -con_rate_A_AA[0]\n",
    "                    \n",
    "        # B fission events from insertions\n",
    "        B_nonexp_fissions_out = -B_count_input * B_indel_rates[0] * B_length_array # used to calculate fission_in, starting with L=2 going to 2x L=1\n",
    "        # each fission creates 2 Bs. add these to B\n",
    "        B_nonexp_in_fission =  np.array([np.sum(((2/B_length_array[:B_bins]) * -B_nonexp_fissions_out[1:B_bins+1])[L-1:]) for L in B_length_array[:B_bins]])\n",
    "            \n",
    "       # update counts for next round (with absorbing boundary)\n",
    "        total_A_change_in += A_exp_in[:A_bins] + A_con_in[:A_bins] + A_mut_in_fusion_Bdel[:A_bins] + A_nonexp_in_fission[:A_bins]\n",
    "        total_B_change_in += B_exp_in[:B_bins] + B_con_in[:B_bins] + B_mut_in_fusion_Adel[:B_bins] + B_nonexp_in_fission[:B_bins]\n",
    "        total_A_change_out += A_exp_out[:A_bins] + A_con_out[:A_bins] + A_mut_out_fusion_Bdel[:A_bins] + A_nonexp_fissions_out[:A_bins]\n",
    "        total_B_change_out += B_exp_out[:B_bins] + B_con_out[:B_bins] + B_mut_out_fusion_Adel[:B_bins] + B_nonexp_fissions_out[:B_bins]\n",
    "\n",
    "        # apply reflecting boundary\n",
    "        if reflective == True:\n",
    "            total_A_change_in[A_bins-1] += A_exp_in[A_bins:].sum() + A_con_in[A_bins:].sum() + A_mut_in_fusion_Bdel[A_bins:].sum() + A_nonexp_in_fission[A_bins:].sum()\n",
    "            total_B_change_in[B_bins-1] += B_exp_in[B_bins:].sum() + B_con_in[B_bins:].sum() + B_mut_in_fusion_Adel[B_bins:].sum() + B_nonexp_in_fission[B_bins:].sum()\n",
    "            total_A_change_out[A_bins-1] += A_exp_out[A_bins:].sum() + A_con_out[A_bins:].sum() + A_mut_out_fusion_Bdel[A_bins:].sum() + A_nonexp_fissions_out[A_bins:].sum()\n",
    "            total_B_change_out[B_bins-1] += B_exp_out[B_bins:].sum() + B_con_out[B_bins:].sum() + B_mut_out_fusion_Adel[B_bins:].sum() + B_nonexp_fissions_out[B_bins:].sum()\n",
    "\n",
    "    \n",
    "    # flag to stop the simulation if more repeats are removed from a bin than exist in that bin (excluding the last 10 noisy bins)\n",
    "    flag = ((np.abs(total_A_change_out[:A_bins-10]) * speedup_multiplier > A_count_output[:A_bins-10]).sum()) > 0\n",
    "\n",
    "    # apply speedup\n",
    "    total_A_change_in *= speedup_multiplier; total_A_change_out *= speedup_multiplier\n",
    "    total_B_change_in *= speedup_multiplier; total_B_change_out *= speedup_multiplier\n",
    "    \n",
    "    if stochastics is not None:\n",
    "        # the sum of poisson random variables is poisson-distributed. not necessary to run n poisson samples\n",
    "        total_A_change_in = np.random.poisson(total_A_change_in)\n",
    "        total_A_change_out = -1 * np.random.poisson(np.abs(total_A_change_out))\n",
    "        total_B_change_in = np.random.poisson(total_B_change_in)\n",
    "        total_B_change_out = -1 * np.random.poisson(np.abs(total_B_change_out))   \n",
    "    \n",
    "    total_A_change = total_A_change_in + total_A_change_out\n",
    "    total_B_change = total_B_change_in + total_B_change_out\n",
    "    \n",
    "    # update counts for next round\n",
    "    A_count_output = A_count_output[:A_bins] + total_A_change[:A_bins]\n",
    "    B_count_output = B_count_output[:B_bins] + total_B_change[:B_bins]\n",
    "\n",
    "    # remove negative values\n",
    "    A_count_output[A_count_output <0] = 0            \n",
    "    B_count_output[B_count_output <0] = 0\n",
    "    \n",
    "    if output_components == True:\n",
    "        if mutonly == False:\n",
    "            return  A_mut_in_local_A_B[:A_bins], A_mut_out_local_A_B[:A_bins], A_mut_in_local_B_A[:A_bins], A_mut_out_local_B_A[:A_bins], A_mut_in_fission[:A_bins], A_mut_out_fission[:A_bins], A_mut_in_fusion_A_B[:A_bins], A_mut_out_fusion_A_B[:A_bins], A_exp_in[:A_bins], A_exp_out[:A_bins], A_con_in[:A_bins], A_con_out[:A_bins], A_mut_in_fusion_Bdel[:A_bins], A_mut_out_fusion_Bdel[:A_bins], A_nonexp_in_fission[:A_bins], A_nonexp_fissions_out[:A_bins]\n",
    "        else:\n",
    "            return  A_mut_in_local_A_B[:A_bins], A_mut_out_local_A_B[:A_bins], A_mut_in_local_B_A[:A_bins], A_mut_out_local_B_A[:A_bins], A_mut_in_fission[:A_bins], A_mut_out_fission[:A_bins], A_mut_in_fusion_A_B[:A_bins], A_mut_out_fusion_A_B[:A_bins]\n",
    "    else:\n",
    "        return A_count_output, B_count_output, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e6fc5-6a9a-4777-8735-fd6eb6a26d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_power_law(power, start_rate, start_len, end_len=200):\n",
    "    denom = (start_len**power) / start_rate\n",
    "    return pd.Series([i**power for i in range(start_len+1, end_len+1)], index = list(range(start_len+1,end_len+1))) / denom\n",
    "\n",
    "def multiply_then_powerlaw(exp_power, con_power, mult, A_bins = 200, boot = None, L_mult = 9, L_mult_nonexp = 9, motif = 'A', fill = False, nonexp_factor = False):\n",
    "    if boot is None:\n",
    "        bootname = ''\n",
    "        denovo_exp_rate_current = denovo_exp_rate[motif]\n",
    "        denovo_con_rate_current = denovo_con_rate[motif]\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate[motif]\n",
    "    else:\n",
    "        bootname = '_boot'+str(boot)\n",
    "        denovo_exp_rate_current = denovo_exp_rate_poisson[motif][boot]\n",
    "        denovo_con_rate_current = denovo_con_rate_poisson[motif][boot]\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate_poisson[motif][boot]\n",
    "    if fill == True:\n",
    "        fillname = '_fill'\n",
    "        denovo_exp_rate_current = denovo_exp_rate_current.replace(0, np.nan).interpolate(method = 'from_derivatives')\n",
    "        denovo_con_rate_current = denovo_con_rate_current.replace(0, np.nan).interpolate(method = 'from_derivatives')\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate_current.replace(0, np.nan).interpolate(method = 'from_derivatives')\n",
    "    else:\n",
    "        fillname = ''\n",
    "    exp = pd.concat([denovo_exp_rate_current.reindex(range(L_mult)), pd.Series(denovo_exp_rate_current[L_mult-1] * mult, index = [L_mult]), extend_power_law(exp_power, denovo_exp_rate_current[L_mult-1]*mult, L_mult, A_bins+3)])\n",
    "    con = pd.concat([denovo_con_rate_current.reindex(range(L_mult)), pd.Series(denovo_con_rate_current[L_mult-1] * mult, index = [L_mult]), extend_power_law(con_power, denovo_con_rate_current[L_mult-1]*mult, L_mult, A_bins+3)])\n",
    "    if nonexp_factor == False:\n",
    "        nonexpname = ''\n",
    "        nonexp = pd.concat([denovo_nonexp_rate_current.reindex(range(L_mult_nonexp)), pd.Series(denovo_nonexp_rate_current[L_mult_nonexp-1] * mult, index = [L_mult_nonexp]), extend_power_law(exp_power, denovo_nonexp_rate_current[L_mult_nonexp-1]*mult, L_mult_nonexp, A_bins+3)])\n",
    "    else:\n",
    "        nonexpname = '_nonexp_x' + str(nonexp_factor)\n",
    "        nonexp = exp * nonexp_factor\n",
    "    nonexp.loc[1] = 0\n",
    "    name = 'mult_L'+str(L_mult)+'_x'+str(mult)+'_extend_pl_' + str(exp_power) + '_' + str(con_power) + nonexpname + fillname + bootname\n",
    "    return name, exp, con, nonexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce1e4c-5c0d-4929-bfb8-7e7bf3604988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup function\n",
    "def setup_evolve(exp_power=1, con_power=1, mult=1, boot = None, stochastics = None, L_mult = 9, L_mult_nonexp = 9, fill = False, nonexp_factor = False, A_bins = 200, B_bins = 200, input_nuc = 'A', mutonly = False, exp_zero = False, con_zero = False, nonexp_zero = False, different_input = False, random_start = False, ceiling = None):\n",
    "# set up counts\n",
    "    A_length_array = np.array(range(1,A_bins+1))\n",
    "    B_length_array = np.array(range(1,A_bins+1))\n",
    "    if different_input == False:\n",
    "        if random_start == False:\n",
    "            A_count_input = np.nan_to_num(CHM13_counts['A'][input_nuc].reindex(range(1,A_bins+1)).values)\n",
    "            B_count_input = np.nan_to_num(CHM13_counts['B'][input_nuc].reindex(range(1,B_bins+1)).values)\n",
    "        if random_start == True:\n",
    "            A_count_input = np.nan_to_num(random_counts['A'][input_nuc].reindex(range(1,A_bins+1)).values)\n",
    "            B_count_input = np.nan_to_num(random_counts['B'][input_nuc].reindex(range(1,B_bins+1)).values)\n",
    "    else:\n",
    "        A_count_input = np.nan_to_num(different_input[0].reindex(range(1,A_bins+1)).values)\n",
    "        B_count_input = np.nan_to_num(different_input[1].reindex(range(1,B_bins+1)).values)\n",
    "# set up rates    \n",
    "    if mutonly == False:\n",
    "        name, exp_rate, con_rate, nonexp_rate = multiply_then_powerlaw(exp_power = exp_power, con_power = con_power, A_bins = A_bins, mult=mult, boot = boot, L_mult = 9, L_mult_nonexp = 9, motif = input_nuc, fill = fill, nonexp_factor = nonexp_factor)\n",
    "        B_indel_rate = np.array([exp_rate[0], con_rate[0], nonexp_rate[0]])        \n",
    "        # change rates from per unit to per STR\n",
    "        exp_rate = exp_rate.values[1:A_bins+1] * A_length_array\n",
    "        con_rate = con_rate.values[1:A_bins+2] * np.array(range(1,A_bins+2))\n",
    "        nonexp_rate = nonexp_rate.values[1:A_bins+3] * np.array(range(1,A_bins+3))\n",
    "        if ceiling != None:\n",
    "            exp_rate[exp_rate > ceiling] = ceiling\n",
    "            con_rate[con_rate > ceiling] = ceiling\n",
    "            nonexp_rate[nonexp_rate > ceiling] = ceiling\n",
    "            name = name + '_ceiling_' + str(ceiling)\n",
    "        if exp_zero == True:\n",
    "            exp_rate *= 0\n",
    "        if con_zero == True:\n",
    "            con_rate *= 0\n",
    "        if nonexp_zero == True:\n",
    "            nonexp_rate *= 0\n",
    "        if random_start == False:\n",
    "            name = name + '_CHM13start'\n",
    "        if random_start == True:\n",
    "            name = name + '_randomstart'\n",
    "        if stochastics is None:\n",
    "            name = name\n",
    "        else:\n",
    "            name = name + '_stochastics_' + str(stochastics)\n",
    "        return A_count_input, B_count_input, exp_rate, con_rate, nonexp_rate, B_indel_rate, name\n",
    "    else:\n",
    "        if boot is None:\n",
    "            name = 'mutonly'\n",
    "        else:\n",
    "            name = 'mutonly_boot' + str(boot)\n",
    "        if random_start == False:\n",
    "            name = name + '_CHM13start'\n",
    "        if random_start == True:\n",
    "            name = name + '_randomstart'\n",
    "        if stochastics is None:\n",
    "            name = name\n",
    "        else:\n",
    "            name = name + '_stochastics_' + str(stochastics)\n",
    "        return A_count_input, B_count_input, None, None, None, None, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dd6b2-61ab-4a4a-b223-6d351b7de96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_processes(mult, exp, con, different_input, L_mult=9, motif = 'A', show = False, norm = True, returndata = False, separate = False, A_bins = 200, B_bins = 200, cut_at_n1 = False):\n",
    "    starting_conditions = setup_evolve(exp, con, mult, input_nuc = motif, different_input = different_input, A_bins = A_bins, B_bins = B_bins, L_mult=L_mult)\n",
    "    A_components = mut_evolve_dist_AB(different_input[0][:A_bins], different_input[1][:B_bins], starting_conditions[2:6], output_components=True, input_nuc = motif, speedup_multiplier = 0)\n",
    "    A_components = pd.DataFrame(A_components)\n",
    "    A_components.columns = A_components.columns + 1\n",
    "    A_components.index = ['mut_in_local_A_B', 'mut_out_local_A_B', 'mut_in_local_B_A', 'mut_out_local_B_A', 'mut_in_fission', 'mut_out_fission', 'mut_in_fusion_A_B', 'mut_out_fusion_A_B', 'exp_in', 'exp_out', 'con_in', 'con_out', 'mut_in_fusion_Bdel', 'mut_out_fusion_Bdel', 'nonexp_in_fission', 'nonexp_fissions_out']\n",
    "    A_components_in = A_components.loc[A_components.index[::2]]\n",
    "    A_components_out = A_components.loc[A_components.index[1::2]]\n",
    "#    A_components_in.index = ['sub. -1', 'sub. +1', 'sub. fission', 'sub. fusion', 'exp. +1', 'con. -1', 'del. fusion', 'ins. fission']\n",
    "#    A_components_out.index = ['sub. -1', 'sub. +1', 'sub. fission', 'sub. fusion', 'exp. +1', 'con. -1', 'del. fusion', 'ins. fission']\n",
    "    A_components_in.index = ['substitution -1', 'substitution +1', 'substitution fission', 'substitution fusion', 'expansion +1', 'contraction -1', 'deletion fusion', 'non-motif insertion fission']\n",
    "    A_components_out.index = ['substitution -1', 'substitution +1', 'substitution fission', 'substitution fusion', 'expansion +1', 'contraction -1', 'deletion fusion', 'non-motif insertion fission']\n",
    "    A_components_sum = A_components_in + A_components_out\n",
    "    if norm == True:\n",
    "        abs_total = A_components_in.abs().sum() + A_components_out.abs().sum()\n",
    "        A_components_in = A_components_in / abs_total\n",
    "        A_components_out = A_components_out / abs_total\n",
    "        A_components_sum = A_components_sum / A_components_sum.abs().sum()\n",
    "    if returndata == 'sum':\n",
    "        return A_components_sum\n",
    "    if returndata == 'in':\n",
    "        return A_components_in\n",
    "    if returndata == 'out':\n",
    "        return A_components_out\n",
    "    else:\n",
    "        last_int_bin = (different_input[0] >= 1).idxmin()\n",
    "        fig_components = go.Figure()\n",
    "        if separate == True:\n",
    "            for component in A_components_sum.index:\n",
    "                fig_components.add_trace(go.Bar(name = component, x = A_components_in.columns, y = A_components_in.loc[component], legendgroup = component))\n",
    "            for component in A_components_sum.index:\n",
    "                fig_components.add_trace(go.Bar(name = component, x = A_components_out.columns, y = A_components_out.loc[component], legendgroup = component, showlegend = False))\n",
    "        else:\n",
    "            for component in A_components_sum.index:\n",
    "                fig_components.add_trace(go.Bar(name = component, x = A_components_sum.columns, y = A_components_sum.loc[component]))\n",
    "        fig_components.add_trace(go.Scatter(x = [last_int_bin] *2, y = [A_components_sum.min().min() - 0.05, A_components_sum.max().max() + 0.1], name = 'count <1', mode = 'lines', line = dict(color = 'rgba(0,0,0,0.5)', dash = 'dash', width = 3)))\n",
    "        fig_components.update_layout(barmode='relative', colorway = plotly.colors.qualitative.Plotly[:8], height = 250, margin={'t':20,'l':60,'b':40,'r':10})        \n",
    "        if cut_at_n1 == True:\n",
    "            if last_int_bin > 10:\n",
    "                fig_components.update_xaxes(range = [0.5, last_int_bin + 0.5], title = 'repeat length (nt)')\n",
    "        if cut_at_n1 == 'sup':\n",
    "            if last_int_bin > 10:\n",
    "                fig_components.update_xaxes(range = [0.5, last_int_bin + 0.5], title = 'repeat length (nt)')\n",
    "        else:\n",
    "            fig_components.update_xaxes(range = [0.5, A_bins + 0.5], title = 'repeat length (nt)')\n",
    "        fig_components.update_yaxes(title = 'relative contribution', gridcolor = 'rgba(0,0,0,0.5)')\n",
    "        if show == True:\n",
    "            fig_components.show()\n",
    "        return fig_components, last_int_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d407ed7-ec39-46a3-87db-634a2c6622c9",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f525a-f2d0-4216-960b-77ddda74a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'simulations/grid_A_L9_subonlystart_prospeedup_200/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad60d8-c72e-4b61-b719-cb65624015c2",
   "metadata": {},
   "source": [
    "#### Simple job list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fd8f2-816b-4a48-888b-1c70b4c98566",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.DataFrame([(mult, exp/10, con/10) for mult in [1,2,4,8,16,32] for exp in range(51) for con in range(51)])\n",
    "jobs.reset_index(inplace = True)\n",
    "jobs.columns = ['ArrayTaskID', 'mult', 'exp', 'con']\n",
    "jobs['ArrayTaskID'] += 1\n",
    "jobs['mult'] = jobs['mult'].astype(float)\n",
    "jobs.to_csv(folder + 'jobs.csv', index = False, sep = '\\t')\n",
    "jobs2 = jobs[10000:].copy()\n",
    "jobs2['ArrayTaskID'] -=10000\n",
    "jobs2.to_csv(folder + 'jobs2.csv', index = False, sep = '\\t')\n",
    "jobs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee376abe-dfec-4149-ba55-99c17eadd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs3 = pd.DataFrame([(mult, exp/10, con/10) for mult in [1,2,4,8,16,32] for exp in range(26) for con in range(26)])\n",
    "jobs3.reset_index(inplace = True)\n",
    "jobs3.columns = ['ArrayTaskID', 'mult', 'exp', 'con']\n",
    "jobs3['ArrayTaskID'] += 1\n",
    "jobs3['mult'] = jobs3['mult'].astype(float)\n",
    "jobs3.to_csv(folder + 'jobs_short.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7b1c8-ffbe-4bb9-ac34-fcf44b584d6b",
   "metadata": {},
   "source": [
    "#### Load simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80087e1-ee8e-4f79-b45d-fe820f104e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_files = os.listdir(folder)\n",
    "grid_files_A = [file for file in grid_files if 'Adist' in file]\n",
    "\n",
    "parameter_info = pd.Series(grid_files_A).str.split('_', expand = True)[[2,3,4,6,7,10,11,12]]\n",
    "parameter_info.index = grid_files_A\n",
    "parameter_info[2] = parameter_info[2].str.split('bins', expand = True)[1].astype(int)\n",
    "parameter_info[3] = parameter_info[3].str.split('sp1e', expand = True)[1].astype(int)\n",
    "#parameter_info[4] = parameter_info[4].str.split('rounds1e', expand = True)[1].astype(int)\n",
    "parameter_info[6] = parameter_info[6].str.split('L', expand = True)[1].astype(int)\n",
    "parameter_info[7] = parameter_info[7].str.split('x', expand = True)[1].astype(float)\n",
    "parameter_info[10] = parameter_info[10].astype(float)\n",
    "parameter_info[11] = parameter_info[11].astype(float)\n",
    "parameter_info[12] = parameter_info[12].str.split('.pickle', expand = True)[0]\n",
    "parameter_info.columns = ['bins', 'speedup (1e)', 'rounds (1e)', 'L_mult', 'mult', 'exp', 'con', 'start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70165c0b-1e41-4088-8d9c-90dee12e7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_info['speedup (1e)'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b467a4-2897-470e-b8a5-6300bab25a2e",
   "metadata": {},
   "source": [
    "#### Check for missing files\n",
    "re-run from \"Load files\" after filling in any missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9be2b-998f-4efc-8e9b-c418647c61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_incomplete = jobs.set_index(['mult', 'exp', 'con']).reindex(parameter_info.set_index(['mult', 'exp', 'con']).reindex(jobs.set_index(['mult', 'exp', 'con']).index).fillna('missing').replace('prospeedup', np.nan).dropna().index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67d70c-93a9-4008-b75f-562e1831d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_incomplete.reset_index(inplace = True)\n",
    "jobs_incomplete.columns = ['ArrayTaskID', 'mult', 'exp', 'con', 'oldid']\n",
    "jobs_incomplete = jobs_incomplete[['ArrayTaskID', 'mult', 'exp', 'con']]\n",
    "jobs_incomplete['ArrayTaskID'] += 1\n",
    "jobs_incomplete['mult'] = jobs_incomplete['mult'].astype(float)\n",
    "jobs_incomplete.to_csv('simulations/grid_A_L9_subonlystart_prospeedup/jobs_incomplete.csv', index = False, sep = '\\t')\n",
    "jobs_incomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e24115-275a-4dd3-b69f-41fb39c17eaa",
   "metadata": {},
   "source": [
    "#### Load simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ee856-1573-4a62-bb96-bf4d4ceb61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_inference_cols = parameter_info.groupby(['speedup (1e)', 'rounds (1e)', 'mult', 'exp', 'con', 'start'])['con'].count().index\n",
    "inference_grid = dict()\n",
    "for speedup, rounds, mult, exp, con, start in parameters_inference_cols:\n",
    "    file = 'Adist_A_bins200_sp1e0_prospeedup_mult_L9_x'+str(mult)+'_extend_pl_'+str(exp)+'_'+str(con)+'_'+start+'.pickle'\n",
    "    inference_grid[(mult, exp, con)] = pd.read_pickle(folder + file)\n",
    "    inference_grid[(mult, exp, con)].columns = inference_grid[(mult, exp, con)].columns * (10**speedup)\n",
    "inference_grid = pd.concat(inference_grid, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220b4e6-f16e-429d-943b-f612007c5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_grid_final = inference_grid.T.groupby(level=[0,1,2]).tail(1).transpose()\n",
    "inference_grid_final.columns = inference_grid_final.columns.droplevel(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f03bd7-535b-4d95-b77b-ba3d080b99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export grid final timepoint for comparison to analytics\n",
    "inference_grid_final.index +=1\n",
    "inference_grid_final.to_csv(folder+'/distributions_grid_prospeedup_Lbound200.csv')\n",
    "inference_grid_final.index -=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed545e-09fc-4a2f-935b-fa36381a844c",
   "metadata": {},
   "source": [
    "## Normalized metric grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf1ee4-480c-4930-9d7c-50f7a7ef0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inference_grid = curve_metric_to_startend(inference_grid, dist_2 = bootstrap_counts_mean['A'].copy(), to_start = False, max_L = 200, normalize=True).unstack().transpose()\n",
    "metric_inference_grid_final = metric_inference_grid.apply(lambda x: x[x.notnull()].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa9b56-6d29-4f93-8a87-833a1227aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inference_grid_final.to_csv(folder+'/metric_grid_prospeedup_finaltimepoint.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e1b51-4a69-4481-b1ce-b56cf447987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_bin = (inference_grid_final > 1).idxmin(axis=0).replace(0,200)\n",
    "\n",
    "def find_max_rate(mult, exp, con, last_bin):\n",
    "    return extend_power_law(exp, denovo_exp_rate['A'][8] *mult, 9, 203)[last_bin] + extend_power_law(con, denovo_con_rate['A'][8]  *mult, 9, 203)[last_bin]\n",
    "\n",
    "max_rate = last_bin.reset_index()\n",
    "max_rate.columns = ['mult', 'exp', 'con', 'last_bin']\n",
    "max_rate['max_rate'] = max_rate.apply(lambda x: find_max_rate(x.mult, x.exp, x.con, x.last_bin), axis=1)\n",
    "max_rate['max_rate_above01'] = max_rate['max_rate'] > 0.1\n",
    "\n",
    "colorscale_clear_white=[[0.0, 'rgba(230,230,230,0)'], [1.0, 'rgba(230,230,230,1)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca15e4d7-9031-47bf-951c-710ed0b4aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 3, shared_xaxes = True, shared_yaxes = True, subplot_titles = ['<i>m</i>=1','<i>m</i>=2','<i>m</i>=4', '<i>m</i>=8','<i>m</i>=16','<i>m</i>=32'], vertical_spacing = 0.12, horizontal_spacing = 0.05, row_heights = [0.5, 0.5], x_title = 'expansion power 𝜏<sub>𝜀</sub>', y_title = 'contraction power 𝜏<sub>𝜅</sub>')\n",
    "col_count = 0\n",
    "for mult in [1,2,4]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = metric_inference_grid_final[mult].index.get_level_values(0), y = metric_inference_grid_final[mult].index.get_level_values(1), z=np.log10(metric_inference_grid_final[mult]), coloraxis='coloraxis1'), row = 1, col = col_count)\n",
    "    fig.add_trace(go.Heatmap(x = max_rate.loc[(max_rate['mult'] == mult)]['exp'], y = max_rate.loc[(max_rate['mult'] == mult)]['con'], z = max_rate.loc[(max_rate['mult'] == mult)]['max_rate_above01'].astype(int), showlegend = False, coloraxis='coloraxis2'), row = 1, col = col_count)\n",
    "col_count = 0\n",
    "for mult in [8,16,32]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = metric_inference_grid_final[mult].index.get_level_values(0), y = metric_inference_grid_final[mult].index.get_level_values(1), z=np.log10(metric_inference_grid_final[mult]), coloraxis='coloraxis1'), row = 2, col = col_count)\n",
    "    fig.add_trace(go.Heatmap(x = max_rate.loc[(max_rate['mult'] == mult)]['exp'], y = max_rate.loc[(max_rate['mult'] == mult)]['con'], z = max_rate.loc[(max_rate['mult'] == mult)]['max_rate_above01'].astype(int), showlegend = False, coloraxis='coloraxis2'), row = 2, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='deep_R', colorbar = dict(title = 'log<sub>10</sub>(metric)', len=1), cmin = np.log10(metric_inference_grid.loc[metric_inference_grid.index.max()].min()), cmax= 3.55))\n",
    "fig.update_layout(coloraxis2=dict(colorscale=colorscale_clear_white, showscale = False, cmin = 0, cmax= 1))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 580, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,5], dtick = 2, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,5], dtick = 2, col = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,5], dtick = 2, col = 2, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,5], dtick = 2, col = 3, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.add_shape(type=\"rect\", x0=2.369-0.745, y0=2.879-0.53, x1=2.369+0.745, y1=2.879+0.53, line=dict(color='rgba(0,255,255,0.85)'), row = 2, col = 1)\n",
    "fig.add_shape(type=\"rect\", x0=2.369-0.745, y0=2.879-0.53, x1=2.369+0.745, y1=2.879+0.53, line=dict(color='rgba(0,255,255,0.85)'), row = 2, col = 2)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power 𝜏<sub>𝜀</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power 𝜏<sub>𝜅</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e7733-e8c4-4d19-84bf-9b94a3e85f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig2b.svg')\n",
    "fig.write_image('plots/fig2b.pdf')\n",
    "fig.write_image('plots/fig2b.png', scale = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad17f6-66b6-4265-9766-ca939ede96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inference_grid_norm_sorted = metric_inference_grid_final.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb604cc-4024-4579-8161-bd24ad53531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inference_grid_norm_sorted.reset_index()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18621122-14c4-478f-bcde-bf40d180d83c",
   "metadata": {},
   "source": [
    "### Grid with 1e9 speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e212588-576a-4954-9d4a-8389d8589e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_1e9 = 'simulations/grid_A_L9_subonlystart_long/'\n",
    "grid_files = os.listdir(folder_1e9)\n",
    "grid_files_A = [file for file in grid_files if 'Adist' in file]\n",
    "\n",
    "parameter_info_1e9 = pd.Series(grid_files_A).str.split('_', expand = True)[[2,3,4,6,7,10,11,12]]\n",
    "parameter_info_1e9.index = grid_files_A\n",
    "parameter_info_1e9[2] = parameter_info_1e9[2].str.split('bins', expand = True)[1].astype(int)\n",
    "parameter_info_1e9[3] = parameter_info_1e9[3].str.split('sp1e', expand = True)[1].astype(int)\n",
    "parameter_info_1e9[4] = parameter_info_1e9[4].str.split('rounds1e', expand = True)[1].astype(int)\n",
    "parameter_info_1e9[6] = parameter_info_1e9[6].str.split('L', expand = True)[1].astype(int)\n",
    "parameter_info_1e9[7] = parameter_info_1e9[7].str.split('x', expand = True)[1].astype(float)\n",
    "parameter_info_1e9[10] = parameter_info_1e9[10].astype(float)\n",
    "parameter_info_1e9[11] = parameter_info_1e9[11].astype(float)\n",
    "parameter_info_1e9[12] = parameter_info_1e9[12].str.split('.pickle', expand = True)[0]\n",
    "parameter_info_1e9.columns = ['bins', 'speedup (1e)', 'rounds (1e)', 'L_mult', 'mult', 'exp', 'con', 'start']\n",
    "\n",
    "# sort by speedup and remove (faster) duplicates\n",
    "parameter_info_1e9 = parameter_info_1e9.sort_values(by = 'speedup (1e)').drop_duplicates(subset = ['mult', 'exp', 'con'], keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd920f-790b-4097-b9c7-ff6841299fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_info_1e9 = parameter_info_1e9.loc[(parameter_info_1e9['exp'] <= 3) & (parameter_info_1e9['con'] <= 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad51867-0631-4983-8e3d-c4fa46d0aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_inference_cols = parameter_info_1e9.groupby(['speedup (1e)', 'rounds (1e)', 'mult', 'exp', 'con', 'start'])['con'].count().index\n",
    "inference_grid_1e9 = dict()\n",
    "for speedup, rounds, mult, exp, con, start in parameters_inference_cols:\n",
    "    file = 'Adist_A_bins100_sp1e'+str(speedup)+'_rounds1e'+str(rounds)+'_mult_L9_x'+str(mult)+'_extend_pl_'+str(exp)+'_'+str(con)+'_'+start+'.pickle'\n",
    "    inference_grid_1e9[(mult, exp, con)] = pd.read_pickle(folder_1e9 + file)\n",
    "    inference_grid_1e9[(mult, exp, con)].columns = inference_grid_1e9[(mult, exp, con)].columns * (10**speedup)\n",
    "inference_grid_1e9 = pd.concat(inference_grid_1e9, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc69f0-e714-4750-8090-f371bd73ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_grid_1e9_final = inference_grid_1e9.T.groupby(level=[0,1,2]).tail(1).transpose()\n",
    "inference_grid_1e9_final.columns = inference_grid_1e9_final.columns.droplevel(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f2a4f-da43-4b56-aba0-811f9d2e31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inference_grid_1e9 = curve_metric_to_startend(inference_grid_1e9, dist_2 = bootstrap_counts_mean['A'].copy(), to_start = False, max_L = 100, normalize=True).unstack().transpose()\n",
    "metric_inference_grid_1e9_final = metric_inference_grid_1e9.apply(lambda x: x[x.notnull()].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0b375-2900-4f58-a9cf-836fdb61d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 3, shared_xaxes = True, shared_yaxes = True, subplot_titles = ['<i>m</i>=1','<i>m</i>=2','<i>m</i>=4', '<i>m</i>=8','<i>m</i>=16','<i>m</i>=32'], vertical_spacing = 0.12, horizontal_spacing = 0.05, row_heights = [0.5, 0.5], x_title = 'expansion power 𝜏<sub>𝜀</sub>', y_title = 'contraction power 𝜏<sub>𝜅</sub>')\n",
    "col_count = 0\n",
    "for mult in [1,2,4]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = metric_inference_grid_1e9_final[mult].index.get_level_values(0), y = metric_inference_grid_1e9_final[mult].index.get_level_values(1), z=np.log10(metric_inference_grid_1e9_final[mult]), coloraxis='coloraxis1'), row = 1, col = col_count)\n",
    "col_count = 0\n",
    "for mult in [8,16,32]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = metric_inference_grid_1e9_final[mult].index.get_level_values(0), y = metric_inference_grid_1e9_final[mult].index.get_level_values(1), z=np.log10(metric_inference_grid_1e9_final[mult]), coloraxis='coloraxis1'), row = 2, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='deep_R', colorbar = dict(title = 'log<sub>10</sub>(metric)', len=1), cmin = np.log10(metric_inference_grid_1e9.loc[metric_inference_grid_1e9.index.max()].min()), cmax= 3.55))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 580, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,3.5], dtick = 2, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,3.5], dtick = 2, col = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,3.5], dtick = 2, col = 2, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,3.5], dtick = 2, col = 3, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.add_shape(type=\"rect\", x0=2.369-0.745, y0=2.879-0.53, x1=2.369+0.745, y1=2.879+0.53, line=dict(color='rgba(0,255,255,0.85)'), row = 2, col = 1)\n",
    "fig.add_shape(type=\"rect\", x0=2.369-0.745, y0=2.879-0.53, x1=2.369+0.745, y1=2.879+0.53, line=dict(color='rgba(0,255,255,0.85)'), row = 2, col = 2)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power 𝜏<sub>𝜀</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power 𝜏<sub>𝜅</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa46101-0631-426b-acd1-30ea3462d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/figS8c.svg')\n",
    "fig.write_image('plots/figS8c.pdf')\n",
    "fig.write_image('plots/figS8c.png', scale = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af587b6b-26cc-419a-b769-deae5c66fa76",
   "metadata": {},
   "source": [
    "### Grid with stochastics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e9281-df96-4074-ad0f-a6ae2c797f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_stoch = 'simulations/grid_A_L9_subonlystart_prospeedup_200_stoch/'\n",
    "grid_files = os.listdir(folder_stoch)\n",
    "grid_files_A = [file for file in grid_files if 'Adist' in file]\n",
    "\n",
    "parameter_info_stoch = pd.Series(grid_files_A).str.split('_', expand = True)[[2,3,4,6,7,10,11,12]]\n",
    "parameter_info_stoch.index = grid_files_A\n",
    "parameter_info_stoch[2] = parameter_info_stoch[2].str.split('bins', expand = True)[1].astype(int)\n",
    "parameter_info_stoch[3] = parameter_info_stoch[3].str.split('sp1e', expand = True)[1].astype(int)\n",
    "#parameter_info_stoch[4] = parameter_info_stoch[4].str.split('rounds1e', expand = True)[1].astype(int)\n",
    "parameter_info_stoch[6] = parameter_info_stoch[6].str.split('L', expand = True)[1].astype(int)\n",
    "parameter_info_stoch[7] = parameter_info_stoch[7].str.split('x', expand = True)[1].astype(float)\n",
    "parameter_info_stoch[10] = parameter_info_stoch[10].astype(float)\n",
    "parameter_info_stoch[11] = parameter_info_stoch[11].astype(float)\n",
    "parameter_info_stoch[12] = parameter_info_stoch[12].str.split('.pickle', expand = True)[0]\n",
    "parameter_info_stoch.columns = ['bins', 'speedup (1e)', 'rounds (1e)', 'L_mult', 'mult', 'exp', 'con', 'start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f817d4f-0a04-4c34-b9f5-b9af9e5f0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_inference_cols = parameter_info_stoch.groupby(['speedup (1e)', 'rounds (1e)', 'mult', 'exp', 'con', 'start'])['con'].count().index\n",
    "inference_grid_stoch = dict()\n",
    "for speedup, rounds, mult, exp, con, start in parameters_inference_cols:\n",
    "    file = 'Adist_A_bins200_sp1e0_prospeedup_mult_L9_x'+str(mult)+'_extend_pl_'+str(exp)+'_'+str(con)+'_'+start+'_stochastics_1.pickle'\n",
    "    inference_grid_stoch[(mult, exp, con)] = pd.read_pickle(folder_stoch + file)\n",
    "    inference_grid_stoch[(mult, exp, con)].columns = inference_grid_stoch[(mult, exp, con)].columns * (10**speedup)\n",
    "inference_grid_stoch = pd.concat(inference_grid_stoch, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa25c2-ab24-4d82-9b09-7a08ed3c578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_grid_stoch_final = inference_grid_stoch.T.groupby(level=[0,1,2]).tail(1).transpose()\n",
    "inference_grid_stoch_final.columns = inference_grid_stoch_final.columns.droplevel(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1be15-cc55-44ad-9469-3b5abf8a560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inference_grid_stoch = curve_metric_to_startend(inference_grid_stoch, dist_2 = bootstrap_counts_mean['A'].copy(), to_start = False, max_L = 200, normalize=True).unstack().transpose()\n",
    "metric_inference_grid_stoch_final = metric_inference_grid_stoch.apply(lambda x: x[x.notnull()].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72366f7-75af-4712-aac1-d8319e1dee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: missing values are exceeding int32 limitation in the poisson calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d1bf1-5f59-43d6-b70c-c9f8db79851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 3, shared_xaxes = True, shared_yaxes = True, subplot_titles = ['<i>m</i>=1','<i>m</i>=2','<i>m</i>=4', '<i>m</i>=8','<i>m</i>=16','<i>m</i>=32'], vertical_spacing = 0.12, horizontal_spacing = 0.05, row_heights = [0.5, 0.5], x_title = 'expansion power 𝜏<sub>𝜀</sub>', y_title = 'contraction power 𝜏<sub>𝜅</sub>')\n",
    "col_count = 0\n",
    "for mult in [1,2,4]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = metric_inference_grid_stoch_final[mult].index.get_level_values(0), y = metric_inference_grid_stoch_final[mult].index.get_level_values(1), z=np.log10(metric_inference_grid_stoch_final[mult]), coloraxis='coloraxis1'), row = 1, col = col_count)\n",
    "col_count = 0\n",
    "for mult in [8,16,32]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = metric_inference_grid_stoch_final[mult].index.get_level_values(0), y = metric_inference_grid_stoch_final[mult].index.get_level_values(1), z=np.log10(metric_inference_grid_stoch_final[mult]), coloraxis='coloraxis1'), row = 2, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='deep_R', colorbar = dict(title = 'log<sub>10</sub>(metric)', len=1), cmin = np.log10(metric_inference_grid_stoch.loc[metric_inference_grid_stoch.index.max()].min()), cmax= 3.55))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 580, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,2.5], dtick = 2, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,2.5], dtick = 2, col = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,2.5], dtick = 2, col = 2, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,2.5], dtick = 2, col = 3, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power 𝜏<sub>𝜀</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power 𝜏<sub>𝜅</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb7e49-7e93-43e8-a00d-d051b1d269c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/figS8a.svg')\n",
    "fig.write_image('plots/figS8a.pdf')\n",
    "fig.write_image('plots/figS8a.png', scale = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026caf70-1b8c-4806-9d96-dbbc5b6a8316",
   "metadata": {},
   "source": [
    "### Stochastics on top solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f9040-b551-48a9-812f-fbc4c5e58fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_files_stoch = os.listdir(folder + 'stoch/')\n",
    "grid_files_A_stoch = [file for file in grid_files_stoch if file.startswith('Adist')]\n",
    "\n",
    "parameter_info_stoch = pd.Series(grid_files_A_stoch).str.split('_', expand = True)[[2,7,10,11,14]]\n",
    "parameter_info_stoch.index = grid_files_A_stoch\n",
    "parameter_info_stoch[2] = parameter_info_stoch[2].str.split('bins', expand = True)[1].astype(int)\n",
    "parameter_info_stoch[7] = parameter_info_stoch[7].str.split('x', expand = True)[1].astype(float)\n",
    "parameter_info_stoch[10] = parameter_info_stoch[10]#.astype(float)\n",
    "parameter_info_stoch[11] = parameter_info_stoch[11]#.astype(float)\n",
    "parameter_info_stoch[14] = parameter_info_stoch[14].str.split('.pickle', expand = True)[0]\n",
    "\n",
    "parameter_info_stoch.columns = ['bins', 'mult', 'exp', 'con', 'stochastics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d618c4c-5ec7-4aab-976d-882ac79a8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "motif = 'A'\n",
    "parameter_info_stoch_cols = parameter_info_stoch.groupby(['bins', 'mult', 'exp', 'con', 'stochastics'])['bins'].count().index\n",
    "best_stoch = dict()\n",
    "for bins, mult, exp, con, stochastics in parameter_info_stoch_cols:\n",
    "    file = 'Adist_A_bins'+str(bins)+'_sp1e0_prospeedup_mult_L9_x'+str(mult)+'_extend_pl_'+str(exp)+'_'+str(con)+'_subonlystart_stochastics_'+str(stochastics)+'.pickle'\n",
    "    best_stoch[(motif, mult, float(exp), float(con), stochastics)] = pd.read_pickle(folder + 'stoch/' + file)\n",
    "    best_stoch[(motif, mult, float(exp), float(con), stochastics)].columns = best_stoch[(motif, mult, float(exp), float(con), stochastics)].columns * (10**speedup)\n",
    "best_stoch = pd.concat(best_stoch, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b615be2-492e-4e21-9f65-bb6cce7d331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_stoch_final = best_stoch.T.groupby(level=[0,1,2,3,4]).tail(1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f06736-bd27-4544-897c-c93032400b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fig_stochastics(motif, mult, exp, con, timepoint = metric_inference_grid.index.max(), normalize = False):\n",
    "    fig_stochastics = go.Figure()\n",
    "    current = best_stoch_final[motif][mult][exp][con]\n",
    "    maxL = (inference_grid_final[mult][exp][con] >= bootstrap_counts_mean[motif].min()).idxmin() +1\n",
    "    leg = True\n",
    "    if normalize == False:\n",
    "        for run in current.columns:\n",
    "            fig_stochastics.add_trace(go.Scatter(x = (current[run].index+1), y = current[run].replace(0, np.nan), mode = 'lines', line = dict(width = 1, color = plotly.colors.DEFAULT_PLOTLY_COLORS[0]), opacity = 0.1, legendgroup = 'med', name = 'computational model (stochastics)', showlegend = leg))\n",
    "            leg = False\n",
    "        fig_stochastics.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index * len(motif), y = bootstrap_counts_mean[motif], line = dict(color = 'rgba(0,0,0,0.8)'), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "        fig_stochastics.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index * len(motif), y = bootstrap_counts_max[motif], line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "        fig_stochastics.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index * len(motif), y = bootstrap_counts_min[motif], fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "        fig_stochastics.add_trace(go.Scatter(x = (inference_grid_final[mult][exp][con].index+1) * len(motif), y = inference_grid_final[mult][exp][con], mode = 'lines', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1]), legendgroup = 'med', name = 'computational model (deterministic)'))\n",
    "        fig_stochastics.update_yaxes(type = 'log', title = 'counts', range = [-0.05,9.05], tickformat = '1.0e', dtick = 2)\n",
    "    if normalize == True:\n",
    "        for run in current.columns:\n",
    "            fig_stochastics.add_trace(go.Scatter(x = (current[run].index+1)[:maxL], y = current[run][:maxL] / current[run].sum(), mode = 'lines', line = dict(width = 1, color = plotly.colors.DEFAULT_PLOTLY_COLORS[0]), opacity = 0.05, legendgroup = 'med', name = 'computational model (stochastics)', showlegend = leg))\n",
    "            leg = False\n",
    "        fig_stochastics.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index * len(motif), y = bootstrap_counts_mean[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,0.8)'), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "        fig_stochastics.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index * len(motif), y = bootstrap_counts_max[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "        fig_stochastics.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index * len(motif), y = bootstrap_counts_min[motif] / bootstrap_counts_mean[motif].sum(), fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "        fig_stochastics.add_trace(go.Scatter(x = (inference_grid_final[mult][exp][con].index+1)[:maxL] * len(motif), y = inference_grid_final[mult][exp][con][:maxL] / inference_grid_final[mult][exp][con].sum(), mode = 'lines', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1]), legendgroup = 'med', name = 'computational model (deterministic)'))\n",
    "        fig_stochastics.update_yaxes(type = 'log', title = 'frequency', range = [-9.05,0], tickformat = '1.0e', dtick = 2)\n",
    "    fig_stochastics.update_xaxes(type = 'log', title = 'repeat length (nt)', range = [0,2], tickvals = [1,2,5,10,20,50], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig_stochastics.update_yaxes(gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig_stochastics.update_layout(width = 800, height = 330, font=dict(family = 'Arial', size = 20), margin={'t':20,'l':80,'b':50,'r':10})\n",
    "    fig_stochastics.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=1.1))\n",
    "    \n",
    "    return fig_stochastics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ed73a-e666-49cf-a1c7-f8eb3780f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_fig_stochastics('A', 2,1.5,1.8, normalize=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94280877-4d01-43cb-b1ba-c9953a414148",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/figS8b.svg')\n",
    "fig.write_image('plots/figS8b.pdf')\n",
    "fig.write_image('plots/figS8b.png', scale = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42aee4-39d5-42ae-a45a-d23be515a201",
   "metadata": {},
   "source": [
    "### Genome size plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8889e-fdd9-4a1b-8422-afbac19850d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_size = inference_grid.mul(inference_grid.index+1, axis=0).sum() #+ inference_grid_B.mul(inference_grid_B.index+1, axis=0).sum()\n",
    "genome_size_final = inference_grid_final.mul(inference_grid_final.index+1, axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd22b2-b0ba-4ce6-9dcf-10010e9d4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 3, shared_xaxes = True, shared_yaxes = True, subplot_titles = ['<i>m</i>=1','<i>m</i>=2','<i>m</i>=4', '<i>m</i>=8','<i>m</i>=16','<i>m</i>=32'], vertical_spacing = 0.12, horizontal_spacing = 0.05, row_heights = [0.5, 0.5], x_title = 'expansion power 𝜏<sub>𝜀</sub>', y_title = 'contraction power 𝜏<sub>𝜅</sub>')\n",
    "col_count = 0\n",
    "for mult in [1,2,4]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = genome_size_final.loc[mult].index.get_level_values(0), y = genome_size_final.loc[mult].index.get_level_values(1), z=np.log10(genome_size_final.replace(0, 1e50).loc[mult]), coloraxis='coloraxis1'), row = 1, col = col_count)\n",
    "col_count = 0\n",
    "for mult in [8,16,32]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = genome_size_final.loc[mult].index.get_level_values(0), y = genome_size_final.loc[mult].index.get_level_values(1), z=np.log10(genome_size_final.replace(0, 1e50).loc[mult]), coloraxis='coloraxis1'), row = 2, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='deep_R', colorbar = dict(title = 'log<sub>10</sub>(L<sub>genome</sub>)', len=1), cmin = 9.3, cmax= 50))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 580, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,5], dtick = 2, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,5], dtick = 2, col = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,5], dtick = 2, col = 2, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_xaxes(range = [0,5], dtick = 2, col = 3, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power 𝜏<sub>𝜀</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power 𝜏<sub>𝜅</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663fde8-3df8-4d48-b195-d5c9ab73fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig_S6.png', scale=10)\n",
    "fig.write_image('plots/fig_S6.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff559b39-036a-43a1-8812-336a5ec37d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log10 of starting genome size\n",
    "np.log10((inference_grid[1][1][1][0] * (inference_grid.index+1)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf1c80-8183-431f-8e2d-53e82c387973",
   "metadata": {},
   "source": [
    "## Poisson error calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf93c7d-b86c-4735-81fe-08fd8953cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_files_poisson = os.listdir(folder + 'poisson/')\n",
    "grid_files_A_poisson = [file for file in grid_files_poisson if file.startswith('Adist')]\n",
    "\n",
    "parameter_info_poisson = pd.Series(grid_files_A_poisson).str.split('_', expand = True)[[2,3,4,7,10,11,12,13]]\n",
    "parameter_info_poisson.index = grid_files_A_poisson\n",
    "parameter_info_poisson[2] = parameter_info_poisson[2].str.split('bins', expand = True)[1].astype(int)\n",
    "parameter_info_poisson[3] = parameter_info_poisson[3].str.split('sp1e', expand = True)[1].astype(int)\n",
    "parameter_info_poisson[7] = parameter_info_poisson[7].str.split('x', expand = True)[1].astype(float)\n",
    "parameter_info_poisson[10] = parameter_info_poisson[10]#.astype(float)\n",
    "parameter_info_poisson[11] = parameter_info_poisson[11]#.astype(float)\n",
    "parameter_info_poisson[12] = parameter_info_poisson[12].str.split('boot', expand = True)[1].astype(int)\n",
    "parameter_info_poisson[13] = parameter_info_poisson[13].str.split('.pickle', expand = True)[0]\n",
    "\n",
    "parameter_info_poisson.columns = ['bins', 'speedup (1e)', 'rounds (1e)', 'mult', 'exp', 'con', 'boot', 'start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da663b-36ec-427d-b9e1-15aa1375141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grid_files_A_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f58680-1e67-41c9-9b02-f876a1807ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "motif = 'A'\n",
    "parameter_info_poisson_cols = parameter_info_poisson.groupby(['bins', 'speedup (1e)', 'rounds (1e)', 'mult', 'exp', 'con', 'boot', 'start'])['bins'].count().index\n",
    "best_poisson = dict()\n",
    "for bins, speedup, rounds, mult, exp, con, boot, start in parameter_info_poisson_cols:\n",
    "    file = 'Adist_A_bins200_sp1e0_prospeedup_mult_L9_x'+str(mult)+'_extend_pl_'+str(exp)+'_'+str(con)+'_boot'+str(boot)+'_'+start+'.pickle'\n",
    "    best_poisson[(motif, mult, float(exp), float(con), boot)] = pd.read_pickle(folder + 'poisson/' + file)\n",
    "    best_poisson[(motif, mult, float(exp), float(con), boot)].columns = best_poisson[(motif, mult, float(exp), float(con), boot)].columns * (10**speedup)\n",
    "best_poisson = pd.concat(best_poisson, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01cb350-ae09-45f2-abaa-a858f6cadc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_poisson_final = best_poisson.T.groupby(level=[0,1,2,3,4]).tail(1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275d98f-edb1-47fa-b4b6-0889c11a730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fig_boot(motif, mult, exp, con, timepoint = metric_inference_grid.index.max(), normalize = False):\n",
    "    fig_boot = go.Figure()\n",
    "    current = best_poisson_final[motif][mult][exp][con]\n",
    "    maxL = (inference_grid_final[mult][exp][con] >= bootstrap_counts_mean[motif].min()).idxmin() +1\n",
    "    if normalize == False:\n",
    "        fig_boot.add_trace(go.Scatter(x = (inference_grid_final[mult][exp][con].index+1)[:maxL] * len(motif), y = inference_grid_final[mult][exp][con][:maxL], legendgroup = 'med', name = 'computational model'))\n",
    "        fig_boot.add_trace(go.Scatter(x = (current.index+1)[:maxL] * len(motif), y = current.quantile(0.975, axis=1)[:maxL], line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'med', showlegend = False, name = 'bootstrap 95%'))\n",
    "        fig_boot.add_trace(go.Scatter(x = (current.index+1)[:maxL] * len(motif), y = current.quantile(0.025, axis=1)[:maxL], fill='tonexty', fillcolor = 'rgba(31, 119, 180,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'med', showlegend = False, name = 'bootstrap 5%'))\n",
    "        \n",
    "        fig_boot.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index * len(motif), y = bootstrap_counts_mean[motif], line = dict(color = 'rgba(0,0,0,0.8)'), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "        fig_boot.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index * len(motif), y = bootstrap_counts_max[motif], line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "        fig_boot.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index * len(motif), y = bootstrap_counts_min[motif], fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "        fig_boot.update_yaxes(type = 'log', title = 'counts', range = [-0.05,9.05], tickformat = '1.0e', dtick = 2)\n",
    "    if normalize == True:\n",
    "        fig_boot.add_trace(go.Scatter(x = (inference_grid_final[mult][exp][con].index+1)[:maxL] * len(motif), y = inference_grid_final[mult][exp][con][:maxL] / inference_grid_final[mult][exp][con].sum(), legendgroup = 'med', name = 'computational model'))\n",
    "        fig_boot.add_trace(go.Scatter(x = (current.index+1)[:maxL] * len(motif), y = current.quantile(0.975, axis=1)[:maxL] / current.median(axis=1).sum(), line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'med', showlegend = False, name = 'bootstrap 95%'))\n",
    "        fig_boot.add_trace(go.Scatter(x = (current.index+1)[:maxL] * len(motif), y = current.quantile(0.025, axis=1)[:maxL] / current.median(axis=1).sum(), fill='tonexty', fillcolor = 'rgba(31, 119, 180,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'med', showlegend = False, name = 'bootstrap 5%'))\n",
    "        \n",
    "        fig_boot.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index * len(motif), y = bootstrap_counts_mean[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,0.8)'), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "        fig_boot.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index * len(motif), y = bootstrap_counts_max[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "        fig_boot.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index * len(motif), y = bootstrap_counts_min[motif] / bootstrap_counts_mean[motif].sum(), fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "        fig_boot.update_yaxes(type = 'log', title = 'frequency', range = [-9.05,0], tickformat = '1.0e', dtick = 2)\n",
    "    fig_boot.update_xaxes(type = 'log', title = 'repeat length (nt)', range = [0,2], tickvals = [1,2,5,10,20,50], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig_boot.update_yaxes(gridcolor = 'rgba(0,0,0,0.2)')\n",
    "\n",
    "    fig_boot.update_layout(font=dict(family = 'Arial', size = 13), margin={'t':20,'l':60,'b':40,'r':10})\n",
    "\n",
    "    fig_boot.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99))\n",
    "    \n",
    "    return fig_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861f94a-c230-4e34-98b3-41a26af5ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_boot = make_fig_boot('A', 2, 1.5, 1.8, normalize = True)\n",
    "fig_boot.update_layout(height = 250, width = 470, margin={'t':20,'l':55,'b':35,'r':10})       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90a08b-ddf2-4e77-a988-54f65e7d8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_boot.write_image('plots/fig2c.svg')\n",
    "fig_boot.write_image('plots/fig2c.pdf')\n",
    "fig_boot.write_image('plots/fig2c.png', scale = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eeb2d7-f7b6-4615-a3ef-2e188748d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_metric(motif, mult, exp, con, timepoint = metric_inference_grid.index.max(), normalize = False, max_L = 200):\n",
    "    poisson_metric = dict()\n",
    "    poisson_current = best_poisson_final[motif][mult][exp][con]\n",
    "    for boot in poisson_current.columns.levels[0]:\n",
    "        poisson_metric[boot] = curve_metric_to_startend(poisson_current[boot], dist_2 = bootstrap_counts[boot][motif].copy(), to_start=False, max_L = 200, normalize = normalize)\n",
    "    poisson_metric = pd.concat(poisson_metric).sort_values().head(len(poisson_metric) - int(0.05 * len(poisson_metric)))   # one-sided 95%\n",
    "    return poisson_metric.median(), poisson_metric.max(), poisson_metric.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addae65e-f2dc-4c60-9129-8df83edb9926",
   "metadata": {},
   "source": [
    "## Plot diagonals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569f635-2948-46f5-97ae-b1ee3bd2d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_add_paramlist(fig, param_list, group_name, colorlist = plotly.colors.cyclical.Phase, motif = 'A', colornum = 0, df = inference_grid_final, opacity = 0.5, normalize = False, show_CHM13 = False):\n",
    "    group = df.reindex(param_list.set_index(['mult', 'exp', 'con']).index, axis=1)\n",
    "    group.columns = list(range(len(group.columns)))\n",
    "    group = group[group >1].fillna(1,limit=1, axis=0)\n",
    "    group.loc[len(group)+1] = np.nan\n",
    "    group_index = np.array(([group.index+1]*200)).flatten()\n",
    "    if normalize == True:\n",
    "        group = group.div(group.sum())\n",
    "    group = pd.Series(group.transpose().to_numpy().flatten())\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x = group_index, y = group, mode = 'lines', line = dict(width = 1.5, color = colorlist[colornum] if colornum != -1 else 'rgba(120,120,120,0.2)'), name = group_name, connectgaps = False, opacity = opacity))\n",
    "\n",
    "    if show_CHM13 == True:\n",
    "        if normalize == True:\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index, y = bootstrap_counts_mean[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,1)', width = 3), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index, y = bootstrap_counts_max[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index, y = bootstrap_counts_min[motif] / bootstrap_counts_mean[motif].sum(), fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "        else:\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index, y = bootstrap_counts_mean[motif], line = dict(color = 'rgba(0,0,0,1)', width = 3), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index, y = bootstrap_counts_max[motif], line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index, y = bootstrap_counts_min[motif], fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "    fig.update_xaxes(type = 'log', title = 'repeat length (nt)', range = [0,2], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    if normalize == True:\n",
    "        fig.update_yaxes(type = 'log', title = 'frequency', range = [-9,0], gridcolor = 'rgba(0,0,0,0.2)', tickformat = '1.0e', dtick = 2)\n",
    "    else:\n",
    "        fig.update_yaxes(type = 'log', title = 'counts', range = [0,11], gridcolor = 'rgba(0,0,0,0.2)', tickformat = '1.0e', dtick = 2)\n",
    "    fig.update_layout(font=dict(family = 'Arial', size = 16), height = 300, width = 780, margin={'t':20,'l':60,'b':40,'r':10}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ef0c9-acfc-46da-9e6e-36d051f418bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore lower left corner\n",
    "mult = 8\n",
    "corner_size = 1\n",
    "diagonal_groups = dict()\n",
    "for diag in [0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2, -1.3, -1.4, -1.5, -1.6, -1.7, -1.8, -1.9, -2, -2.1, -2.2, -2.3, -2.4, -2.5, -2.6, -2.7, -2.8, -2.9, -3, -3.1, -3.2, -3.3, -3.4, -3.5, -3.6, -3.7, -3.8, -3.9, -4, -4.1, -4.2, -4.3, -4.4, -4.5, -4.6, -4.7, -4.8, -4.9]:#, -5]:\n",
    "    diagonal_groups[diag] = parameter_info.loc[(parameter_info['mult'] == mult) & (parameter_info['exp'] - parameter_info['con'] >= diag-0.01) & (parameter_info['exp'] - parameter_info['con'] <= diag+0.01)  & ((parameter_info['exp'] >corner_size) | (parameter_info['con'] >corner_size))].copy()\n",
    "    if len(diagonal_groups[diag]) == 0:\n",
    "        del diagonal_groups[diag]\n",
    "\n",
    "diagonal_groups_exp = dict()\n",
    "for diag in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9]:#, 5]:\n",
    "    diagonal_groups_exp[diag] = parameter_info.loc[(parameter_info['mult'] == mult) & (parameter_info['exp'] - parameter_info['con'] >= diag-0.01) & (parameter_info['exp'] - parameter_info['con'] <= diag+0.01)  & ((parameter_info['exp'] >corner_size) | (parameter_info['con'] >corner_size))].copy()\n",
    "    if len(diagonal_groups_exp[diag]) == 0:\n",
    "        del diagonal_groups_exp[diag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9c563-54d9-4c29-aca5-3744e7e1e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_colorscale = plotly.colors.sample_colorscale(plotly.colors.sequential.Rainbow, np.linspace(0,len(diagonal_groups.keys())) / len(diagonal_groups.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e401e-3117-46c3-8d93-7c75bb3d66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrative figure\n",
    "fig_phases = go.Figure()\n",
    "for diag in list(diagonal_groups_exp.keys())[:-1]:\n",
    "    fig_phases.add_trace(go.Scatter(x = diagonal_groups_exp[diag]['exp'], y = diagonal_groups_exp[diag]['con'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 6, color = 'rgba(120,120,120,0.65)')))\n",
    "colornum = 0\n",
    "for diag in diagonal_groups:\n",
    "    fig_phases.add_trace(go.Scatter(x = diagonal_groups[diag]['exp'], y = diagonal_groups[diag]['con'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 6, color = current_colorscale[colornum])))\n",
    "    colornum +=1\n",
    "\n",
    "fig_phases.add_trace(go.Scatter(x = [0,5], y = [1.5, 6.5], line = dict(color = 'white', width = 3.5, dash = 'dash'), opacity = 0.8, mode = 'lines', showlegend = False))\n",
    "fig_phases.add_trace(go.Scatter(x = [0,4.5], y = [0.5, 5], line = dict(color = 'white', width = 3.5, dash = 'dash'), opacity = 0.8, mode = 'lines', showlegend = False))\n",
    "fig_phases.add_trace(go.Scatter(x = [0,5], y = [0, 5], line = dict(color = 'white', width = 3.5, dash = 'dash'), opacity = 0.8, mode = 'lines', showlegend = False))\n",
    "\n",
    "fig_phases.add_trace(go.Scatter(x = [0], y = [3], marker = dict(color = 'red', size = 8, line_width = 1, line_color = 'white', symbol = 'circle'), mode = 'markers', name = 'i'))\n",
    "fig_phases.add_trace(go.Scatter(x = [1], y = [2], marker = dict(color = 'red', size = 9, line_width = 1, line_color = 'white', symbol = 'diamond'), mode = 'markers', name = 'ii'))\n",
    "fig_phases.add_trace(go.Scatter(x = [1.3], y = [1.7], marker = dict(color = 'red', size = 8, line_width = 1, line_color = 'white', symbol = 'square'), mode = 'markers', name = 'iii'))\n",
    "fig_phases.add_trace(go.Scatter(x = [1.5], y = [1.5], marker = dict(color = 'red', size = 11, line_width = 1, line_color = 'white', symbol = 'triangle-up'), mode = 'markers', name = 'iv'))\n",
    "fig_phases.add_trace(go.Scatter(x = [2.5], y = [0.5], marker = dict(color = 'red', size = 11, line_width = 1, line_color = 'white', symbol = 'triangle-down'), mode = 'markers', name = 'v'))\n",
    "\n",
    "fig_phases.update_layout(font=dict(family = 'Arial', size = 14), height = 250, width = 270, margin={'t':30,'l':35,'b':40,'r':0})\n",
    "fig_phases.update_xaxes(range = [-0.2, 3.05], dtick = 1, title = 'expansion power 𝜏<sub>𝜀</sub>', gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_phases.update_yaxes(range = [0, 3.1], dtick = 1, title = 'contraction power 𝜏<sub>𝜅</sub>', gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"x\", scaleratio=1)\n",
    "fig_phases.update_layout(legend=dict(indentation = -15))\n",
    "fig_phases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e7d21-44d1-48cc-b30b-bf2b41413789",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_phases.write_image('plots/fig3a.svg')\n",
    "fig_phases.write_image('plots/fig3a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc0fe1-0a57-4f7b-926e-ff6d53b08213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore lower left corner\n",
    "for mult, corner_size in zip([1,2,4,8,16,32], [1.5, 1.4, 1.3, 1.2, 1.1, 1]):\n",
    "    diagonal_groups = dict()\n",
    "    for diag in [0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2, -1.3, -1.4, -1.5, -1.6, -1.7, -1.8, -1.9, -2, -2.1, -2.2, -2.3, -2.4, -2.5, -2.6, -2.7, -2.8, -2.9, -3, -3.1, -3.2, -3.3, -3.4, -3.5, -3.6, -3.7, -3.8, -3.9, -4, -4.1, -4.2, -4.3, -4.4, -4.5, -4.6, -4.7, -4.8, -4.9]:\n",
    "        diagonal_groups[diag] = parameter_info.loc[(parameter_info['mult'] == mult) & (parameter_info['exp'] - parameter_info['con'] >= diag-0.01) & (parameter_info['exp'] - parameter_info['con'] <= diag+0.01)  & ((parameter_info['exp'] >corner_size) | (parameter_info['con'] >corner_size))].copy()\n",
    "        diagonal_groups[diag]['round'] = 1e9\n",
    "        if len(diagonal_groups[diag]) == 0:\n",
    "            del diagonal_groups[diag]\n",
    "    \n",
    "    diagonal_groups_exp = dict()\n",
    "    for diag in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9]:\n",
    "        diagonal_groups_exp[diag] = parameter_info.loc[(parameter_info['mult'] == mult) & (parameter_info['exp'] - parameter_info['con'] >= diag-0.01) & (parameter_info['exp'] - parameter_info['con'] <= diag+0.01)  & ((parameter_info['exp'] >corner_size) | (parameter_info['con'] >corner_size))].copy()\n",
    "        diagonal_groups_exp[diag]['round'] = 1e9\n",
    "        if len(diagonal_groups_exp[diag]) == 0:\n",
    "            del diagonal_groups_exp[diag]\n",
    "\n",
    "    fig_phases = go.Figure()\n",
    "    for diag in list(diagonal_groups_exp.keys())[:-1]:\n",
    "        fig_phases.add_trace(go.Scatter(x = diagonal_groups_exp[diag]['exp'], y = diagonal_groups_exp[diag]['con'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 4.5, color = 'rgba(120,120,120,0.65)')))\n",
    "    colornum = 0\n",
    "    for diag in diagonal_groups:\n",
    "        fig_phases.add_trace(go.Scatter(x = diagonal_groups[diag]['exp'], y = diagonal_groups[diag]['con'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 4.5, color = current_colorscale[colornum])))\n",
    "        colornum +=1\n",
    "    fig_phases.update_layout(title = '<i>m</i>='+str(mult), font=dict(family = 'Arial', size = 14), height = 220, width = 220, margin={'t':30,'l':35,'b':40,'r':10})\n",
    "    fig_phases.update_xaxes(range = [0,5.1], dtick = 1, title = 'expansion power 𝜏<sub>𝜀</sub>', gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig_phases.update_yaxes(range = [0,5.1], dtick = 1, title = 'contraction power 𝜏<sub>𝜅</sub>', gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"x\", scaleratio=1)\n",
    "    fig_phases.show()\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    for diag in list(diagonal_groups_exp.keys())[:-1]:\n",
    "        fig_add_paramlist(fig, diagonal_groups_exp[diag], group_name = str(diag), colornum = -1, normalize = True, show_CHM13 = False)\n",
    "    colornum = 0\n",
    "    for diag in list(diagonal_groups.keys())[:-1]:\n",
    "        fig_add_paramlist(fig, diagonal_groups[diag], group_name = str(diag), colorlist = current_colorscale, colornum = colornum, opacity = 0.4, normalize = True, show_CHM13 = False)\n",
    "        colornum +=1\n",
    "    for diag in list(diagonal_groups.keys())[-1:]:\n",
    "        fig_add_paramlist(fig, diagonal_groups[diag], group_name = str(diag), colorlist = current_colorscale, colornum = colornum, opacity = 0.4, normalize = True, show_CHM13 = True)\n",
    "    fig.update_xaxes(range=[0,2.01], tickvals = [1,2,5,10,20,50,100])\n",
    "    fig.update_layout(font=dict(family = 'Arial', size = 14), height = 250, width = 520, margin={'t':30,'l':60,'b':40,'r':10}, showlegend = False)\n",
    "    fig.show()\n",
    "    \n",
    "    fig_phases.write_image('plots/figS5a_mult'+str(mult)+'.pdf')\n",
    "    fig.write_image('plots/figS5b_mult'+str(mult)+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f96c33-63e4-460a-adf2-e847e8805462",
   "metadata": {},
   "source": [
    "## flux plots for analytics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b4e95-6200-4ed5-bdae-cd27e6450216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for Fig. 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ad2a5-cad0-47ca-b900-be604b4c476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flux_combinations(comb_list, mult = 4, separate = False, show_plot = True, showlegend = True, write = False, cut_at_n1 = False, norm = True, legend_size = False, A_bins = 200):\n",
    "    for parameters in comb_list:\n",
    "        input_df_B = pd.read_pickle(folder + 'Bdist_A_bins200_sp1e0_prospeedup_mult_L9_x'+str(float(mult))+'_extend_pl_'+str(float(parameters[0]))+'_'+str(float(parameters[1]))+'_subonlystart.pickle')\n",
    "        fig_flux, last_int_bin = plot_relative_processes(mult,parameters[0],parameters[1], [inference_grid_final[mult][parameters[0]][parameters[1]], input_df_B[input_df_B.columns.max()]], norm=norm, separate=separate, cut_at_n1=cut_at_n1, A_bins=A_bins)\n",
    "        if cut_at_n1 == False:\n",
    "            fig_flux.update_xaxes(range = [0.5, 99])\n",
    "        fig_flux.update_xaxes(dtick = 10)\n",
    "        fig_flux.update_layout(font=dict(family = 'Arial', size = 12), title = str((mult,parameters[0],parameters[1])), height = 210, width = 550, margin={'t':60,'l':60,'b':40,'r':10}, showlegend = showlegend)\n",
    "        if legend_size == True:\n",
    "            fig_flux.update_layout(font=dict(family = 'Arial', size = 12), title = str((mult,parameters[0],parameters[1])), height = 500, width = 500, margin={'t':60,'l':60,'b':40,'r':10}, showlegend = showlegend)\n",
    "        if cut_at_n1 == True:\n",
    "            if last_int_bin > 10:\n",
    "                fig_flux.update_layout(width = 80 + 7*last_int_bin)\n",
    "            else:\n",
    "                fig_flux.update_xaxes(dtick = 50)\n",
    "        if show_plot == True:\n",
    "            fig_flux.show()\n",
    "        if write != False:\n",
    "            if separate == False:\n",
    "                if cut_at_n1 == 'sup':\n",
    "                    fig_flux.write_image('plots/fig_sup_flux_'+str(mult)+'_'+str(parameters[0])+'_'+str(parameters[1])+'.'+ write)\n",
    "                else:\n",
    "                    fig_flux.write_image('plots/fig_flux_'+str(mult)+'_'+str(parameters[0])+'_'+str(parameters[1])+'.'+ write)\n",
    "            else:\n",
    "                if cut_at_n1 == 'sup':\n",
    "                    fig_flux.write_image('plots/fig_sup_flux_separated'+str(mult)+'_'+str(parameters[0])+'_'+str(parameters[1])+'.'+ write)\n",
    "                else:\n",
    "                    fig_flux.write_image('plots/fig_flux_separated'+str(mult)+'_'+str(parameters[0])+'_'+str(parameters[1])+'.'+ write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da436ef9-bc05-410a-8c7b-bb1826130fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_combination_examples = [[0,3], [1,2], [1.3, 1.7], [1.5, 1.5], [2.5, 0.5]]\n",
    "plot_flux_combinations(parameter_combination_examples, mult = 8, showlegend = False, separate = False, cut_at_n1=True, A_bins=200, write = 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582fa68-8186-4c0c-98bf-8de9a98858fb",
   "metadata": {},
   "source": [
    "#### additional plots for Supplemental Note 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd52ff5-2c4e-4fb2-8aaf-938009d49f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_combination_examples = [[0,3], [0.5,2.5], [0.8,2.2], [1,2], [1.1,1.9], [1.2,1.8], [1.3, 1.7], [1.4,1.6], [1.5, 1.5], [2.5, 0.5]]\n",
    "plot_flux_combinations(parameter_combination_examples, mult = 8, showlegend = False, separate = False, cut_at_n1='sup', A_bins=200, write = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd451b9-e676-4908-a0e0-740194fe7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_combination_examples = [[0,3], [0.5,2.5], [0.8,2.2], [1,2], [1.1,1.9], [1.2,1.8], [1.3, 1.7], [1.4,1.6], [1.5, 1.5], [2.5, 0.5]]\n",
    "plot_flux_combinations(parameter_combination_examples, mult = 8, showlegend = False, separate = True, cut_at_n1='sup', A_bins=200, write = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f30941-c8d4-4bf2-8bfe-dc87b4fbc774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_net_flux_lineplot(comb_list, mult = 8, show_plot = True, show_sum = False, show_legend = True, write = False):\n",
    "    for parameters in comb_list:\n",
    "        input_df_B = pd.read_pickle(folder + 'Bdist_A_bins200_sp1e0_prospeedup_mult_L9_x'+str(float(mult))+'_extend_pl_'+str(float(parameters[0]))+'_'+str(float(parameters[1]))+'_subonlystart.pickle')\n",
    "\n",
    "        data = plot_relative_processes(mult,parameters[0],parameters[1], [inference_grid_final[mult][parameters[0]][parameters[1]], input_df_B[input_df_B.columns.max()]], A_bins=200, norm = False, returndata = 'sum')\n",
    "        data_ins = plot_relative_processes(mult,parameters[0],parameters[1], [inference_grid_final[mult][parameters[0]][parameters[1]], input_df_B[input_df_B.columns.max()]], A_bins=200, norm = False, returndata = 'in')\n",
    "        data_outs = plot_relative_processes(mult,parameters[0],parameters[1], [inference_grid_final[mult][parameters[0]][parameters[1]], input_df_B[input_df_B.columns.max()]], A_bins=200, norm = False, returndata = 'out')\n",
    "        Lmax = (inference_grid_final[mult][parameters[0]][parameters[1]] >= 1).idxmin()\n",
    "        if Lmax < 10:\n",
    "            Lmax = 200\n",
    "        \n",
    "        components_fission_in = data_ins.loc['substitution fission'] + data_ins.loc['non-motif insertion fission']\n",
    "        components_fission_out = data_outs.loc['substitution fission'] + data_outs.loc['non-motif insertion fission']\n",
    "        \n",
    "        local_terms = data_ins.loc['expansion +1'] + data_ins.loc['contraction -1'] + (data_outs.loc['expansion +1'] + data_outs.loc['contraction -1'])\n",
    "        local_terms_wsub = data_ins.loc['expansion +1'] + data_ins.loc['contraction -1'] + data_ins.loc['substitution +1'] + data_ins.loc['substitution -1'] + (data_outs.loc['expansion +1'] + data_outs.loc['contraction -1'] + data_outs.loc['substitution +1'] + data_outs.loc['substitution -1'])\n",
    "        local_subonly = data_ins.loc['substitution +1'] + data_ins.loc['substitution -1'] + (data_outs.loc['substitution +1'] + data_outs.loc['substitution -1'])\n",
    "        all_subonly = data_ins.loc['substitution +1'] + data_ins.loc['substitution -1'] + data_ins.loc['substitution fission'] + data_ins.loc['substitution fusion'] + (data_outs.loc['substitution +1'] + data_outs.loc['substitution -1'] + data_outs.loc['substitution fission'] + data_outs.loc['substitution fusion'])\n",
    "        local_plus_fission_out = local_terms + components_fission_out\n",
    "        local_plus_fission_all = local_terms + components_fission_in + components_fission_out\n",
    "        all_terms = (data_ins + data_outs).sum()\n",
    "        \n",
    "        fig_components = go.Figure()\n",
    "        fig_components.add_trace(go.Scatter(x = all_terms.index[:Lmax], y = all_terms[:Lmax], mode = 'lines', line = dict(color = 'rgba(1,1,1,0.8)', width = 3), name = 'computational model: all terms'))\n",
    "        fig_components.add_trace(go.Scatter(x = local_terms.index[:Lmax], y = local_terms[:Lmax], mode = 'lines', line = dict(color = 'rgba(255,178,101,0.8)', width = 3), name = 'local terms (no fission, no fusion)'))\n",
    "        fig_components.add_trace(go.Scatter(x = local_plus_fission_out.index[:Lmax], y = local_plus_fission_out[:Lmax], mode = 'lines', line = dict(color = 'rgba(255,101,101,0.8)', width = 3), name = 'no fission in, no fusion'))\n",
    "        fig_components.add_trace(go.Scatter(x = local_plus_fission_all.index[:Lmax], y = local_plus_fission_all[:Lmax], mode = 'lines', line = dict(color = 'rgba(178,101,178,0.8)', width = 3), name = 'no fusion'))\n",
    "        fig_components.update_xaxes(title = 'repeat length (nt)')\n",
    "        yrange = max(0.05, all_terms[5:15].abs().max())\n",
    "        fig_components.update_yaxes(title = 'net flux (mut. per gen.)', range = [-yrange, yrange])\n",
    "        fig_components.update_layout(font=dict(family = 'Arial', size = 12), title = str((mult,parameters[0],parameters[1])), height = 210, width = 550, margin={'t':60,'l':60,'b':40,'r':10}, showlegend = show_legend)\n",
    "        if show_plot == True:\n",
    "            fig_components.show()\n",
    "        if show_sum == True:\n",
    "            print(all_terms.sum())\n",
    "        if write != False:\n",
    "            fig_components.write_image('plots/fig_netfluxlines_finaltimepoint_'+str(mult)+'_'+str(parameters[0])+'_'+str(parameters[1])+'.'+ write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ee8d1-7c01-4803-9657-210afb603ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_net_flux_lineplot(parameter_combination_examples, show_legend=False, write = 'pdf')\n",
    "plot_net_flux_lineplot([[0,0]], show_legend=True, write = 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1127d-b498-44f9-899e-f4ee8dc4fdcc",
   "metadata": {},
   "source": [
    "## Plotting timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41d403-b69a-490c-9f8e-898295c955fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timepoint where metric value drops below the Poisson error of the best parameter combination, if the final timepoint is also below\n",
    "timepoint_below = ((metric_inference_grid_1e9 < poisson_metric('A', 2, 1.5, 1.8, normalize=True)[1]).idxmax().mul((metric_inference_grid_1e9.loc[1e9] < poisson_metric('A', 2, 1.5, 1.8, normalize=True)[1]).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95a1fd-6420-42c8-aae2-f4b00239009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_consistent = metric_inference_grid_final.loc[metric_inference_grid_final < poisson_metric('A', 2, 1.5, 1.8, normalize=True)[1]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2992af-2628-4a48-a995-6f3befb71e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 3, shared_xaxes = True, shared_yaxes = True, subplot_titles = ['<i>m</i>=1','<i>m</i>=2','<i>m</i>=4', '<i>m</i>=8','<i>m</i>=16','<i>m</i>=32'], vertical_spacing = 0.12, horizontal_spacing = 0.05, row_heights = [0.52, 0.48], x_title = 'expansion power 𝜏<sub>𝜀</sub>', y_title = 'contraction power 𝜏<sub>𝜅</sub>')\n",
    "col_count = 0\n",
    "for mult in [1,2,4]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = all_consistent[mult].dropna().index.get_level_values(0), y = all_consistent[mult].dropna().index.get_level_values(1), z=[1]*len(all_consistent[mult].dropna().index), coloraxis='coloraxis2', hoverongaps=False, showlegend = False), row = 1, col = col_count)\n",
    "    fig.add_trace(go.Heatmap(x = timepoint_below[mult].dropna().index.get_level_values(0), y = timepoint_below[mult].dropna().index.get_level_values(1), z=timepoint_below[mult].replace(0, np.nan), coloraxis='coloraxis1', hoverongaps=False), row = 1, col = col_count)\n",
    "col_count = 0\n",
    "for mult in [8,16,32]:\n",
    "    col_count +=1\n",
    "    fig.add_trace(go.Heatmap(x = all_consistent[mult].dropna().index.get_level_values(0), y = all_consistent[mult].dropna().index.get_level_values(1), z=[1]*len(all_consistent[mult].dropna().index), coloraxis='coloraxis2', hoverongaps=False, showlegend = False), row = 2, col = col_count)\n",
    "    fig.add_trace(go.Heatmap(x = timepoint_below[mult].dropna().index.get_level_values(0), y = timepoint_below[mult].dropna().index.get_level_values(1), z=timepoint_below[mult].replace(0, np.nan), coloraxis='coloraxis1', hoverongaps=False), row = 2, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='sunset_r', cmin = 0, cmax = 1e8, colorbar = dict(title = 'generation', len=1)))\n",
    "fig.update_layout(coloraxis2=dict(colorscale='greys', cmin = 0, cmax = 5, colorbar = dict(title = 'generation', len=1), showscale = False))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 580, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_xaxes(range = [0,5], dtick = 2, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_yaxes(range = [0,5], dtick = 2, row = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_yaxes(range = [0,5], dtick = 2, row = 2, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power 𝜏<sub>𝜀</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power 𝜏<sub>𝜅</sub>\"}, xshift=-30, y=0.5)\n",
    "\n",
    "fig.add_shape(type=\"rect\", x0=2.369-0.745, y0=2.879-0.53, x1=2.369+0.745, y1=2.879+0.53, line=dict(color='rgba(0,255,255,0.85)'), row = 2, col = 1)\n",
    "fig.add_shape(type=\"rect\", x0=2.369-0.745, y0=2.879-0.53, x1=2.369+0.745, y1=2.879+0.53, line=dict(color='rgba(0,255,255,0.85)'), row = 2, col = 2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e109e4-3f96-43b6-b144-4317933ededf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig2d.svg')\n",
    "fig.write_image('plots/fig2d.pdf')\n",
    "fig.write_image('plots/fig2d.png', scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc54f6-f468-4b4b-94a3-edfca26a3af2",
   "metadata": {},
   "source": [
    "## Substitution-only simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b3a64-8049-448b-aaaf-00e9b3dad3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_files_mutonly = os.listdir('simulations/subonly_output/')\n",
    "grid_files_A_mutonly = [file for file in grid_files_mutonly if file.startswith('Adist')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d6ae7-88ac-42a6-8968-d529c7c0ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_info_mutonly = pd.Series(grid_files_A_mutonly).str.split('_', expand = True)[[1,2,3,4,6]]\n",
    "parameter_info_mutonly.index = grid_files_A_mutonly\n",
    "parameter_info_mutonly[2] = parameter_info_mutonly[2].str.split('bins', expand = True)[1].astype(int)\n",
    "parameter_info_mutonly[3] = parameter_info_mutonly[3].str.split('sp1e', expand = True)[1].astype(int)\n",
    "parameter_info_mutonly[4] = parameter_info_mutonly[4].str.split('rounds1e', expand = True)[1].astype(int)\n",
    "parameter_info_mutonly[6] = parameter_info_mutonly[6].str.split('.pickle', expand = True)[0]\n",
    "parameter_info_mutonly.columns = ['motif', 'bins', 'speedup (1e)', 'rounds (1e)', 'start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72326751-6811-469d-9449-80458831d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_info_mutonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a522f-88e1-4aee-8842-64fa546b70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_info_mutonly_cols = parameter_info_mutonly.groupby(['motif', 'bins', 'speedup (1e)', 'rounds (1e)', 'start'])['bins'].count().index\n",
    "substitutions_only = dict()\n",
    "for motif, bins, speedup, rounds, start in parameter_info_mutonly_cols:\n",
    "    file = 'Adist_'+motif+'_bins'+str(bins)+'_sp1e'+str(speedup)+'_rounds1e'+str(rounds)+'_mutonly_'+start+'.pickle'\n",
    "    substitutions_only[motif] = pd.read_pickle('simulations/subonly_output/' + file)\n",
    "    substitutions_only[motif].columns = substitutions_only[motif].columns * (10**speedup)\n",
    "substitutions_only = pd.concat(substitutions_only, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd77032-b102-4fee-a323-d0035d1be0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_subonlydist = dict()\n",
    "for motif in ['A', 'AC', 'AAC', 'AAAC']:\n",
    "    starting_subonlydist[motif] = substitutions_only[motif][1e10][:100]\n",
    "starting_subonlydist = pd.concat(starting_subonlydist, axis=1)\n",
    "starting_subonlydist.index +=1\n",
    "starting_subonlydist.to_pickle('repeat_distributions/subonly_counts.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce275f-2820-4602-a3d6-fbf98159c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subonly_counts = pd.read_pickle('repeat_distributions/subonly_counts.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531eceef-fed2-47df-baa7-8b30e3788202",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mutonly = go.Figure()\n",
    "for motif in ['A', 'AC', 'AAC', 'AAAC']:\n",
    "    fig_mutonly.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index * len(motif), y = bootstrap_counts_mean[motif].loc[bootstrap_counts_mean[motif] >=1] / bootstrap_counts_mean[motif].loc[bootstrap_counts_mean[motif] >=1].sum(), opacity = 0.6, mode = 'lines', line = dict(width = 3), legendgroup = motif, name = motif))\n",
    "for motif in ['A', 'AC', 'AAC', 'AAAC']:\n",
    "    fig_mutonly.add_trace(go.Scatter(x = random_counts['A'][motif].index * len(motif), y = random_counts['A'][motif].loc[random_counts['A'][motif] >=1] / random_counts['A'][motif].loc[random_counts['A'][motif] >=1].sum(), opacity = 0.75, mode = 'lines', line = dict(dash = 'dot', width = 3), legendgroup = motif, name = 'shuffled'))\n",
    "for motif in ['A', 'AC', 'AAC', 'AAAC']:\n",
    "    sub_only = substitutions_only[motif][1e9]\n",
    "    sub_only.index +=1\n",
    "    sub_only = sub_only.loc[sub_only >=1]\n",
    "    fig_mutonly.add_trace(go.Scatter(x = (sub_only.index) * len(motif), y = sub_only / sub_only.sum(), opacity = 0.5, mode = 'lines', line = dict(dash = 'dash', width = 3), legendgroup = motif, name = 'substitutions only'))\n",
    "fig_mutonly.update_yaxes(type = 'log', title = 'frequency', range = [-9.05,0], tickformat = '1.0e', dtick = 2, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_mutonly.update_xaxes(type = 'log', title = 'repeat length (nt)', range = [0,2.2], tickvals = [1,2,5,10,20,50,100], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_mutonly.update_layout(font=dict(family = 'Arial', size = 14), height = 360, width = 700, margin={'t':20,'l':55,'b':35,'r':20}, colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:4])\n",
    "\n",
    "fig_mutonly.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b5851-f89e-4b7b-aa09-cad2cab8d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mutonly.write_image('plots/figS7.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
