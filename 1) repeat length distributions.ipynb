{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6afbe9-ffff-40f0-b008-3313cf160c9d",
   "metadata": {},
   "source": [
    "# Supplemental Code\n",
    "- Inherent instability of simple DNA repeats shapes an evolutionarily stable distribution of repeat lengths \n",
    "- McGinty et al. 2025\n",
    "- Part 1 of 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3dc6a-1715-4063-8afd-8bd43f4254c1",
   "metadata": {},
   "source": [
    "## Load Python libraries and define functions\n",
    "- Links included for instructions on how to install libraries using pip or conda (if libraries not included with conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2a275-c34c-4249-a230-ac95de1d4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import gzip\n",
    "from zipfile import ZipFile\n",
    "import regex as re     # https://pypi.org/project/regex/\n",
    "import fastapy_custom as fastapy    # based on https://github.com/aziele/fastapy, with a line of custom code added\n",
    "import gc\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Manager\n",
    "manager = Manager()\n",
    "\n",
    "import kaleido    # https://github.com/plotly/Kaleido    # for image export: conda install python-kaleido==0.1.0\n",
    "import plotly     # https://plotly.com/python/getting-started/\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "pio.templates.default = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e2256-7a2b-4955-8cab-eaff6ca2c686",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6c16c-e12d-4d6a-83c3-0414fe7a0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = ['A', 'T', 'G', 'C']\n",
    "def reverse_complement(dna):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return ''.join([complement[base] for base in dna[::-1]]) \n",
    "def repeat_frames_RC(input_seq):\n",
    "    return list(pd.Series([''.join(input_seq*2)[i:len(input_seq)+i] for i in range(len(input_seq))] + [reverse_complement(seq) for seq in [''.join(input_seq*2)[i:len(input_seq)+i] for i in range(len(input_seq))]]).sort_values().drop_duplicates())\n",
    "def repeat_frames_noRC(input_seq):\n",
    "    return list(pd.Series([''.join(input_seq*2)[i:len(input_seq)+i] for i in range(len(input_seq))]).sort_values().drop_duplicates())\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "repeats_1_4 = ['A', 'C', 'AC', 'AT', 'AG', 'CG', 'AAT', 'AAG', 'AAC', 'ATC', 'ACT', 'AGG', 'AGC', 'ACG', 'ACC', 'CCG', 'AAAT', 'AAAG', 'AAAC', 'AATG', 'AATC', 'AAGT', 'AAGG', 'AAGC', 'AACT', 'AACG', 'AACC', 'AGAT', 'ACAT', 'ATCC', 'ACAG', 'ACTC', 'ACTG', 'ACCT', 'AGGG', 'AGGC', 'AGCC', 'ACGG', 'ACGC', 'ACCG', 'ACCC', 'AGCG', 'CCCG', 'AATT', 'ATGC', 'ATCG', 'AGCT', 'ACGT', 'CCGG']\n",
    "repeats_1_3 = ['A', 'C', 'AC', 'AT', 'AG', 'CG', 'AAT', 'AAG', 'AAC', 'ATC', 'ACT', 'AGG', 'AGC', 'ACG', 'ACC', 'CCG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988a944-c9a8-402e-ab67-93b1d4db1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dist_1_9(seq, trim = True, pool=True, shuffle = False):\n",
    "    find_multi = r'([ATGC]{1,9}?)\\1+'; find_multi = re.compile(find_multi)\n",
    "    find_ind = r'([ATGC]{1,9}?)\\1{1,}'; find_ind = re.compile(find_ind)\n",
    "    find_L1 = dict()\n",
    "    find_L1[1] = r'([ATGC]{1})\\1{0}(?!\\1)'; find_L1[1] = re.compile(find_L1[1])\n",
    "    find_L1[2] = r'([ATGC]{2})\\1{0}(?!\\1)'; find_L1[2] = re.compile(find_L1[2])\n",
    "    find_L1[3] = r'([ATGC]{3})\\1{0}(?!\\1)'; find_L1[3] = re.compile(find_L1[3])\n",
    "    find_L1[4] = r'([ATGC]{4})\\1{0}(?!\\1)'; find_L1[4] = re.compile(find_L1[4])\n",
    "    find_L1[5] = r'([ATGC]{5})\\1{0}(?!\\1)'; find_L1[5] = re.compile(find_L1[5])\n",
    "    find_L1[6] = r'([ATGC]{6})\\1{0}(?!\\1)'; find_L1[6] = re.compile(find_L1[6])\n",
    "    find_L1[7] = r'([ATGC]{7})\\1{0}(?!\\1)'; find_L1[7] = re.compile(find_L1[7])\n",
    "    find_L1[8] = r'([ATGC]{8})\\1{0}(?!\\1)'; find_L1[8] = re.compile(find_L1[8])\n",
    "    find_L1[9] = r'([ATGC]{9})\\1{0}(?!\\1)'; find_L1[9] = re.compile(find_L1[9])\n",
    "\n",
    "    def count_L1(unit, seq, out):\n",
    "        out[unit] = pd.Series([m.group() for m in re.finditer(find_L1[unit], seq)]).value_counts()\n",
    "\n",
    "    seq = seq.upper()\n",
    "    if shuffle == True:\n",
    "        seq = ''.join(random.sample(seq, len(seq)))\n",
    "    \n",
    "    if pool == True:\n",
    "        L1 = manager.dict()\n",
    "        job = [Process(target=count_L1, args=(unit, seq, L1)) for unit in range(1,10)]\n",
    "        _ = [p.start() for p in job]\n",
    "        _ = [p.join() for p in job]\n",
    "        _ = [p.close() for p in job]\n",
    "        \n",
    "        L1 = pd.concat(dict(L1)).reset_index()\n",
    "        L1.columns = ['unit_len', 'motif', 'count']\n",
    "        L1['length'] = 1\n",
    "    else:\n",
    "        L1 = dict()\n",
    "        for unit in range(1,10):\n",
    "            count_L1(unit, seq, L1)\n",
    "        L1 = pd.concat(L1).reset_index()\n",
    "        L1.columns = ['unit_len', 'motif', 'count']\n",
    "        L1['length'] = 1\n",
    "        \n",
    "    \n",
    "    multi = pd.Series([m.group() for m in re.finditer(find_multi, seq, overlapped=True)]).value_counts().reset_index()\n",
    "    multi['motif'] = [re.split(find_ind, ind)[1] for ind in multi['index']]\n",
    "    multi['unit_len'] = multi['motif'].str.len()\n",
    "    multi['length'] = [index.count(motif) for index, motif in zip(multi['index'], multi['motif'])]\n",
    "    \n",
    "    counts = pd.concat([L1, multi])\n",
    "    counts['motif_RC'] = [repeat_frames_RC(motif)[0] for motif in counts['motif']]\n",
    "    counts = counts.groupby(['unit_len', 'motif_RC', 'length'])['count'].sum().unstack().transpose().sort_index(axis=0).fillna(0)\n",
    "    counts  = counts.sub(counts.shift(-1), fill_value = 0)\n",
    "    if trim == True:\n",
    "        counts = counts.transpose().loc[counts.transpose()[2] > 0].transpose()\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6368674-387c-4b2f-b0d9-c6f8904d53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be run per motif\n",
    "def make_B_dist(seq, motif, out):\n",
    "    B_dist = dict()\n",
    "    for frame in repeat_frames_RC(motif):\n",
    "        find_B = '(?:(?!' + frame + ')[ATGC])+'\n",
    "        current = pd.DataFrame([m.span() for m in re.finditer(find_B, seq)])\n",
    "        current = current[1] - current[0] - (len(motif)-1)\n",
    "        B_dist[frame] = current.value_counts()\n",
    "    B_dist = pd.concat(B_dist, axis=1).fillna(0).sort_index().sum(axis=1)\n",
    "    out[motif] = B_dist\n",
    "#    return B_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebc1d4-40d3-412e-b54c-1232753fa7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_genome(genome_file, genomes_path = 'genomes/', output_path = 'repeat_distributions/', output_name = False, shuffle = False, B_dist = None, zip_file = None, pool=True):\n",
    "    genome_counts = dict(); B_genome_counts = dict()\n",
    "\n",
    "    if zip_file is not None:\n",
    "        records = list(fastapy.parse(genomes_path+zip_file, inner_filename = genome_file))\n",
    "        if output_name == False:\n",
    "            output_name = genome_file.split('/')[-1][:-4]\n",
    "    else:\n",
    "        records = list(fastapy.parse(genomes_path+genome_file))\n",
    "        if output_name == False:\n",
    "            output_name = genome_file[:-3]\n",
    "    record_len = pd.Series([len(rec) for rec in records])\n",
    "    complete_nt = 0; record_sum = record_len.sum()\n",
    "    short_records = pd.Series(records).reindex(record_len.loc[record_len < 10000].index)\n",
    "    records = pd.Series(records).reindex(record_len.loc[record_len >= 10000].index).to_list()\n",
    "    for record in records:\n",
    "        current_record = record.seq.upper()\n",
    "        if shuffle == True:\n",
    "            current_record = ''.join(random.sample(current_record, len(current_record)))            \n",
    "        genome_counts[record.id] = make_dist_1_9(current_record, pool=pool)\n",
    "        if B_dist is not None:\n",
    "            B_dist_current = manager.dict()\n",
    "            job = [Process(target=make_B_dist, args=(current_record, motif, B_dist_current)) for motif in B_dist]\n",
    "            _ = [p.start() for p in job]\n",
    "            _ = [p.join() for p in job]\n",
    "            _ = [p.close() for p in job]\n",
    "            B_genome_counts[record.id] = pd.concat(dict(B_dist_current), axis=1).fillna(0).astype(int).T.sort_index().T\n",
    "            B_genome_counts[record.id].columns.name = 'motif_RC'\n",
    "        complete_nt += len(record)\n",
    "        print('\\r' + 'finished ' + str(round((complete_nt* 100)/record_sum, 2))+ '%', end = '         ')\n",
    "    genome_counts = pd.concat(genome_counts, axis=1).T.groupby(['unit_len', 'motif_RC']).sum().T\n",
    "    if B_dist is not None:\n",
    "        B_genome_counts = pd.concat(B_genome_counts, axis=1).T.groupby(['motif_RC']).sum().T\n",
    "    if len(short_records) > 0:\n",
    "        short_seq = 'N'.join([seq.seq for seq in short_records]).upper()\n",
    "        genome_counts_sub10k = make_dist_1_9(short_seq)\n",
    "        genome_counts_all = dict()\n",
    "        genome_counts_all['long'] = genome_counts\n",
    "        genome_counts_all['short'] = genome_counts_sub10k\n",
    "        genome_counts_all = pd.concat(genome_counts_all)\n",
    "        genome_counts_all.to_pickle(output_path+output_name+'.pickle')\n",
    "        if B_dist is not None:\n",
    "            B_dist_current = manager.dict()\n",
    "            job = [Process(target=make_B_dist, args=(short_seq, motif, B_dist_current)) for motif in B_dist]\n",
    "            _ = [p.start() for p in job]\n",
    "            _ = [p.join() for p in job]\n",
    "            _ = [p.close() for p in job]\n",
    "            B_genome_counts_sub10k = pd.concat(dict(B_dist_current), axis=1).fillna(0).astype(int).T.sort_index().T\n",
    "            B_genome_counts_sub10k.columns.name = 'motif_RC'\n",
    "            B_genome_counts_sub10k = pd.concat(B_genome_counts[record.id], axis=1)\n",
    "            B_genome_counts_all = dict()\n",
    "            B_genome_counts_all['long'] = B_genome_counts\n",
    "            B_genome_counts_all['short'] = B_genome_counts_sub10k\n",
    "            B_genome_counts_all = pd.concat(B_genome_counts_all)\n",
    "            B_genome_counts_all.to_pickle(output_path+output_name+'_Bdist.pickle')\n",
    "\n",
    "        complete_nt += len(short_seq)\n",
    "        print('\\r' + 'finished ' + str(round((complete_nt* 100)/record_sum, 2))+ '%', end = '         ')\n",
    "    else:\n",
    "        genome_counts.to_pickle(output_path+output_name+'.pickle')\n",
    "        B_genome_counts.to_pickle(output_path+output_name+'_Bdist.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9260fd9-98c0-4af1-8acd-fffc06807902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dist_1_6(seq, name, out, pool=True, shuffle = False):\n",
    "    find_multi = r'([ATGC]{1,6}?)\\1+'; find_multi = re.compile(find_multi)\n",
    "    find_ind = r'([ATGC]{1,6}?)\\1{1,}'; find_ind = re.compile(find_ind)\n",
    "    find_L1 = dict()\n",
    "    find_L1[1] = r'([ATGC]{1})\\1{0}(?!\\1)'; find_L1[1] = re.compile(find_L1[1])\n",
    "    find_L1[2] = r'([ATGC]{2})\\1{0}(?!\\1)'; find_L1[2] = re.compile(find_L1[2])\n",
    "    find_L1[3] = r'([ATGC]{3})\\1{0}(?!\\1)'; find_L1[3] = re.compile(find_L1[3])\n",
    "    find_L1[4] = r'([ATGC]{4})\\1{0}(?!\\1)'; find_L1[4] = re.compile(find_L1[4])\n",
    "    find_L1[5] = r'([ATGC]{5})\\1{0}(?!\\1)'; find_L1[5] = re.compile(find_L1[5])\n",
    "    find_L1[6] = r'([ATGC]{6})\\1{0}(?!\\1)'; find_L1[6] = re.compile(find_L1[6])\n",
    "    \n",
    "    def count_L1(unit, seq, out):\n",
    "        out[unit] = pd.Series([m.group() for m in re.finditer(find_L1[unit], seq)]).value_counts()\n",
    "\n",
    "    seq = seq.upper()\n",
    "    if shuffle == True:\n",
    "        seq = ''.join(random.sample(seq, len(seq)))\n",
    "    \n",
    "    if pool == True:\n",
    "        L1 = manager.dict()\n",
    "        job = [Process(target=count_L1, args=(unit, seq, L1)) for unit in range(1,7)]\n",
    "        _ = [p.start() for p in job]\n",
    "        _ = [p.join() for p in job]\n",
    "        _ = [p.close() for p in job]\n",
    "        \n",
    "        L1 = pd.concat(dict(L1)).reset_index()\n",
    "        L1.columns = ['unit_len', 'motif', 'count']\n",
    "        L1['length'] = 1\n",
    "    else:\n",
    "        L1 = dict()\n",
    "        for unit in range(1,7):\n",
    "            count_L1(unit, seq, L1)\n",
    "        L1 = pd.concat(L1).reset_index()\n",
    "        L1.columns = ['unit_len', 'motif', 'count']\n",
    "        L1['length'] = 1\n",
    "        \n",
    "    \n",
    "    multi = pd.Series([m.group() for m in re.finditer(find_multi, seq, overlapped=True)]).value_counts().reset_index()\n",
    "    multi['motif'] = [re.split(find_ind, ind)[1] for ind in multi['index']]\n",
    "    multi['unit_len'] = multi['motif'].str.len()\n",
    "    multi['length'] = [index.count(motif) for index, motif in zip(multi['index'], multi['motif'])]\n",
    "    \n",
    "    counts = pd.concat([L1, multi])\n",
    "    counts['motif_RC'] = [repeat_frames_RC(motif)[0] for motif in counts['motif']]\n",
    "    counts = counts.groupby(['unit_len', 'motif_RC', 'length'])['count'].sum().unstack().transpose().sort_index(axis=0).fillna(0).astype(int)\n",
    "    counts  = counts.sub(counts.shift(-1), fill_value = 0)\n",
    "\n",
    "    out[name] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7572bf-e8aa-4e83-97b8-54bea03f807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_genome_1_6(genome_file, genomes_path = 'genomes/', output_path = 'repeat_distributions/', output_name = False, shuffle = False, B_dist = None, zip_file = None, pool=True):\n",
    "    genome_counts = dict(); B_genome_counts = dict()\n",
    "\n",
    "    if zip_file is not None:\n",
    "        records = list(fastapy.parse(genomes_path+zip_file, inner_filename = genome_file))\n",
    "        if output_name == False:\n",
    "            output_name = genome_file.split('/')[-1][:-4]\n",
    "    else:\n",
    "        records = list(fastapy.parse(genomes_path+genome_file))\n",
    "        if output_name == False:\n",
    "            output_name = genome_file[:-3]\n",
    "    record_len = pd.Series([len(rec) for rec in records])\n",
    "    complete_nt = 0; record_sum = record_len.sum()\n",
    "    medium_records = pd.Series(records).reindex(record_len.loc[(record_len < 1000000) & (record_len >= 10000)].index)\n",
    "    # skip short contigs (<10kb)\n",
    "    records = pd.Series(records).reindex(record_len.loc[record_len >= 1000000].index).to_list()\n",
    "    \n",
    "    genome_counts = manager.dict()\n",
    "    job = [Process(target=make_dist_1_6, args=(record.seq, record.id, genome_counts, False, shuffle)) for record in records]\n",
    "    _ = [p.start() for p in job]\n",
    "    _ = [p.join() for p in job]\n",
    "    _ = [p.close() for p in job]\n",
    "\n",
    "    if len(medium_records) > 0:\n",
    "        short_seq = 'N'.join([seq.seq for seq in medium_records]).upper()\n",
    "        make_dist_1_6(short_seq, 'medium', genome_counts, shuffle = shuffle)\n",
    "\n",
    "    genome_counts = pd.concat(dict(genome_counts), axis=1).T.groupby(['unit_len', 'motif_RC']).sum().T.astype(int)\n",
    "    genome_counts = genome_counts.where(genome_counts>1).dropna(how = 'all').fillna(0).astype(int)\n",
    "\n",
    "    genome_counts.to_pickle(output_path+output_name+'.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54dfb9b-e11c-4484-ba9d-5653ea5e447e",
   "metadata": {},
   "source": [
    "# Generate repeat length distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f35ff-ced6-4beb-91d7-f833b72edbd8",
   "metadata": {},
   "source": [
    "## T2T-CHM13 genome\n",
    "- T2T v2.0 Fasta file\n",
    "- download \"hs1.fa.gz\" from http://hgdownload.soe.ucsc.edu/goldenPath/hs1/bigZips/\n",
    "- also available from https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_009914755.1/\n",
    "- Fasta file can remain compressed\n",
    "- for demo purposes, any smaller Fasta file could be substituted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed317b-01f3-40be-8f5f-6bbc97835828",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_genome('hs1.fa.gz', output_name = 'CHM13_counts', B_dist = repeats_1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45755a-b857-46ea-a196-8f2a42e3390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled genome distribution\n",
    "count_genome('hs1.fa.gz', output_name = 'random_counts', shuffle = True, B_dist = repeats_1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2693ff63-cf02-438d-8178-95eb20c7ba3f",
   "metadata": {},
   "source": [
    "### CHM13 repeat length distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f034aba-de5c-4a3e-8b8d-07279afd3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHM13_counts = pd.read_pickle('repeat_distributions/CHM13_counts.pickle').sort_index()\n",
    "CHM13_counts_B = pd.read_pickle('repeat_distributions/CHM13_counts_Bdist.pickle')\n",
    "random_counts = pd.read_pickle('repeat_distributions/random_counts.pickle').sort_index() # still old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf0668-65bc-4072-9b92-13d3002fd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHM13_counts_byunit = CHM13_counts.T.groupby(['unit_len']).sum().transpose()\n",
    "\n",
    "CHM13_counts_byunit_nocentel = CHM13_counts_byunit.copy()\n",
    "CHM13_counts_byunit_nocentel[5] = CHM13_counts_byunit[5] - CHM13_counts[5]['AATGG']\n",
    "CHM13_counts_byunit_nocentel[6] = CHM13_counts_byunit[6] - CHM13_counts[6]['AACCCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae0876-5708-43fd-938c-42e0b9f2564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_counts_byunit = random_counts.T.groupby(['unit_len']).sum().transpose()\n",
    "\n",
    "random_counts_byunit_nocentel = random_counts_byunit.copy()\n",
    "random_counts_byunit_nocentel[5] = random_counts_byunit[5] - random_counts[5]['AATGG']\n",
    "random_counts_byunit_nocentel[6] = random_counts_byunit[6] - random_counts[6]['AACCCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc4077-461c-468a-beea-6057333668fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S1a (by nt)\n",
    "fig_starting_counts = go.Figure()\n",
    "legendnames = []\n",
    "for unit in range(1,5):\n",
    "    for motif in CHM13_counts[unit].columns:\n",
    "        fig_starting_counts.add_trace(go.Scatter(x = CHM13_counts[unit][motif].index * len(motif), y = CHM13_counts[unit][motif].replace(0, np.nan), name = 'unit length = '+str(len(motif)), text = motif, legendgroup = len(motif), showlegend = False if len(motif) in legendnames else True, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[len(motif)-1]), mode = 'lines', opacity = 0.95/(1+0.5*len(motif))))\n",
    "        legendnames.append(len(motif))\n",
    "fig_starting_counts.update_xaxes(type = 'log', title = 'repeat tract length (nt)', range = [0,2.1], tickvals = [1,2,5,10,20,50,100], gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "fig_starting_counts.update_yaxes(type = 'log', title = 'counts', tickformat = '1.0e', dtick = 2, range = [0,10], gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "fig_starting_counts.update_layout(font=dict(family = 'Arial', size = 14), legend = dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=1.2), height = 300, width = 580, margin={'t':40,'l':80,'b':40,'r':60}, )   \n",
    "fig_starting_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482207c-d79d-4e3d-9c7c-3dc2a7985aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_starting_counts.write_image('plots/figS1a.svg')\n",
    "fig_starting_counts.write_image('plots/figS1a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62fe1d-adfd-4e5c-876e-0b77888a69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 1a\n",
    "fig_starting_counts = go.Figure()\n",
    "for i in range(1,7):\n",
    "    fig_starting_counts.add_trace(go.Scatter(x = CHM13_counts_byunit.index * i, y = CHM13_counts_byunit[i].replace(0,np.nan), connectgaps = True, name = str(i), line = dict(width = 4), mode = 'lines', opacity = 0.75))\n",
    "for i in range(1,7):\n",
    "    fig_starting_counts.add_trace(go.Scatter(x = random_counts_byunit.index * i, y = random_counts_byunit[i].replace(0,np.nan), connectgaps = True, showlegend = False, name = 'random, unit length = '+str(i), line = dict(width = 3, dash = '5'), mode = 'lines', opacity = 0.55))\n",
    "\n",
    "fig_starting_counts.update_xaxes(type = 'log', title = 'repeat tract length (nt)', range = [0,3.2], tickvals = [1,2,5,10,20,50,100,300,1000], gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "fig_starting_counts.update_yaxes(type = 'log', title = 'counts', tickformat = '1.0e', dtick = 2, gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "fig_starting_counts.update_layout(font=dict(family = 'Arial', size = 16), legend = dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99, title = 'unit length'), height = 300, width = 500, margin={'t':40,'l':80,'b':40,'r':10}, colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:6])\n",
    "fig_starting_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30229b0-b894-48cc-b1b1-f004973fbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_starting_counts.write_image('plots/fig1a.svg')\n",
    "fig_starting_counts.write_image('plots/fig1a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab797e-8caf-4027-911c-235711eb98ca",
   "metadata": {},
   "source": [
    "### bootstrap counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef3b963-886b-45ed-96d7-6293f315818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dist_1_3_boot(seq, out, name, chunk_size = 1000000, trim = True):\n",
    "    if len(seq) == chunk_size:\n",
    "        find_multi = r'([ATGC]{1,3}?)\\1+'; find_multi = re.compile(find_multi)\n",
    "        find_ind = r'([ATGC]{1,3}?)\\1{1,}'; find_ind = re.compile(find_ind)\n",
    "        find_L1 = dict()\n",
    "        find_L1[1] = r'([ATGC]{1})\\1{0}(?!\\1)'; find_L1[1] = re.compile(find_L1[1])\n",
    "        find_L1[2] = r'([ATGC]{2})\\1{0}(?!\\1)'; find_L1[2] = re.compile(find_L1[2])\n",
    "        find_L1[3] = r'([ATGC]{3})\\1{0}(?!\\1)'; find_L1[3] = re.compile(find_L1[3])\n",
    "        \n",
    "        def count_L1(unit, seq, out):\n",
    "            out[unit] = pd.Series([m.group() for m in re.finditer(find_L1[unit], seq)]).value_counts()\n",
    "        \n",
    "        L1 = manager.dict()\n",
    "        job = [Process(target=count_L1, args=(unit, seq, L1)) for unit in range(1,4)]\n",
    "        _ = [p.start() for p in job]\n",
    "        _ = [p.join() for p in job]\n",
    "        _ = [p.close() for p in job]\n",
    "        \n",
    "        L1 = pd.concat(dict(L1)).reset_index()\n",
    "        L1.columns = ['unit_len', 'motif', 'count']\n",
    "        L1['length'] = 1\n",
    "        \n",
    "        multi = pd.Series([m.group() for m in re.finditer(find_multi, seq, overlapped=True)]).value_counts().reset_index()\n",
    "        multi['motif'] = [re.split(find_ind, ind)[1] for ind in multi['index']]\n",
    "        multi['unit_len'] = multi['motif'].str.len()\n",
    "        multi['length'] = [index.count(motif) for index, motif in zip(multi['index'], multi['motif'])]\n",
    "        \n",
    "        counts = pd.concat([L1, multi])\n",
    "        counts['motif_RC'] = [repeat_frames_RC(motif)[0] for motif in counts['motif']]\n",
    "        counts = counts.groupby(['unit_len', 'motif_RC', 'length'])['count'].sum().unstack().transpose().sort_index(axis=0).fillna(0)\n",
    "        counts  = counts.sub(counts.shift(-1), fill_value = 0)\n",
    "        if trim == True:\n",
    "            counts = counts.transpose().loc[counts.transpose()[2] > 0].transpose()\n",
    "    \n",
    "        out[name] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6c6ef-fb89-42bf-9dd3-faf1022a33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_genome_bootstrap(genome_file, genomes_path = 'genomes/', output_path = 'repeat_distributions/', output_name = False):\n",
    "    if output_name == False:\n",
    "        output_name = genome_file[:-3]\n",
    "    records = list(fastapy.parse(genomes_path+genome_file))\n",
    "    record_len = pd.Series([len(rec) for rec in records])\n",
    "    complete_nt = 0; record_sum = record_len.sum()\n",
    "    records = pd.Series(records).reindex(record_len.loc[record_len >= 10000].index).to_list()\n",
    "\n",
    "    genome_counts = manager.dict()\n",
    "    for record in records:\n",
    "        job = [Process(target=make_dist_1_3_boot, args=(chunk, genome_counts, record.id + '_' + str(counter))) for counter, chunk in enumerate(re.findall('.{1,1000000}', record.seq.upper()))]\n",
    "        _ = [p.start() for p in job]\n",
    "        _ = [p.join() for p in job]\n",
    "        _ = [p.close() for p in job]\n",
    "    \n",
    "        complete_nt += len(record)\n",
    "        print('\\r' + 'finished ' + str(round((complete_nt* 100)/record_sum, 2))+ '%', end = '         ')\n",
    "    genome_counts = pd.concat(dict(genome_counts), axis=1).fillna(0).astype(int)\n",
    "    genome_counts.to_pickle(output_path+output_name+'_bootstrap.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a0b6c-dbba-4966-8b48-9ede1047abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_genome_bootstrap('hs1.fa.gz', output_name = 'CHM13_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dec1e2-d8c5-477b-909f-534d5f96a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_CHM13_counts = pd.read_pickle('repeat_distributions/CHM13_counts_bootstrap.pickle').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5341bde-89d0-4067-aa5a-444b80c69b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_counts = dict()\n",
    "for i in range(1000):\n",
    "    print('\\r' + str(i), end = '   ')\n",
    "    sample_ids = np.random.choice(bootstrap_CHM13_counts.columns.levels[0], 3117, replace=True)\n",
    "    bootstrap_main = bootstrap_CHM13_counts[sample_ids].T.groupby(['unit_len', 'motif_RC']).sum().T\n",
    "    remainder = np.random.choice(bootstrap_CHM13_counts.columns.levels[0], 1, replace=True)\n",
    "    remainder = bootstrap_CHM13_counts[remainder].copy()\n",
    "    remainder = (remainder * (275501 / remainder.mul(remainder.index, axis=0).sum())).round().astype(int)\n",
    "    remainder.columns = remainder.columns.droplevel(0)\n",
    "    bootstrap_counts[i] = bootstrap_main.add(remainder, fill_value = 0)\n",
    "bootstrap_counts = pd.concat(bootstrap_counts, axis=1).sort_index()\n",
    "bootstrap_counts.to_pickle('repeat_distributions/bootstrap_counts_1000.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a20795-0792-4b79-8cab-4f337f344277",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_counts = pd.read_pickle('repeat_distributions/bootstrap_counts_1000.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e0624-4581-4556-8910-aaa77a4f6491",
   "metadata": {},
   "source": [
    "## Mammalian genomes\n",
    "- download link: https://www.ncbi.nlm.nih.gov/datasets/genome/?taxon=40674&reference_only=true&typical_only=true&assembly_level=2:3&release_year=2019:2025\n",
    "- contains 344 genomes as of 6/20/2025 (including HG38 and several duplicate species)\n",
    "- retrieve two additional human genome assemblies: GCA_015074485.1_ASM1507448v1_genomic.fna, GCA_003112815.1_ASM311281v1_genomic.fna\n",
    "- leave all genomes compressed in the original zip file (i.e. from NCBI download, one file contains all genomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aecde59-7749-4103-9954-dd147f06be61",
   "metadata": {},
   "source": [
    "#### count multiple genomes downloaded from NCBI and stored in a single zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77e39d-4b23-4b2a-9c26-bff1aeb9b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: replace file paths where necessary\n",
    "genomes_path_mammals = '../../non_human_genomes/mammalian_reference_genomes/'\n",
    "output_path_mammals = 'repeat_distributions/mammalian_reference_genomes/'\n",
    "with ZipFile(genomes_path_mammals + 'ncbi_dataset.zip') as zf:\n",
    "    zip_list = [file for file in zf.namelist() if file.endswith('.fna')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df8796-7521-492e-a26e-e2fc3c52c394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for genome_file in zip_list:\n",
    "    print(str(counter) + '/'+str(len(zip_list)) + ': ' + genome_file[:-4])\n",
    "    if genome_file.split('/')[-1][:-4]+'.pickle' not in os.listdir(output_path_mammals):\n",
    "        count_genome_1_6(genome_file, genomes_path = genomes_path_mammals, output_path = output_path_mammals, zip_file = 'ncbi_dataset.zip')\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe13d4-4e81-4e32-924b-e817fba19e5d",
   "metadata": {},
   "source": [
    "## Load distributions and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2b8a8-0505-4b25-b7fc-e9c9f0db5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = [file for file in os.listdir('repeat_distributions/mammalian_reference_genomes/') if file.startswith('GC')]\n",
    "len(completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1685817-63b8-4328-aaa5-bcc7b6743ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_all = dict()\n",
    "for file in completed:\n",
    "    if file[:-15] not in counts_all.keys():\n",
    "        counts_all[file[:-15]] = pd.read_pickle('repeat_distributions/mammalian_reference_genomes/'+file).replace(0, np.nan).dropna(how = 'all')\n",
    "        if 'long' in counts_all[file[:-15]].index.get_level_values(0):\n",
    "            counts_all[file[:-15]] = counts_all[file[:-15]].loc['long']\n",
    "counts_all = pd.concat(counts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8ee57-d896-4e83-af2a-81e92d5e3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_all_info = pd.DataFrame(counts_all.index.levels[0], columns = ['filename'])\n",
    "counts_all_info['Assembly Accession'] = [str.join('_', name[:2]) for name in (counts_all.index.levels[0]).str.split('_')]\n",
    "counts_all_info['Assembly Name'] = [str.join('_', name[2:]) for name in (counts_all.index.levels[0]).str.split('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32c301-bed8-49ff-83bc-ca6ca76a8650",
   "metadata": {},
   "source": [
    "### Genome and taxonomy info\n",
    "- In my experience, some info was missing and had to be filled in. It is possible that this could differ for other users at later dates and would therefore require some adjustment of the code in this section.\n",
    "- Due to historical usage, this code combines info from two separate collections of genomes (representing 2019-2023 and 2024-(mid)2025)\n",
    "- Note: \"data_summary.tsv\" file included with download of multiple genome files from NCBI\n",
    "- Download taxonomy file from: https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/new_taxdump/new_taxdump.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603855b6-5c17-46ed-a88b-06e4bf80763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_info = pd.read_csv('repeat_distributions/mammalian_reference_genomes/data_summary.tsv', sep = '\\t')\n",
    "# Fill in some missing data\n",
    "genome_info.loc[genome_info['Organism Common Name'].isna(), 'Organism Common Name'] = ['oldfield mouse', 'Masai giraffe', 'Nubian giraffe', 'South-central black rhinoceros', 'Marco Polo sheep (hybrid)', 'Indian elephant', 'Tibetan macaque', 'Fringe-lipped bat', 'Brazilian porcupine', 'Marco Polo sheep', 'Ground cuscus', 'East African Hippopotamus', 'Intermediate roundleaf bat', 'Eastern spiny mouse']\n",
    "\n",
    "genome_info['Assembly Name'] = genome_info['Assembly Name'].str.replace(' ', '_').str.replace('+', '_')\n",
    "genome_info.loc[129, 'Assembly Name'] = 'mEubGla1.1.hap2._XY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcab279-2fff-494e-85c8-04ba28d8dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_info_2425 = pd.read_csv('repeat_distributions/mammalian_reference_genomes/data_summary_24-25.tsv', sep = '\\t')\n",
    "# Fill in some missing data\n",
    "# Note: download contains 124 genomes as of July 2025. Following line may need adjustment if number of genomes differs.\n",
    "genome_info_2425.loc[genome_info_2425['Organism Common Name'].isna(), 'Organism Common Name'] = ['Chinese zokor', 'Birdlike noctule', 'Great fruit-eating bat', 'Northern red muntjac', 'King horseshoe bat', 'Northern woolly horseshoe bat', 'Addax', 'Transbaikal zokor', \"Keenan's Hairy-nosed Bat\"]\n",
    "genome_info_2425['Assembly Name'] = genome_info_2425['Assembly Name'].str.replace(' ', '_').str.replace('+', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249b7f2-3c2c-4caf-8648-9dad404a77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_info = pd.concat([genome_info, genome_info_2425])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939b172-7c77-4a50-a839-6670a188b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_csv('repeat_distributions/mammalian_reference_genomes/NCBI_taxonomy/rankedlineage.dmp', sep = '\\t', usecols = [0,2,6,8,10,12,14,16,18], header = None, low_memory=False)\n",
    "taxonomy.columns = ['tax_id', 'tax_name', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom', 'superkingdom']\n",
    "taxonomy_present = taxonomy.set_index(['tax_id']).reindex(genome_info['Taxonomy id'])\n",
    "# fill in missing values\n",
    "taxonomy_present.loc[346063] = taxonomy_present.loc[89462].values\n",
    "taxonomy_present.loc[346063, 'tax_name'] = 'Bubalus carabanensis'\n",
    "taxonomy_present.loc[94439, 'order'] = 'Afrosoricida'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c77827-2ac8-48f6-9d96-757a14756ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_info = pd.concat([genome_info.set_index(['Taxonomy id']), taxonomy_present.drop_duplicates().reindex(genome_info['Taxonomy id'])], axis=1).reset_index()\n",
    "genome_info['filename'] = counts_all_info.set_index(['Assembly Accession']).reindex(genome_info['Assembly Accession'])['filename'].values\n",
    "genome_info = genome_info.set_index(['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00899456-c7d6-4b84-8e7c-fa6ed04fea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove older versions of genomes from same individuals\n",
    "genome_info_removedups = genome_info.sort_values(by = ['Contig N50'], ascending = False).drop_duplicates(subset = ['Organism Scientific Name', 'BioSample'], keep = 'first').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66fbff-7aa3-4449-b5e1-e1e086966ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroup_list = pd.Series(['order', 'family', 'genus', 'tax_name'], index = ['class', 'order', 'family', 'genus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4c427-9211-459e-847e-2430245eac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of mammals, primates, hominids (inclusive)"
    "len(genome_info['tax_name'].value_counts()), len(genome_info.loc[genome_info['order'] == 'Primates']['tax_name'].value_counts()), len(genome_info.loc[genome_info['family'] == 'Hominidae']['tax_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e251730a-53c1-4e4b-8871-1d1d433c3bb9",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5bd335-bbfd-4184-863c-a5497ab2e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_grouped(motif = 'A', group_list = ['class'], select_list = ['Mammalia'], x_nt = True, show = False, cutoff_n = 30, show_median = 1, norm = True, showmed = True):\n",
    "    fig_counts = go.Figure()\n",
    "    counter = 0\n",
    "    for group, select in zip(group_list, select_list):\n",
    "        current_set = genome_info_removedups.loc[genome_info_removedups[group] == select].copy()\n",
    "        current_counts = counts_all.reindex(current_set.index, level = 0)[len(motif)][motif].unstack().T.replace(0, np.nan).dropna(how = 'all', axis=1).fillna(0)\n",
    "        #current_counts.columns = list(range(len(current_counts.columns)))\n",
    "        current_counts = current_counts[current_counts >1].fillna(1,limit=1, axis=0)\n",
    "        current_counts.loc[len(current_counts)+1] = np.nan\n",
    "        for col in current_counts:\n",
    "            current_col = current_counts[col].copy()\n",
    "            current_col = current_col.reindex(list(range(1, (current_col > cutoff_n).idxmin())))\n",
    "            if norm == True:\n",
    "                current_col = current_col.div(current_col.sum())\n",
    "            fig_counts.add_trace(go.Scatter(x = current_col.index * len(motif) if x_nt == True else current_col.index, y = current_col, mode = 'lines', connectgaps = False, name = select, hovertemplate= 'L=%{x}, n=%{y}' + '<br>' + '<b>'+ current_set['Organism Common Name'].loc[col] + '</b><br>' + 'Order: ' + current_set['order'].loc[col] + '<br>' + 'Family: ' + current_set['family'].loc[col] + '<br>' + current_set['Organism Scientific Name'].loc[col] + '<br>' + \"<extra></extra>\", opacity = min(0.25, 15/len(current_set.index)), line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[counter], width = 1), legendgroup = counter, showlegend = False))\n",
    "        counter +=1\n",
    "    if showmed == True:\n",
    "        counter = 0\n",
    "        for group, select in zip(group_list, select_list):\n",
    "            current_set = genome_info_removedups.loc[genome_info_removedups[group] == select].copy()\n",
    "            current_counts = counts_all.reindex(current_set.index, level = 0)[len(motif)][motif].unstack().T.replace(0, np.nan).dropna(how = 'all', axis=1).fillna(0)\n",
    "            current_counts = current_counts.reindex(list(range(1,1001)))\n",
    "    #        current_counts = current_counts.reindex(list(range(1, current_counts.loc[current_counts>30].idxmin())))\n",
    "            if norm == True:\n",
    "                current_med = (current_counts / current_counts.sum()).median(axis=1)\n",
    "                current_med = current_med.loc[current_med > 1e-9]\n",
    "                fig_counts.add_trace(go.Scatter(x = current_med.index * len(motif) if x_nt == True else current_med.index, y = current_med, mode = 'lines', connectgaps = True, opacity = show_median, name = select, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[counter], width = 3), legendgroup = counter))\n",
    "            counter +=1\n",
    "    fig_counts.update_xaxes(type = 'log', title = 'repeat tract length (nt)' if x_nt == True else 'repeat tract length (units)', range = [0,3], gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "    fig_counts.update_yaxes(type = 'log', tickformat = '1.0e', dtick = 2, title = 'counts (normalized)' if norm == True else 'counts', gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)   \n",
    "    fig_counts.update_layout(font=dict(family = 'Arial', size = 16), height = 300, width = 500, margin={'t':40,'l':80,'b':40,'r':10})        \n",
    "    if show == True:\n",
    "        fig_counts.show()\n",
    "    return fig_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edfa290-24e5-4673-abef-771d97697a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 1b\n",
    "fig_grouped = plot_counts_grouped(cutoff_n = 30, group_list = ['class', 'order', 'family'], select_list = ['Mammalia', 'Primates', 'Hominidae'], show = False)\n",
    "fig_grouped.update_xaxes(range = [0,2.33], tickvals = [1,2,5,10,20,50,100,200])\n",
    "fig_grouped.update_layout(legend = dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcc9b6-90de-467a-a51d-2a5e5cc068f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_grouped.write_image('plots/fig1b.pdf')\n",
    "fig_grouped.write_image('plots/fig1b.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc12f20-aab6-48f8-8137-f6d8c0f0df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S2b (right)\n",
    "fig_grouped = plot_counts_grouped(cutoff_n = 30, group_list = ['class', 'order', 'family'], select_list = ['Mammalia', 'Primates', 'Hominidae'], show = False, showmed = False)\n",
    "fig_grouped.update_xaxes(range = [0,2.33], tickvals = [1,2,5,10,20,50,100,200])\n",
    "fig_grouped.update_layout(legend = dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56068e36-6ceb-4b00-969f-3f6d49cb5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_grouped.write_image('plots/figS1c1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e29dec-424f-469c-b383-39d46e5f77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S2b (left)\n",
    "fig_grouped = plot_counts_grouped(cutoff_n = 0, group_list = ['class', 'order', 'family'], select_list = ['Mammalia', 'Primates', 'Hominidae'], show = False, norm = False)\n",
    "fig_grouped.add_trace(go.Scatter(x = [1,200], y = [30,30], mode = 'lines', line = dict(dash = 'dash', color = 'black'), showlegend = False))\n",
    "fig_grouped.update_xaxes(range = [0,2.33], tickvals = [1,2,5,10,20,50,100,200])\n",
    "fig_grouped.update_layout(legend = dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4d54a-4ac8-4803-b78e-643a6b4148fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_grouped.write_image('plots/figS1c2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faafaf23-98ea-4864-bbcf-80c30d0ac138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S2a\n",
    "fig_assemblysize = go.Figure()\n",
    "fig_assemblysize.add_trace(go.Violin(x = ['all mammals']*len(genome_info['Size'].dropna()), y = genome_info['Size'].dropna(), points='all', line = dict(width = 1), opacity=1, pointpos = 0, marker = dict(size = 2), showlegend=False))\n",
    "fig_assemblysize.add_trace(go.Violin(x = ['primates']*len(genome_info.loc[genome_info['order'] == 'Primates']['Size'].dropna()), y = genome_info.loc[genome_info['order'] == 'Primates']['Size'].dropna(), points='all', line = dict(width = 1), opacity=1, pointpos = 0, marker = dict(size = 2), showlegend=False))\n",
    "fig_assemblysize.update_yaxes(title = 'assembly size (nt)', tickformat = '1.0e', dtick = 1e9)\n",
    "fig_assemblysize.update_layout(font=dict(family = 'Arial', size = 16), height = 500, width = 300, margin={'t':30,'l':80,'b':40,'r':10})        \n",
    "fig_assemblysize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e64035-fb44-4d05-a776-69dd39ad2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_assemblysize.write_image('plots/assembly_size.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fee519-8f65-4725-82f3-9f414dbbc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_grouped_multi(n_rows = 1, n_cols = 4, motif_list = repeats_1_4[:4], x_nt = True, group_list = ['class'], select_list = ['Mammalia'], chrom = 'only_CM', show = False, cutoff_n = 10\n",
    "                            , show_median = 1):\n",
    "    fig_counts = make_subplots(rows = n_rows, cols = n_cols, subplot_titles = motif_list, x_title = 'repeat tract length (nt)', y_title = 'counts (normalized)', vertical_spacing = 0.24 / n_rows, horizontal_spacing = 0.2 / n_cols, shared_xaxes = True, shared_yaxes = True)\n",
    "    row_counter = 1; col_counter = 0; legend_counter = 1\n",
    "    for motif in motif_list:\n",
    "        counter = 0; col_counter +=1\n",
    "        for group, select in zip(group_list, select_list):\n",
    "            current_set = genome_info_removedups.loc[genome_info_removedups[group] == select].copy()\n",
    "            current_counts = counts_all.reindex(current_set.index, level = 0)[len(motif)][motif].unstack().T.replace(0, np.nan).dropna(how = 'all', axis=1).fillna(0)\n",
    "            current_counts = current_counts[current_counts >1].fillna(1,limit=1, axis=0)\n",
    "            current_counts.loc[len(current_counts)+1] = np.nan\n",
    "            for col in current_counts:\n",
    "                current_col = current_counts[col].copy()\n",
    "                current_col = current_col.reindex(list(range(1, (current_col > cutoff_n).idxmin())))\n",
    "                current_col = current_col.div(current_col.sum())\n",
    "                fig_counts.add_trace(go.Scatter(x = current_col.index * len(motif) if x_nt == True else current_col.index, y = current_col, connectgaps = False, name = select, hovertemplate= 'L=%{x}, n=%{y}' + '<br>' + '<b>'+ current_set['Organism Common Name'].loc[col] + '</b><br>' + 'Order: ' + current_set['order'].loc[col] + '<br>' + 'Family: ' + current_set['family'].loc[col] + '<br>' + current_set['Organism Scientific Name'].loc[col] + '<br>' + \"<extra></extra>\", opacity = min(0.25, 15/len(current_set.index)), mode = 'lines', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[counter], width = 0.5), legendgroup = counter, showlegend = False), row = row_counter, col = col_counter)\n",
    "            counter +=1\n",
    "        legend_counter +=1\n",
    "        if col_counter == n_cols:\n",
    "            col_counter -= n_cols; row_counter +=1\n",
    "    row_counter = 1; col_counter = 0; legend_counter = 1\n",
    "    for motif in motif_list:\n",
    "        counter = 0; col_counter +=1\n",
    "        for group, select in zip(group_list, select_list):\n",
    "            current_set = genome_info_removedups.loc[genome_info_removedups[group] == select].copy()\n",
    "            current_counts = counts_all.reindex(current_set.index, level = 0)[len(motif)][motif].unstack().T.replace(0, np.nan).dropna(how = 'all', axis=1).fillna(0)\n",
    "            current_counts = current_counts.reindex(list(range(1,1001)))\n",
    "            current_med = (current_counts / current_counts.sum()).median(axis=1)\n",
    "            current_med = current_med.loc[current_med > 1e-9]\n",
    "            fig_counts.add_trace(go.Scatter(x = current_med.index * len(motif) if x_nt == True else current_med.index, y = current_med, connectgaps = True, opacity = show_median, name = select, mode = 'lines', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[counter], width = 1.5), legendgroup = counter, showlegend = False), row = row_counter, col = col_counter)\n",
    "            counter +=1\n",
    "        legend_counter +=1\n",
    "        if col_counter == n_cols:\n",
    "            col_counter -= n_cols; row_counter +=1   \n",
    "    fig_counts.update_xaxes(type = 'log', range = [0,2.5], dtick = 1, gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "    fig_counts.update_yaxes(type = 'log', range = [-10,0], tickformat = '1.0e', dtick = 3, gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "    fig_counts.update_layout(font=dict(family = 'Helvetica', size = 12), height = 180 * n_rows, width = 220 * n_cols, margin={'t':40,'l':60,'b':55,'r':30})        \n",
    "    if show == True:\n",
    "        fig_counts.show()\n",
    "    return fig_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854038e-1ed5-4442-94f5-886aec2bc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig S3 (display first line)\n",
    "fig_grouped = plot_counts_grouped_multi(group_list = ['class', 'order', 'family'], select_list = ['Mammalia', 'Primates', 'Hominidae'], show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b83864-b48f-4e4b-bece-39996db418d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig S3\n",
    "for n in range(len(repeats_1_4[::4])):\n",
    "    print(n, end = ' ')\n",
    "    current_list = repeats_1_4[n*4:n*4+4]\n",
    "    fig_grouped = plot_counts_grouped_multi(motif_list = current_list, group_list = ['class', 'order', 'family'], select_list = ['Mammalia', 'Primates', 'Hominidae'], show = False)\n",
    "    fig_grouped.update_layout(legend=dict(orientation = 'h', yanchor='bottom', y=-0.1, xanchor='right', x=1.04))\n",
    "    fig_grouped.write_image('plots/fig_S2_'+str(n)+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69200c-886a-41cd-95c5-fdf061f2551b",
   "metadata": {},
   "source": [
    "## Human genome assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f86581-a84d-4e0d-a2f1-3256fb3adb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting done above because fastas were placed in mammalian directory\n",
    "#could separately download from ncbi and get new info file instead of this\n",
    "\n",
    "# add in info for human genome assemblies\n",
    "for col in ['Organism Scientific Name', 'Taxonomy id', 'tax_name', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom', 'superkingdom']:\n",
    "    genome_info.loc['GCA_015074485.1_ASM1507448v1', col] = genome_info.loc['GCA_000001405.29_GRCh38.p14', col]\n",
    "    genome_info.loc['GCA_003112815.1_ASM311281v1', col] = genome_info.loc['GCA_000001405.29_GRCh38.p14', col]\n",
    "\n",
    "genome_info.loc['GCA_000001405.29_GRCh38.p14', 'Organism Common Name'] = 'GRCh38'\n",
    "genome_info.loc['GCA_015074485.1_ASM1507448v1', 'Organism Common Name'] = 'short read (Illumina NovaSeq)'\n",
    "genome_info.loc['GCA_003112815.1_ASM311281v1', 'Organism Common Name'] = 'short read (Illumina HiSeq)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bc70c-1b43-488f-879e-ccc424c07f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S1c\n",
    "current_set = genome_info.loc[genome_info['genus'] == 'Homo']\n",
    "opacity = 0.8\n",
    "fig_counts = make_subplots(rows = 4, cols = 3, subplot_titles = ['A', 'C', 'AC', 'AT', 'AG', 'CG', 'AAC', 'AAG', 'AAT', 'CCG', 'AGC', 'AGG'], x_title = 'repeat tract length (nt)', y_title = 'counts (normalized)', vertical_spacing = 0.06, horizontal_spacing = 0.05, shared_xaxes = True, shared_yaxes = True)\n",
    "row_counter = 1; col_counter = 0; legend_counter = 0\n",
    "for seq in ['A', 'C', 'AC', 'AT', 'AG', 'CG', 'AAC', 'AAG', 'AAT', 'CCG', 'AGC', 'AGG']:\n",
    "    col_counter +=1; legend_counter +=1\n",
    "    current = (CHM13_counts[len(seq)][seq] * len(seq)) / (len(seq) * CHM13_counts[len(seq)][seq]).sum()\n",
    "    current = current.loc[current > 1e-10]\n",
    "    for file in current_set.index[::-1]:\n",
    "        current = counts_all[len(seq)][seq].loc[file].replace(0, np.nan).dropna().fillna(0)\n",
    "        current = current / current.sum()\n",
    "        current = current.loc[current > 1e-10]\n",
    "        fig_counts.add_trace(go.Scatter(x = current.index * len(seq), y = current, name = current_set['Organism Common Name'].loc[file], hovertemplate= 'L=%{x}, n=%{y}' + '<br>' + '<b>' + current_set['Organism Common Name'].loc[file] + '</b><br>' + 'Order: ' + current_set['order'].loc[file] + '<br>' + 'Family: ' + current_set['family'].loc[file] + '<br>' + current_set['Organism Scientific Name'].loc[file] + '<br>' + \"<extra></extra>\", mode = 'lines', legendgroup = file,  showlegend = True if legend_counter == 1 else False, opacity = opacity), row = row_counter, col = col_counter)\n",
    "    fig_counts.add_trace(go.Scatter(x = current.index * len(seq), y = current, name = 'T2T-CHM13', hovertemplate= 'L=%{x}, n=%{y}' + '<br>' + '<b>'+ 'T2T-CHM13' + '</b><br>' + 'Order: ' + current_set['order'].loc['GCA_000001405.29_GRCh38.p14'] + '<br>' + 'Family: ' + current_set['family'].loc['GCA_000001405.29_GRCh38.p14'] + '<br>' + current_set['Organism Scientific Name'].loc['GCA_000001405.29_GRCh38.p14'] + ' (T2T)' + '<br>' + \"<extra></extra>\", mode = 'lines', legendgroup = 'T2T', showlegend = True if legend_counter == 1 else False, opacity = 1), row = row_counter, col = col_counter)\n",
    "    if col_counter == 3:\n",
    "        col_counter -= 3; row_counter +=1\n",
    "fig_counts.update_xaxes(type = 'log', range = [-0.1,2.05], tickvals = [1,2,5,10,20,50,100], gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "fig_counts.update_yaxes(type = 'log', range = [-10,0], tickformat = '1.0e', dtick = 3, gridcolor = 'rgba(0,0,0,0.15)', gridwidth = 1)\n",
    "fig_counts.update_layout(font=dict(family = 'Arial', size = 16), colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:4][::-1], legend = dict(orientation = 'h', xanchor = 'center', x = 0.5, y= -0.12, entrywidth = 300), margin={'t':40,'l':60,'b':60,'r':10}, width = 800, height = 600)        \n",
    "fig_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c67bc9-a753-432a-a41b-b74b3a0d7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_counts.write_image('plots/figS1b.svg')\n",
    "fig_counts.write_image('plots/figS1b.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a896326-f392-429e-8854-59f99afb4b58",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf8bd2-c3f7-48f3-ac11-d8f1aa6ee95c",
   "metadata": {},
   "source": [
    "### Primate counts (fur use in inference)\n",
    "- Note: includes human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f1369-4170-4d40-83ab-2549798e4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "primate_counts = counts_all.reindex(genome_info.loc[genome_info['order'] == 'Primates'].sort_values(by = ['Contig N50'], ascending = False).drop_duplicates(subset = ['Taxonomy id']).index, level = 0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8c8b8-182a-4d59-a9f2-b24fc35d27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "primate_counts.to_pickle('repeat_distributions/primates_counts_all.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14635a52-e4b3-4bdd-ab60-a08d3e196735",
   "metadata": {},
   "source": [
    "### Supplementary Data File SF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05eb82-b25b-4561-a285-612f8888771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_SF1 = dict()\n",
    "for file in completed:\n",
    "    if file[:-15] not in counts_SF1.keys():\n",
    "        counts_SF1[file[:-15]] = pd.read_pickle('repeat_distributions/mammalian_reference_genomes/'+file).replace(0, np.nan).dropna(how = 'all')\n",
    "        if 'long' in counts_SF1[file[:-15]].index.get_level_values(0):\n",
    "            counts_SF1[file[:-15]] = counts_SF1[file[:-15]].loc['long']\n",
    "\n",
    "counts_SF1['T2T-CHM13'] = CHM13_counts[range(1,7)].replace(0, np.nan).dropna(how = 'all')\n",
    "counts_SF1 = pd.concat(counts_SF1, axis=1).sort_index().dropna(how = 'all', axis=1).fillna(0).astype(int).reindex(range(1,201))\n",
    "counts_SF1 = counts_SF1.transpose().reset_index()\n",
    "counts_SF1 = counts_SF1.loc[counts_SF1['unit_len'].isin(range(1,7))]\n",
    "reps_1_6 = ['A', 'AAAAAC', 'AAAAAG', 'AAAAAT', 'AAAAC', 'AAAACC', 'AAAACG', 'AAAACT', 'AAAAG', 'AAAAGC', 'AAAAGG', 'AAAAGT', 'AAAAT', 'AAAATC', 'AAAATG', 'AAAATT', 'AAAC', 'AAACAC', 'AAACAG', 'AAACAT', 'AAACC', 'AAACCC', 'AAACCG', 'AAACCT', 'AAACG', 'AAACGC', 'AAACGG', 'AAACGT', 'AAACT', 'AAACTC', 'AAACTG', 'AAACTT', 'AAAG', 'AAAGAC', 'AAAGAG', 'AAAGAT', 'AAAGC', 'AAAGCC', 'AAAGCG', 'AAAGCT', 'AAAGG', 'AAAGGC', 'AAAGGG', 'AAAGGT', 'AAAGT', 'AAAGTC', 'AAAGTG', 'AAAGTT', 'AAAT', 'AAATAC', 'AAATAG', 'AAATAT', 'AAATC', 'AAATCC', 'AAATCG', 'AAATCT', 'AAATG', 'AAATGC', 'AAATGG', 'AAATGT', 'AAATT', 'AAATTC', 'AAATTG', 'AAATTT', 'AAC', 'AACAAG', 'AACAAT', 'AACAC', 'AACACC', 'AACACG', 'AACACT', 'AACAG', 'AACAGC', 'AACAGG', 'AACAGT', 'AACAT', 'AACATC', 'AACATG', 'AACATT', 'AACC', 'AACCAC', 'AACCAG', 'AACCAT', 'AACCC', 'AACCCC', 'AACCCG', 'AACCCT', 'AACCG', 'AACCGC', 'AACCGG', 'AACCGT', 'AACCT', 'AACCTC', 'AACCTG', 'AACCTT', 'AACG', 'AACGAC', 'AACGAG', 'AACGAT', 'AACGC', 'AACGCC', 'AACGCG', 'AACGCT', 'AACGG', 'AACGGC', 'AACGGG', 'AACGGT', 'AACGT', 'AACGTC', 'AACGTG', 'AACGTT', 'AACT', 'AACTAC', 'AACTAG', 'AACTAT', 'AACTC', 'AACTCC', 'AACTCG', 'AACTCT', 'AACTG', 'AACTGC', 'AACTGG', 'AACTGT', 'AACTT', 'AACTTC', 'AACTTG', 'AAG', 'AAGAAT', 'AAGAC', 'AAGACC', 'AAGACG', 'AAGACT', 'AAGAG', 'AAGAGC', 'AAGAGG', 'AAGAGT', 'AAGAT', 'AAGATC', 'AAGATG', 'AAGATT', 'AAGC', 'AAGCAC', 'AAGCAG', 'AAGCAT', 'AAGCC', 'AAGCCC', 'AAGCCG', 'AAGCCT', 'AAGCG', 'AAGCGC', 'AAGCGG', 'AAGCGT', 'AAGCT', 'AAGCTC', 'AAGCTG', 'AAGCTT', 'AAGG', 'AAGGAC', 'AAGGAG', 'AAGGAT', 'AAGGC', 'AAGGCC', 'AAGGCG', 'AAGGCT', 'AAGGG', 'AAGGGC', 'AAGGGG', 'AAGGGT', 'AAGGT', 'AAGGTC', 'AAGGTG', 'AAGT', 'AAGTAC', 'AAGTAG', 'AAGTAT', 'AAGTC', 'AAGTCC', 'AAGTCG', 'AAGTCT', 'AAGTG', 'AAGTGC', 'AAGTGG', 'AAGTGT', 'AAT', 'AATAC', 'AATACC', 'AATACG', 'AATACT', 'AATAG', 'AATAGC', 'AATAGG', 'AATAGT', 'AATAT', 'AATATC', 'AATATG', 'AATATT', 'AATC', 'AATCAC', 'AATCAG', 'AATCAT', 'AATCC', 'AATCCC', 'AATCCG', 'AATCCT', 'AATCG', 'AATCGC', 'AATCGG', 'AATCGT', 'AATCT', 'AATCTC', 'AATCTG', 'AATG', 'AATGAC', 'AATGAG', 'AATGAT', 'AATGC', 'AATGCC', 'AATGCG', 'AATGCT', 'AATGG', 'AATGGC', 'AATGGG', 'AATGGT', 'AATGT', 'AATGTC', 'AATGTG', 'AATT', 'AATTAC', 'AATTAG', 'AATTAT', 'AATTC', 'AATTCC', 'AATTCG', 'AATTGC', 'AC', 'ACACAG', 'ACACAT', 'ACACC', 'ACACCC', 'ACACCG', 'ACACCT', 'ACACG', 'ACACGC', 'ACACGG', 'ACACGT', 'ACACT', 'ACACTC', 'ACACTG', 'ACAG', 'ACAGAG', 'ACAGAT', 'ACAGC', 'ACAGCC', 'ACAGCG', 'ACAGCT', 'ACAGG', 'ACAGGC', 'ACAGGG', 'ACAGGT', 'ACAGT', 'ACAGTC', 'ACAGTG', 'ACAT', 'ACATAG', 'ACATAT', 'ACATC', 'ACATCC', 'ACATCG', 'ACATCT', 'ACATG', 'ACATGC', 'ACATGG', 'ACATGT', 'ACC', 'ACCACG', 'ACCACT', 'ACCAG', 'ACCAGC', 'ACCAGG', 'ACCAGT', 'ACCAT', 'ACCATC', 'ACCATG', 'ACCC', 'ACCCAG', 'ACCCAT', 'ACCCC', 'ACCCCC', 'ACCCCG', 'ACCCCT', 'ACCCG', 'ACCCGC', 'ACCCGG', 'ACCCGT', 'ACCCT', 'ACCCTC', 'ACCCTG', 'ACCG', 'ACCGAG', 'ACCGAT', 'ACCGC', 'ACCGCC', 'ACCGCG', 'ACCGCT', 'ACCGG', 'ACCGGC', 'ACCGGG', 'ACCGGT', 'ACCGT', 'ACCGTC', 'ACCGTG', 'ACCT', 'ACCTAG', 'ACCTAT', 'ACCTC', 'ACCTCC', 'ACCTCG', 'ACCTCT', 'ACCTG', 'ACCTGC', 'ACCTGG', 'ACG', 'ACGACT', 'ACGAG', 'ACGAGC', 'ACGAGG', 'ACGAGT', 'ACGAT', 'ACGATC', 'ACGATG', 'ACGC', 'ACGCAG', 'ACGCAT', 'ACGCC', 'ACGCCC', 'ACGCCG', 'ACGCCT', 'ACGCG', 'ACGCGC', 'ACGCGG', 'ACGCGT', 'ACGCT', 'ACGCTC', 'ACGCTG', 'ACGG', 'ACGGAG', 'ACGGAT', 'ACGGC', 'ACGGCC', 'ACGGCG', 'ACGGCT', 'ACGGG', 'ACGGGC', 'ACGGGG', 'ACGT', 'ACGTAG', 'ACGTAT', 'ACGTC', 'ACGTCC', 'ACGTCG', 'ACGTGC', 'ACT', 'ACTAG', 'ACTAGC', 'ACTAGG', 'ACTAGT', 'ACTAT', 'ACTATC', 'ACTATG', 'ACTC', 'ACTCAG', 'ACTCAT', 'ACTCC', 'ACTCCC', 'ACTCCG', 'ACTCCT', 'ACTCG', 'ACTCGC', 'ACTCGG', 'ACTCT', 'ACTCTC', 'ACTCTG', 'ACTG', 'ACTGAG', 'ACTGAT', 'ACTGC', 'ACTGCC', 'ACTGCG', 'ACTGCT', 'ACTGG', 'ACTGGC', 'ACTGGG', 'AG', 'AGAGAT', 'AGAGC', 'AGAGCC', 'AGAGCG', 'AGAGCT', 'AGAGG', 'AGAGGC', 'AGAGGG', 'AGAT', 'AGATAT', 'AGATC', 'AGATCC', 'AGATCG', 'AGATCT', 'AGATG', 'AGATGC', 'AGATGG', 'AGC', 'AGCAGG', 'AGCAT', 'AGCATC', 'AGCATG', 'AGCC', 'AGCCAT', 'AGCCC', 'AGCCCC', 'AGCCCG', 'AGCCCT', 'AGCCG', 'AGCCGC', 'AGCCGG', 'AGCCT', 'AGCCTC', 'AGCCTG', 'AGCG', 'AGCGAT', 'AGCGC', 'AGCGCC', 'AGCGCG', 'AGCGCT', 'AGCGG', 'AGCGGC', 'AGCGGG', 'AGCT', 'AGCTAT', 'AGCTC', 'AGCTCC', 'AGCTCG', 'AGCTGC', 'AGG', 'AGGAT', 'AGGATC', 'AGGATG', 'AGGC', 'AGGCAT', 'AGGCC', 'AGGCCC', 'AGGCCG', 'AGGCCT', 'AGGCG', 'AGGCGC', 'AGGCGG', 'AGGG', 'AGGGAT', 'AGGGC', 'AGGGCC', 'AGGGCG', 'AGGGG', 'AGGGGC', 'AGGGGG', 'AT', 'ATATC', 'ATATCC', 'ATATCG', 'ATATGC', 'ATC', 'ATCATG', 'ATCC', 'ATCCC', 'ATCCCC', 'ATCCCG', 'ATCCG', 'ATCCGC', 'ATCCGG', 'ATCG', 'ATCGC', 'ATCGCC', 'ATCGCG', 'ATCGGC', 'ATGC', 'ATGCC', 'ATGCCC', 'ATGCGC', 'ATGGCC', 'C', 'CCCCCG', 'CCCCG', 'CCCCGG', 'CCCG', 'CCCGCG', 'CCCGG', 'CCCGGG', 'CCG', 'CCGCG', 'CCGCGG', 'CCGG', 'CCGGCG', 'CG']\n",
    "counts_SF1 = counts_SF1.loc[counts_SF1['motif_RC'].isin(reps_1_6)]\n",
    "counts_SF1 = counts_SF1.groupby(['level_0', 'unit_len', 'motif_RC']).sum().transpose()\n",
    "counts_SF1.columns = counts_SF1.columns.rename('assembly_id', level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7d0f3-7699-45d3-b0b8-f3cb5e69d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_SF1.to_csv('repeat_distributions/SF1_mammalian_repeat_length_counts.csv', sep = '\\t')\n",
    "counts_SF1.transpose().to_excel('repeat_distributions/SF1_mammalian_repeat_length_counts.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
