{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5e729f-8527-4dbf-b083-7cf867bc7621",
   "metadata": {},
   "source": [
    "# Supplemental Code\n",
    "- Inherent instability of simple DNA repeats shapes an evolutionarily stable distribution of repeat lengths \n",
    "- McGinty et al. 2025\n",
    "- Part 4 of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49356e-56ef-43a9-8ae2-114affe23c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "import kaleido    # https://github.com/plotly/Kaleido\n",
    "import plotly     # https://plotly.com/python/getting-started/\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "pio.templates.default = \"none\"\n",
    "pd.set_option('display.precision', 3)\n",
    "go_config = {'showTips': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de93312-4b6e-443e-8815-d67daeadb587",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312bbb5-fc3e-4ad4-9f0a-f64be44448df",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHM13_counts = pd.read_pickle('repeat_distributions/CHM13_counts.pickle')\n",
    "CHM13_counts_B = pd.read_pickle('repeat_distributions/CHM13_counts_Bdist.pickle')\n",
    "random_counts = pd.read_pickle('repeat_distributions/random_counts.pickle')\n",
    "random_counts_B = pd.read_pickle('repeat_distributions/random_counts_Bdist.pickle')\n",
    "subonly_counts = pd.read_pickle('repeat_distributions/subonly_counts_remake.pickle')\n",
    "primate_counts = pd.read_pickle('repeat_distributions/primates_counts_all.pickle')\n",
    "\n",
    "denovo_exp_rate = pd.read_pickle('denovo/denovo_exp_rate_remake.pickle')\n",
    "denovo_con_rate = pd.read_pickle('denovo/denovo_con_rate_remake.pickle')\n",
    "denovo_nonexp_rate = pd.read_pickle('denovo/denovo_nonexp_rate_remake.pickle')\n",
    "denovo_substitution_context_rate = pd.read_pickle('denovo/denovo_mut_freq_all.pickle')\n",
    "decode_exp_rate = pd.read_pickle('decode/decode_expansion_rates.pickle')\n",
    "decode_con_rate = pd.read_pickle('decode/decode_contraction_rates.pickle')\n",
    "\n",
    "intercept_list = [denovo_con_rate['A'][8]] + [denovo_exp_rate['A'][8] * (denovo_exp_rate['A'][8]/ denovo_con_rate['A'][8])**x for x in range(7)]\n",
    "\n",
    "repeats_1_3 = ['A', 'C', 'AC', 'AT', 'AG', 'CG', 'AAT', 'AAG', 'AAC', 'ATC', 'ACT', 'AGG', 'AGC', 'ACG', 'ACC', 'CCG']\n",
    "bootstrap_counts = pd.read_pickle('repeat_distributions/bootstrap_counts_1000.pickle').sort_index()\n",
    "bootstrap_counts_max = dict(); bootstrap_counts_min = dict(); bootstrap_counts_mean = dict()\n",
    "for motif in repeats_1_3:\n",
    "    bootstrap_counts_mean[motif] = bootstrap_counts.xs(motif, level='motif_RC', axis=1).apply(lambda x: x.sort_values().head(975).tail(950).mean(), axis=1).sort_index().replace(0, np.nan).dropna()\n",
    "    bootstrap_counts_max[motif] = bootstrap_counts.xs(motif, level='motif_RC', axis=1).apply(lambda x: x.sort_values().head(975).tail(950).max(), axis=1).reindex(bootstrap_counts_mean[motif].index)\n",
    "    bootstrap_counts_min[motif] = bootstrap_counts.xs(motif, level='motif_RC', axis=1).apply(lambda x: x.sort_values().head(975).tail(950).min(), axis=1).reindex(bootstrap_counts_mean[motif].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d407ed7-ec39-46a3-87db-634a2c6622c9",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7b1c8-ffbe-4bb9-ac34-fcf44b584d6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gather data from each grid point into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6f4f2-ac75-4f03-add5-de201e5e2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_files(folder, run_name, write='out', final_only = False, check_complete = None, B_dist = False, separator = 'tE|tC|iE|iC', col_list = [6,8,10,12]):\n",
    "    grid_files = os.listdir(folder)\n",
    "    grid_files_A = sorted([file for file in grid_files if 'Adist' in file])\n",
    "    filename_start = pd.Series(grid_files_A).str.split(separator)[0][0]\n",
    "    filename_end = '_' + pd.Series(grid_files_A).str.split(separator)[0][4].split('_')[1]\n",
    "    parameter_info = pd.Series(grid_files_A).str.split(separator + '|_', expand=True)[col_list].astype(float)\n",
    "    parameter_info.index = grid_files_A\n",
    "    parameter_info.columns = ['exp_p', 'con_p', 'exp_i', 'con_i']\n",
    "    parameter_info = parameter_info[['exp_i', 'con_i', 'exp_p', 'con_p']]\n",
    "    parameter_info['exp_i'] = parameter_info['exp_i'].astype(int); parameter_info['con_i'] = parameter_info['con_i'].astype(int)\n",
    "    parameter_info = parameter_info.sort_index().drop_duplicates(keep = 'first') # if any duplicates exist, keep one with lowest speedup\n",
    "    parameters_inference_cols = pd.Series([(a,b,c,d) for a,b,c,d in zip(parameter_info['exp_i'], parameter_info['con_i'], parameter_info['exp_p'], parameter_info['con_p'])], index = parameter_info.index)\n",
    "    \n",
    "    if check_complete is not None:\n",
    "        # check for missing files\n",
    "        jobs = pd.read_pickle(check_complete)\n",
    "        jobs_incomplete = jobs.loc[jobs.isin(parameters_inference_cols) == False].reset_index(drop=True)\n",
    "        if len(jobs_incomplete) > 0:\n",
    "            print('missing ' + str(len(jobs_incomplete)) + ' files')\n",
    "            jobs_incomplete.to_pickle('jobs_incomplete.pickle')\n",
    "            return jobs_incomplete\n",
    "        else:\n",
    "            print('grid is complete')\n",
    "\n",
    "    if write != False:\n",
    "        inference_grid = dict()\n",
    "        inference_grid_Bdist = dict()\n",
    "        for file in parameter_info.index:\n",
    "            try:\n",
    "                if final_only == False:\n",
    "                    inference_grid[file] = pd.read_pickle(folder + file)\n",
    "                else:\n",
    "                    inference_grid[file] = pd.read_pickle(folder + file).T.tail(1).T\n",
    "            except pickle.UnpicklingError:\n",
    "                os.remove(folder + file)\n",
    "                print('deleted: ' + str(file))\n",
    "            if B_dist == True:\n",
    "                inference_grid_Bdist[file] = pd.read_pickle(folder + file.replace('Adist', 'Bdist')).T.tail(1).T\n",
    "        inference_grid = pd.concat(inference_grid, axis=1).sort_index(axis=1)\n",
    "        cols = parameter_info.reindex(inference_grid.columns.get_level_values(0))\n",
    "        cols['round'] = inference_grid.columns.get_level_values(1)\n",
    "        cols = pd.MultiIndex.from_frame(cols)\n",
    "        inference_grid.columns = cols\n",
    "        inference_grid.index +=1\n",
    "        if write == 'pickle':\n",
    "            inference_grid.to_pickle('simulations/completed_grids/' + run_name + '.pickle')\n",
    "        if write == 'csv':\n",
    "            inference_grid.to_csv('simulations/completed_grids/' + run_name + '.csv', sep = '\\t')\n",
    "\n",
    "        if B_dist == True:\n",
    "            inference_grid_Bdist = pd.concat(inference_grid_Bdist, axis=1).sort_index(axis=1)\n",
    "            inference_grid_Bdist.columns = cols\n",
    "            inference_grid_Bdist.index +=1\n",
    "            if write == 'pickle':\n",
    "                inference_grid_Bdist.to_pickle('simulations/completed_grids/' + run_name + '_Bdist.pickle')\n",
    "            if write == 'csv':\n",
    "                inference_grid_Bdist.to_csv('simulations/completed_grids/' + run_name + '_Bdist.csv', sep = '\\t')\n",
    "\n",
    "        if write == 'out':\n",
    "            return inference_grid, inference_grid_Bdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7b664-0ccd-4796-8b35-6e748a803bf5",
   "metadata": {},
   "source": [
    "#### For gathering data from cluster\n",
    "put the above function into a separate script, along with the below cell:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab872376-6a1f-4643-919d-969f4de8a9d1",
   "metadata": {},
   "source": [
    "#### used if running the above function in a separate script\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='repeat distribution simulation - gather data')\n",
    "parser.add_argument('--dir', action=\"store\", dest='dir', default = 'simulations/grid_output/', type=str)\n",
    "parser.add_argument('--name', action=\"store\", dest='name', default = 'grid_name', type=str)\n",
    "parser.add_argument('--write', action=\"store\", dest='write', default = 'out', type=str)\n",
    "parser.add_argument('--final', default=False, action=\"store_true\")\n",
    "parser.add_argument('--check_complete', default=None, action=\"store\", type = str)\n",
    "parser.add_argument('--B_dist', default=False, action=\"store_true\")\n",
    "parser.add_argument('--sep', action=\"store\", dest='sep', default = 'tE|tC|iE|iC', type=str)\n",
    "parser.add_argument('--col_list', action=\"store\", dest='col_list', default = '[6,8,10,12]', type=str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.col_list = eval(args.col_list)\n",
    "gather_files(args.dir, args.name, args.write, args.final, args.check_complete, args.B_dist, args.sep, args.col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5842aa0-20b2-4b36-9502-362898f2cd02",
   "metadata": {},
   "source": [
    "#### Script parameters\n",
    "- --dir -> location of DRL files to be combined into one convenient file\n",
    "- --name -> output name of file\n",
    "- --write -> type of file to write: csv, pickle or False (to check completeness only)\n",
    "- --final -> only gather the final timepoint\n",
    "- --check_complete -> takes the job list as an input and checks for completeness, returning a new job list if any files are missing\n",
    "- --B_dist -> return file with info on the DRL for B strings\n",
    "- --sep -> provide alternate file name delimiters (if parameters are named differently than default)\n",
    "- --col_list -> provide location of parameter info within the file name text string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51781551-565e-426a-ac0e-8eac565c9d86",
   "metadata": {},
   "source": [
    "#### Example commands\n",
    "(change path and name as needed)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae4ec57c-9f38-4048-ad6d-144d8d2ed750",
   "metadata": {},
   "source": [
    "gather_files('simulations/grid_example/', 'grid_example', write = 'pickle')\n",
    "gather_files('simulations/grid_example/', 'grid_example_final', write = 'pickle', final_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e24115-275a-4dd3-b69f-41fb39c17eaa",
   "metadata": {},
   "source": [
    "### Load computational model data\n",
    "(change path and name as needed)\n",
    "- note: these parameterizations were completed based on pre-defined grids\n",
    "- other computational model runs focus on reanalysis of data analyzed below and are loaded within the relevant section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f73bc7-973b-4955-8bed-6932335df504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power-law parameterization\n",
    "inference_grid_final_nointerp_subonly = pd.read_pickle('simulations/completed_grids/grid_newpro_PL_final.pickle').droplevel(4, axis=1)\n",
    "inference_grid_final_nointerp_subonly_Bdist = pd.read_pickle('simulations/completed_grids/grid_newpro_PL_final_Bdist.pickle').droplevel(4, axis=1)\n",
    "inference_grid_nointerp_subonly = pd.read_pickle('simulations/completed_grids/grid_newpro_PL.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32035aee-bd04-4006-baf5-4fd807501d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power-law parameterization with interpolated rates\n",
    "inference_grid_final_interp_subonly = pd.read_pickle('simulations/completed_grids/grid_3M_PL_subonly_interp_final.pickle').droplevel(4, axis=1)#.dropna(how = 'all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b4f6f-aa77-4f84-b0c1-fe8e5a26296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power-law parameterization with constant time rescaling\n",
    "inference_grid_final_sparse_constantspeedup_subonly = pd.read_pickle('simulations/completed_grids/grid_4param_PL_constant_subonly_final.pickle').droplevel(4, axis=1)#.dropna(how = 'all', axis=1)\n",
    "inference_grid_sparse_constantspeedup_subonly = pd.read_pickle('simulations/completed_grids/grid_4param_PL_constant_subonly.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b1fed-7c9c-4bbf-a6fd-7f550bbd13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power-law parameterization with constant time rescaling and alternate initial state\n",
    "inference_grid_final_sparse_constantspeedup_uniform = pd.read_pickle('simulations/completed_grids/grid_4param_PL_constant_uniform_final.pickle').droplevel(4, axis=1)#.dropna(how = 'all', axis=1)\n",
    "inference_grid_sparse_constantspeedup_uniform = pd.read_pickle('simulations/completed_grids/grid_4param_PL_constant_uniform.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b024779-8017-49e4-91bf-8a4329c50d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure power-law parameterization\n",
    "inference_grid_final_xrange = pd.read_pickle('simulations/completed_grids/grid_4param_xaxis_v2.pickle').droplevel(4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb176fb-91eb-4074-89bf-36cc45d6e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic power parameterization\n",
    "inference_grid_final_log = pd.read_pickle('simulations/completed_grids/grid_4param_log_v4_final.pickle').droplevel(4, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12afdb50-d013-41e0-b263-d9dcf2d97724",
   "metadata": {},
   "source": [
    "### Load mammalian DRLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2157d8-bd51-4c87-a384-f893295414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "primate_counts = pd.read_pickle('repeat_distributions/primates_counts_all.pickle')\n",
    "primate_counts_A = primate_counts[1]['A'].unstack().T.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da90a7b-830f-4694-9b54-9c2cbe7966d6",
   "metadata": {},
   "source": [
    "# KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e1534-d2c2-4e56-8386-bdf64efe3878",
   "metadata": {},
   "source": [
    "### Primate range used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf77cd-16a9-4719-a29b-7e8860946ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_range = range(4,201); L_range = range(4,201)\n",
    "\n",
    "# calculate Kullback-Leibler divergence, comparing a given DRL to T2T-CHM13\n",
    "def calc_KL_divergence_CHM13(dist, L_range = range(4,201)):\n",
    "    return ((CHM13_counts_A_norm_ps.reindex(L_range)) * np.log((CHM13_counts_A_norm_ps.reindex(L_range)) / (dist.reindex(L_range)))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c1e05-9819-4487-9e34-703281767240",
   "metadata": {},
   "source": [
    "#### Normalize counts (with pseudocount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a1bc1-bef0-4d57-909e-c135dc6d7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudocount = 1 # using 0.01 or 100 makes little difference in rankings. using 100 reduces the Bayes factor of the 2 parameter model, while having almost no effect elsewhere\n",
    "CHM13_counts_A_norm_ps = (CHM13_counts[1]['A'].reindex(norm_range).fillna(0) + pseudocount) / (CHM13_counts[1]['A'].reindex(norm_range).fillna(0) + pseudocount).sum()\n",
    "primate_counts_A_norm_ps = (primate_counts_A.reindex(norm_range).fillna(0) + pseudocount) / (primate_counts_A.reindex(norm_range).fillna(0) + pseudocount).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47750ad-a8f3-46d0-b85e-39cc52693aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KL\n",
    "KL_primate_grid = primate_counts_A_norm_ps.apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a01fc8-bb75-4b3b-8219-05bdd3270b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KL_primate_grid.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de776d3f-3a26-4626-9e00-66ce7a3f6d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cutoff = 2\n",
    "KL_primate_variance = (KL_primate_grid[1:].sort_values()[:-n_cutoff].max() / 2)**2\n",
    "def calc_likelihood_from_primate_metric_KL(metric):\n",
    "    # Gaussian acceptance probability (note: not a true likelihood)\n",
    "    return np.e**-((metric**2)/(2*KL_primate_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f07e22-0f92-41a0-ba05-fcdcf0688031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized counts for plotting\n",
    "primate_counts_A_norm = primate_counts_A.div(primate_counts_A.sum()).reindex(range(1,200)).fillna(0)\n",
    "primate_counts_A_norm_hum = primate_counts_A_norm.where(primate_counts_A > 30) * CHM13_counts[1]['A'].sum()\n",
    "primate_CI_high = primate_counts_A_norm_hum.T.reindex(KL_primate_grid[1:].sort_values()[:-n_cutoff].index).T.max(axis=1)\n",
    "primate_CI_low = primate_counts_A_norm_hum.T.reindex(KL_primate_grid[1:].sort_values()[:-n_cutoff].index).T.min(axis=1)\n",
    "primate_counts_A_norm = primate_counts_A.reindex(norm_range) / primate_counts_A.reindex(norm_range).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe0d9cc-c811-4dd8-9566-6bf6e8fd92f4",
   "metadata": {},
   "source": [
    "## Calculate posterior distributions and Bayes factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7749e-787e-4188-8084-6fc5ab552a41",
   "metadata": {},
   "source": [
    "### Power-law model (with empirical rate data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50090b5e-f250-42e3-9af7-78897d68dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with pseudocount\n",
    "inference_grid_final_nointerp_subonly_norm_ps = (inference_grid_final_nointerp_subonly.reindex(norm_range).fillna(0) + pseudocount) / (inference_grid_final_nointerp_subonly.reindex(norm_range).fillna(0) + pseudocount).sum()\n",
    "# Calculate KL\n",
    "KL_inference_grid_final_nointerp = inference_grid_final_nointerp_subonly_norm_ps.apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range))\n",
    "# Calculate acceptance probability\n",
    "grid_likelihood = calc_likelihood_from_primate_metric_KL(KL_inference_grid_final_nointerp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d9c16-50e9-4ef2-9309-c724f1b9ecab",
   "metadata": {},
   "source": [
    "#### grid of rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a3911-89b5-41d2-b0dc-ffb2f3e17d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pin_power_law(power, pin_rate, pin_len=9, start_len=1, end_len=200):\n",
    "    denom = (pin_len**power) / pin_rate\n",
    "    return pd.Series([i**power for i in range(start_len, end_len+1)], index = list(range(start_len,end_len+1))) / denom\n",
    "\n",
    "def intercept_then_powerlaw(exp_power, con_power, exp_int, con_int, pin_len = 9, A_bins = 200, boot = None, motif = 'A', interp = False, nonexp_factor = 0.01, intercept_list = intercept_list):\n",
    "    if boot is None:\n",
    "        bootname = ''\n",
    "        denovo_exp_rate_current = denovo_exp_rate[motif].copy()\n",
    "        denovo_con_rate_current = denovo_con_rate[motif].copy()\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate[motif].copy()\n",
    "    else:\n",
    "        bootname = '_boot'+str(boot)\n",
    "        denovo_exp_rate_current = denovo_exp_rate_poisson[motif][boot].copy()\n",
    "        denovo_con_rate_current = denovo_con_rate_poisson[motif][boot].copy()\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate_poisson[motif][boot].copy()\n",
    "    exp = pd.concat([denovo_exp_rate_current.reindex(range(pin_len)), pin_power_law(exp_power, intercept_list[exp_int], start_len=pin_len, end_len=A_bins+3)])\n",
    "    con = pd.concat([denovo_con_rate_current.reindex(range(pin_len)), pin_power_law(con_power, intercept_list[con_int], start_len=pin_len, end_len=A_bins+3)])\n",
    "    nonexp = pd.concat([denovo_nonexp_rate_current.reindex(range(pin_len)), pin_power_law(exp_power, intercept_list[exp_int] * nonexp_factor, start_len=pin_len, end_len=A_bins+3)])\n",
    "    nonexpname = '_nex' + str(nonexp_factor)\n",
    "    nonexp.loc[1] = 0\n",
    "    if interp == True:\n",
    "        interpname = '_interp'\n",
    "        exp.loc[8:13] = np.nan\n",
    "        con.loc[8:13] = np.nan\n",
    "        nonexp.loc[8:13] = np.nan\n",
    "        exp = exp.interpolate(method = 'quadratic')\n",
    "        con = con.interpolate(method = 'quadratic')\n",
    "        nonexp = nonexp.interpolate(method = 'quadratic')\n",
    "    else:\n",
    "        interpname = ''\n",
    "    name = '_interceptPL_tE' + str(exp_power) + '_tC' + str(con_power) +'_iE' + str(exp_int) + '_iC' + str(con_int) + nonexpname + interpname + bootname\n",
    "    return name, exp, con, nonexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bef1d-6b67-4ce9-a49b-91495740af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_all = pd.DataFrame([intercept_then_powerlaw(exp_p, con_p, exp_i, con_i, interp = False) for (exp_i, con_i, exp_p, con_p,) in grid_likelihood.index], index = grid_likelihood.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3e1e2-2945-4d96-baf6-75bfcc0a545f",
   "metadata": {},
   "source": [
    "#### Calculate Bayes factors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14eb82-21d8-4bfe-abfd-287a582ff2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(grid_likelihood, modelname, priorname, paramname, prior = None, params = ['exp_i', 'con_i', 'exp_p', 'con_p'], use_intercepts = True, grid_drl = inference_grid_final_nointerp_subonly_norm_ps, rates = rates_all):\n",
    "    grid_likelihood = grid_likelihood.reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])[0]\n",
    "    if prior is None:\n",
    "        prior = (1/len(grid_likelihood))\n",
    "        posterior = grid_likelihood * prior\n",
    "    else:\n",
    "        prior = prior.reindex(grid_likelihood.index)['prob']\n",
    "        prior /= prior.sum()\n",
    "        posterior = grid_likelihood * prior.values\n",
    "    bayesfactors[modelname][priorname][paramname] = posterior.sum()\n",
    "    posterior /= posterior.sum()\n",
    "\n",
    "    drl_weighted_avg[modelname][priorname][paramname] = (grid_drl.T.reindex(grid_likelihood.index).T * posterior.values).sum(axis=1)    \n",
    "    grid_drl_95c[modelname][priorname][paramname] = grid_drl.T.loc[posterior.sort_values(ascending=False).where(posterior.sort_values(ascending=False).cumsum() < 0.95).dropna().index].copy().T\n",
    "\n",
    "    grid_rates_95c[modelname][priorname][paramname] = rates.loc[posterior.sort_values(ascending=False).where(posterior.sort_values(ascending=False).cumsum() < 0.95).dropna().index].copy().T\n",
    "    rates_weighted_exp[modelname][priorname][paramname] = pd.Series(np.average(pd.concat(list(rates[1].reindex(grid_likelihood.index)), axis=1), axis=1, weights = posterior.values))\n",
    "    rates_weighted_con[modelname][priorname][paramname] = pd.Series(np.average(pd.concat(list(rates[2].reindex(grid_likelihood.index)), axis=1), axis=1, weights = posterior.values))\n",
    "    \n",
    "    posterior = posterior.reset_index()\n",
    "    posterior['M'] = pd.Series(intercept_list / intercept_list[1]).reindex(posterior['exp_i']).values\n",
    "    if use_intercepts == True:\n",
    "        posterior['exp_i'] = pd.Series(intercept_list).reindex(posterior['exp_i']).values\n",
    "        posterior['con_i'] = pd.Series(intercept_list).reindex(posterior['con_i']).values\n",
    "\n",
    "    best_params[modelname][priorname][paramname] = posterior.sort_values(by = [0], ascending = False).iloc[0].reindex(params)\n",
    "    avg_params[modelname][priorname][paramname] = pd.Series(np.average(posterior[params], axis=0, weights = posterior[0]), index = params)\n",
    "    \n",
    "    posteriors_all[modelname][priorname][paramname] = posterior\n",
    "    posterior_95c[modelname][priorname][paramname] = posterior.set_index(params)[0].sort_values(ascending = False).where(posterior.set_index(params)[0].sort_values(ascending = False).cumsum() < 0.95).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db970487-0e9b-4349-962a-8449c2e633e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors = dict(); best_params = dict(); avg_params = dict(); drl_weighted_avg = dict(); posteriors_all = dict(); posterior_95c = dict(); grid_drl_95c = dict(); rates_weighted_exp = dict(); rates_weighted_con = dict(); grid_rates_95c = dict(); subset_indices = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815ef21-6a95-40ea-b966-6809f1a922db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors['PL'] = dict(); best_params['PL'] = dict(); avg_params['PL'] = dict(); drl_weighted_avg['PL'] = dict(); posteriors_all['PL'] = dict(); posterior_95c['PL'] = dict(); grid_drl_95c['PL'] = dict(); rates_weighted_exp['PL'] = dict(); rates_weighted_con['PL'] = dict(); grid_rates_95c['PL'] = dict(); subset_indices['PL'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0e13f-dfa7-44c6-b692-2319432cb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform prior\n",
    "bayesfactors['PL']['uniform'] = dict(); best_params['PL']['uniform'] = dict(); avg_params['PL']['uniform'] = dict(); drl_weighted_avg['PL']['uniform'] = dict(); posteriors_all['PL']['uniform'] = dict(); posterior_95c['PL']['uniform'] = dict(); grid_drl_95c['PL']['uniform'] = dict(); rates_weighted_exp['PL']['uniform'] = dict(); rates_weighted_con['PL']['uniform'] = dict(); grid_rates_95c['PL']['uniform'] = dict()\n",
    "subset_indices['PL']['4param'] = grid_likelihood.index\n",
    "model_summary(grid_likelihood, 'PL', 'uniform', '4param', prior = None, params = ['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "\n",
    "# 2 parameter Bayes factor, model where power law is same, intercept is same\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p']) & (partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "subset_indices['PL']['2param'] = partial_grid.set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).index\n",
    "model_summary(partial_grid, 'PL', 'uniform', '2param', prior = None, params = ['exp_i', 'exp_p'])\n",
    "\n",
    "# Bayes factor, 3 parameters with shared powers\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p'])).dropna()\n",
    "subset_indices['PL']['3param_sharedpowers'] = partial_grid.set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).index\n",
    "model_summary(partial_grid, 'PL', 'uniform', '3param_sharedpowers', prior = None, params = ['exp_i', 'con_i', 'exp_p'])\n",
    "\n",
    "# Bayes factor, 3 parameters with shared constants\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "subset_indices['PL']['3param_sharedconstants'] = partial_grid.set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).index\n",
    "model_summary(partial_grid, 'PL', 'uniform', '3param_sharedconstants', prior = None, params = ['exp_i', 'exp_p', 'con_p'])\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "subset_indices['PL']['3param_Mult'] = partial_grid.set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).index\n",
    "model_summary(partial_grid, 'PL', 'uniform', '3param_Mult', prior = None, params = ['M', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693cbea-8eb3-4b41-b594-7621c0dbff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrictive prior\n",
    "prior_rates = pd.read_pickle('simulations/grid_4param_v2/prior_restrictive_a.pickle')\n",
    "prior_rates = prior_rates.reindex(grid_likelihood.index)\n",
    "prior_rates /= prior_rates.sum()\n",
    "\n",
    "# restrictive prior\n",
    "bayesfactors['PL']['restrictive'] = dict(); best_params['PL']['restrictive'] = dict(); avg_params['PL']['restrictive'] = dict(); drl_weighted_avg['PL']['restrictive'] = dict(); posteriors_all['PL']['restrictive'] = dict(); posterior_95c['PL']['restrictive'] = dict(); grid_drl_95c['PL']['restrictive'] = dict(); rates_weighted_exp['PL']['restrictive'] = dict(); rates_weighted_con['PL']['restrictive'] = dict(); grid_rates_95c['PL']['restrictive'] = dict()\n",
    "\n",
    "model_summary(grid_likelihood, 'PL', 'restrictive', '4param', prior = prior_rates, params = ['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "\n",
    "# 2 parameter Bayes factor, model where power law is same, intercept is same\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p']) & (partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'restrictive', '2param', prior = prior_rates, params = ['exp_i', 'exp_p'])\n",
    "\n",
    "# Bayes factor, 3 parameters with shared powers\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'restrictive', '3param_sharedpowers', prior = prior_rates, params = ['exp_i', 'con_i', 'exp_p'])\n",
    "\n",
    "# Bayes factor, 3 parameters with shared constants\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'restrictive', '3param_sharedconstants', prior = prior_rates, params = ['exp_i', 'exp_p', 'con_p'])\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'restrictive', '3param_Mult', prior = prior_rates, params = ['M', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fad53-127c-4d1d-b49c-7014ec4aa292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permissive prior\n",
    "prior_rates = pd.read_pickle('simulations/grid_4param_v2/prior_a.pickle')\n",
    "prior_rates = prior_rates.reindex(grid_likelihood.index)\n",
    "prior_rates /= prior_rates.sum()\n",
    "\n",
    "# permissive prior\n",
    "bayesfactors['PL']['permissive'] = dict(); best_params['PL']['permissive'] = dict(); avg_params['PL']['permissive'] = dict(); drl_weighted_avg['PL']['permissive'] = dict(); posteriors_all['PL']['permissive'] = dict(); posterior_95c['PL']['permissive'] = dict(); grid_drl_95c['PL']['permissive'] = dict(); rates_weighted_exp['PL']['permissive'] = dict(); rates_weighted_con['PL']['permissive'] = dict(); grid_rates_95c['PL']['permissive'] = dict()\n",
    "\n",
    "model_summary(grid_likelihood, 'PL', 'permissive', '4param', prior = prior_rates, params = ['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "\n",
    "# 2 parameter Bayes factor, model where power law is same, intercept is same\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p']) & (partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'permissive', '2param', prior = prior_rates, params = ['exp_i', 'exp_p'])\n",
    "\n",
    "# Bayes factor, 3 parameters with shared powers\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'permissive', '3param_sharedpowers', prior = prior_rates, params = ['exp_i', 'con_i', 'exp_p'])\n",
    "\n",
    "# Bayes factor, 3 parameters with shared constants\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'permissive', '3param_sharedconstants', prior = prior_rates, params = ['exp_i', 'exp_p', 'con_p'])\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PL', 'permissive', '3param_Mult', prior = prior_rates, params = ['M', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc328147-dee3-45f4-bb60-b563b030f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_params['PL']['uniform'] = pd.concat(avg_params['PL']['uniform']).unstack()\n",
    "avg_params['PL']['restrictive'] = pd.concat(avg_params['PL']['restrictive']).unstack()\n",
    "avg_params['PL']['permissive'] = pd.concat(avg_params['PL']['permissive']).unstack()\n",
    "avg_params['PL'] = pd.concat(avg_params['PL'])\n",
    "\n",
    "best_params['PL']['uniform'] = pd.concat(best_params['PL']['uniform']).unstack()\n",
    "best_params['PL']['restrictive'] = pd.concat(best_params['PL']['restrictive']).unstack()\n",
    "best_params['PL']['permissive'] = pd.concat(best_params['PL']['permissive']).unstack()\n",
    "best_params['PL'] = pd.concat(best_params['PL'])\n",
    "\n",
    "drl_weighted_avg['PL']['uniform'] = pd.concat(drl_weighted_avg['PL']['uniform']).unstack()\n",
    "drl_weighted_avg['PL']['restrictive'] = pd.concat(drl_weighted_avg['PL']['restrictive']).unstack()\n",
    "drl_weighted_avg['PL']['permissive'] = pd.concat(drl_weighted_avg['PL']['permissive']).unstack()\n",
    "drl_weighted_avg['PL'] = pd.concat(drl_weighted_avg['PL'])\n",
    "\n",
    "rates_weighted_exp['PL']['uniform'] = pd.concat(rates_weighted_exp['PL']['uniform']).unstack().T\n",
    "rates_weighted_exp['PL']['restrictive'] = pd.concat(rates_weighted_exp['PL']['restrictive']).unstack().T\n",
    "rates_weighted_exp['PL']['permissive'] = pd.concat(rates_weighted_exp['PL']['permissive']).unstack().T\n",
    "rates_weighted_exp['PL'] = pd.concat(rates_weighted_exp['PL'])\n",
    "\n",
    "rates_weighted_con['PL']['uniform'] = pd.concat(rates_weighted_con['PL']['uniform']).unstack().T\n",
    "rates_weighted_con['PL']['restrictive'] = pd.concat(rates_weighted_con['PL']['restrictive']).unstack().T\n",
    "rates_weighted_con['PL']['permissive'] = pd.concat(rates_weighted_con['PL']['permissive']).unstack().T\n",
    "rates_weighted_con['PL'] = pd.concat(rates_weighted_con['PL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61359ab0-3b62-4709-8567-f007064332b9",
   "metadata": {},
   "source": [
    "### Power-law model with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c30fe1-c6ef-4506-a7cb-3b1bcf1f0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with pseudocount\n",
    "inference_grid_final_interp_subonly_norm_ps = (inference_grid_final_interp_subonly.reindex(L_range).fillna(0) + pseudocount) / (inference_grid_final_interp_subonly.reindex(L_range).fillna(0) + pseudocount).sum()\n",
    "# Calculate KL\n",
    "KL_inference_grid_final_interp = inference_grid_final_interp_subonly_norm_ps.apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range))\n",
    "# Calculate acceptance probability\n",
    "grid_likelihood = calc_likelihood_from_primate_metric_KL(KL_inference_grid_final_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8dc1c-217f-44ad-978c-0415202caaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid of rates\n",
    "rates_all_interp = pd.DataFrame([intercept_then_powerlaw(exp_p, con_p, exp_i, con_i, interp = True) for (exp_i, con_i, exp_p, con_p,) in grid_likelihood.index], index = grid_likelihood.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff585b-72a3-4bac-a989-604ec35e686b",
   "metadata": {},
   "source": [
    "#### Calculate Bayes factors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717dbb3c-6042-45ca-ad63-0804311407a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors['PLinterp'] = dict(); best_params['PLinterp'] = dict(); avg_params['PLinterp'] = dict(); drl_weighted_avg['PLinterp'] = dict(); posteriors_all['PLinterp'] = dict(); posterior_95c['PLinterp'] = dict(); grid_drl_95c['PLinterp'] = dict(); rates_weighted_exp['PLinterp'] = dict(); rates_weighted_con['PLinterp'] = dict(); grid_rates_95c['PLinterp'] = dict(); subset_indices['PLinterp'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e520c0-ed1f-4e68-a484-fdd781ba7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform prior\n",
    "bayesfactors['PLinterp']['uniform'] = dict(); best_params['PLinterp']['uniform'] = dict(); avg_params['PLinterp']['uniform'] = dict(); drl_weighted_avg['PLinterp']['uniform'] = dict(); posteriors_all['PLinterp']['uniform'] = dict(); posterior_95c['PLinterp']['uniform'] = dict(); grid_drl_95c['PLinterp']['uniform'] = dict(); rates_weighted_exp['PLinterp']['uniform'] = dict(); rates_weighted_con['PLinterp']['uniform'] = dict(); grid_rates_95c['PLinterp']['uniform'] = dict()\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "subset_indices['PLinterp']['3param_Mult'] = partial_grid.set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).index\n",
    "model_summary(partial_grid, 'PLinterp', 'uniform', '3param_Mult', prior = None, params = ['M', 'exp_p', 'con_p'], grid_drl = inference_grid_final_interp_subonly_norm_ps, rates=rates_all_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9c741-08ac-42a0-a098-4c0f8de46d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrictive prior\n",
    "prior_rates = pd.read_pickle('simulations/grid_4param_v2/prior_restrictive_a.pickle')\n",
    "prior_rates = prior_rates.reindex(grid_likelihood.index)\n",
    "prior_rates /= prior_rates.sum()\n",
    "\n",
    "# restrictive prior\n",
    "bayesfactors['PLinterp']['restrictive'] = dict(); best_params['PLinterp']['restrictive'] = dict(); avg_params['PLinterp']['restrictive'] = dict(); drl_weighted_avg['PLinterp']['restrictive'] = dict(); posteriors_all['PLinterp']['restrictive'] = dict(); posterior_95c['PLinterp']['restrictive'] = dict(); grid_drl_95c['PLinterp']['restrictive'] = dict(); rates_weighted_exp['PLinterp']['restrictive'] = dict(); rates_weighted_con['PLinterp']['restrictive'] = dict(); grid_rates_95c['PLinterp']['restrictive'] = dict()\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PLinterp', 'restrictive', '3param_Mult', prior = prior_rates, params = ['M', 'exp_p', 'con_p'], grid_drl = inference_grid_final_interp_subonly_norm_ps, rates=rates_all_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d660cc-13a3-43bc-863d-545d4c3fc05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permissive prior\n",
    "prior_rates = pd.read_pickle('simulations/grid_4param_v2/prior_a.pickle')\n",
    "prior_rates = prior_rates.reindex(grid_likelihood.index)\n",
    "prior_rates /= prior_rates.sum()\n",
    "\n",
    "# permissive prior\n",
    "bayesfactors['PLinterp']['permissive'] = dict(); best_params['PLinterp']['permissive'] = dict(); avg_params['PLinterp']['permissive'] = dict(); drl_weighted_avg['PLinterp']['permissive'] = dict(); posteriors_all['PLinterp']['permissive'] = dict(); posterior_95c['PLinterp']['permissive'] = dict(); grid_drl_95c['PLinterp']['permissive'] = dict(); rates_weighted_exp['PLinterp']['permissive'] = dict(); rates_weighted_con['PLinterp']['permissive'] = dict(); grid_rates_95c['PLinterp']['permissive'] = dict()\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'PLinterp', 'permissive', '3param_Mult', prior = prior_rates, params = ['M', 'exp_p', 'con_p'], grid_drl = inference_grid_final_interp_subonly_norm_ps, rates=rates_all_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c23d9-4a3d-4fed-8cf7-0356f66f66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_params['PLinterp']['uniform'] = pd.concat(avg_params['PLinterp']['uniform']).unstack()\n",
    "avg_params['PLinterp']['restrictive'] = pd.concat(avg_params['PLinterp']['restrictive']).unstack()\n",
    "avg_params['PLinterp']['permissive'] = pd.concat(avg_params['PLinterp']['permissive']).unstack()\n",
    "avg_params['PLinterp'] = pd.concat(avg_params['PLinterp'])\n",
    "\n",
    "best_params['PLinterp']['uniform'] = pd.concat(best_params['PLinterp']['uniform']).unstack()\n",
    "best_params['PLinterp']['restrictive'] = pd.concat(best_params['PLinterp']['restrictive']).unstack()\n",
    "best_params['PLinterp']['permissive'] = pd.concat(best_params['PLinterp']['permissive']).unstack()\n",
    "best_params['PLinterp'] = pd.concat(best_params['PLinterp'])\n",
    "\n",
    "drl_weighted_avg['PLinterp']['uniform'] = pd.concat(drl_weighted_avg['PLinterp']['uniform']).unstack()\n",
    "drl_weighted_avg['PLinterp']['restrictive'] = pd.concat(drl_weighted_avg['PLinterp']['restrictive']).unstack()\n",
    "drl_weighted_avg['PLinterp']['permissive'] = pd.concat(drl_weighted_avg['PLinterp']['permissive']).unstack()\n",
    "drl_weighted_avg['PLinterp'] = pd.concat(drl_weighted_avg['PLinterp'])\n",
    "\n",
    "rates_weighted_exp['PLinterp']['uniform'] = pd.concat(rates_weighted_exp['PLinterp']['uniform']).unstack().T\n",
    "rates_weighted_exp['PLinterp']['restrictive'] = pd.concat(rates_weighted_exp['PLinterp']['restrictive']).unstack().T\n",
    "rates_weighted_exp['PLinterp']['permissive'] = pd.concat(rates_weighted_exp['PLinterp']['permissive']).unstack().T\n",
    "rates_weighted_exp['PLinterp'] = pd.concat(rates_weighted_exp['PLinterp'])\n",
    "\n",
    "rates_weighted_con['PLinterp']['uniform'] = pd.concat(rates_weighted_con['PLinterp']['uniform']).unstack().T\n",
    "rates_weighted_con['PLinterp']['restrictive'] = pd.concat(rates_weighted_con['PLinterp']['restrictive']).unstack().T\n",
    "rates_weighted_con['PLinterp']['permissive'] = pd.concat(rates_weighted_con['PLinterp']['permissive']).unstack().T\n",
    "rates_weighted_con['PLinterp'] = pd.concat(rates_weighted_con['PLinterp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40457d92-4958-405e-845b-f847c6cce165",
   "metadata": {},
   "source": [
    "## Plot posterior distributions\n",
    "- posterior contours (highest density range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee385c3f-9f34-4245-9642-c5b924c305ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_revlist = pd.Series(intercept_list).reset_index().set_index([0])['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c7941-0841-4804-9733-414b0f359b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = [0, 0.682689492137086, 0.954499736103642, 0.997300203936740, 0.999936657516334, 1]\n",
    "discrete_deep = plotly.colors.make_colorscale(plotly.colors.sample_colorscale('deep', np.linspace(0,1,5)))\n",
    "discrete_deep_range = [[0.0, 'rgb(253, 253, 204)'],\n",
    " [0.249999999, 'rgb(253, 253, 204)'],\n",
    " [0.25, 'rgb(122, 205, 163)'],\n",
    " [0.4999999999, 'rgb(122, 205, 163)'],\n",
    " [0.5, 'rgb(72, 142, 158)'],\n",
    " [0.7499999999, 'rgb(72, 142, 158)'],\n",
    " [0.75, 'rgb(62, 77, 136)'],\n",
    " [0.9999999999, 'rgb(62, 77, 136)'],\n",
    " [1.0, 'rgb(39, 26, 44)'], ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc727dc2-e4f2-4002-9522-fc33b61ffbd8",
   "metadata": {},
   "source": [
    "#### 4 parameter power-law model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950df98-f43d-4b80-a50e-faa2a2ae9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_posterior = posteriors_all['PL']['uniform']['4param'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2816cc-e515-4d28-afbe-8aef9ec549f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S10a\n",
    "fig = make_subplots(rows = 8, cols = 8, shared_xaxes = True, shared_yaxes = True, vertical_spacing = 0.015, horizontal_spacing = 0.008, row_titles = ['<i>c</i><sub>ùúÖ</sub>=' + '{:.2e}'.format(x) for x in intercept_list[::-1]], column_titles = ['<i>c</i><sub>ùúÄ</sub>=' + '{:.2e}'.format(x) for x in intercept_list], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "col_count = 0\n",
    "for exp_i in intercept_list:\n",
    "    row_count=0; col_count +=1\n",
    "    for con_i in intercept_list[::-1]:\n",
    "        row_count+=1\n",
    "        fig.add_trace(go.Heatmap(x = posterior_contour.loc[exp_i].loc[con_i].index.get_level_values(0), y = posterior_contour.loc[exp_i].loc[con_i].index.get_level_values(1), z=(posterior_contour.loc[exp_i].loc[con_i]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', col = 1 + intercept_revlist.loc[current_posterior.iloc[0]['exp_i']], row = 8 - intercept_revlist.loc[current_posterior.iloc[0]['con_i']])\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.25, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%']), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 1000, width = 1200, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838c73c-be76-4a7f-af5c-9d10e7122adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/posterior_dist_contour_PL_4param_uniform.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c385a-9a1b-4a4d-82c5-246c3099710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S10b\n",
    "current_posterior = posteriors_all['PL']['permissive']['4param'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_subplots(rows = 8, cols = 8, shared_xaxes = True, shared_yaxes = True, vertical_spacing = 0.015, horizontal_spacing = 0.008, row_titles = ['<i>c</i><sub>ùúÖ</sub>=' + '{:.2e}'.format(x) for x in intercept_list[::-1]], column_titles = ['<i>c</i><sub>ùúÄ</sub>=' + '{:.2e}'.format(x) for x in intercept_list], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "col_count = 0\n",
    "for exp_i in intercept_list:\n",
    "    row_count=0; col_count +=1\n",
    "    for con_i in intercept_list[::-1]:\n",
    "        row_count+=1\n",
    "        fig.add_trace(go.Heatmap(x = posterior_contour.loc[exp_i].loc[con_i].index.get_level_values(0), y = posterior_contour.loc[exp_i].loc[con_i].index.get_level_values(1), z=(posterior_contour.loc[exp_i].loc[con_i]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', col = 1 + intercept_revlist.loc[current_posterior.iloc[0]['exp_i']], row = 8 - intercept_revlist.loc[current_posterior.iloc[0]['con_i']])\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.25, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%']), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 1000, width = 1200, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.write_image('plots/posterior_dist_contour_PL_4param_permissive.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63419ed-645d-4c7d-8ea2-a2b8ca429a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S10c\n",
    "current_posterior = posteriors_all['PL']['restrictive']['4param'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_subplots(rows = 8, cols = 8, shared_xaxes = True, shared_yaxes = True, vertical_spacing = 0.015, horizontal_spacing = 0.008, row_titles = ['<i>c</i><sub>ùúÖ</sub>=' + '{:.2e}'.format(x) for x in intercept_list[::-1]], column_titles = ['<i>c</i><sub>ùúÄ</sub>=' + '{:.2e}'.format(x) for x in intercept_list], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "col_count = 0\n",
    "for exp_i in intercept_list:\n",
    "    row_count=0; col_count +=1\n",
    "    for con_i in intercept_list[::-1]:\n",
    "        row_count+=1\n",
    "        fig.add_trace(go.Heatmap(x = posterior_contour.loc[exp_i].loc[con_i].index.get_level_values(0), y = posterior_contour.loc[exp_i].loc[con_i].index.get_level_values(1), z=(posterior_contour.loc[exp_i].loc[con_i]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', col = 1 + intercept_revlist.loc[current_posterior.iloc[0]['exp_i']], row = 8 - intercept_revlist.loc[current_posterior.iloc[0]['con_i']])\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.25, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%']), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 1000, width = 1200, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.write_image('plots/posterior_dist_contour_PL_4param_restrictive.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31461022-98b1-4152-8297-3792692d6b02",
   "metadata": {},
   "source": [
    "#### nested model figure (Fig. S16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7a487-968e-4803-bdc5-59b50175f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested = posteriors_all['PL']['uniform']['4param'].copy()\n",
    "nested['category'] = 1\n",
    "nested['category'] = 3*nested.where(nested['exp_i'] == nested['con_i'])['category'].fillna(0) + nested.where(nested['exp_p'] == nested['con_p'])['category'].fillna(0) + 2* nested.where(pd.Series(intercept_revlist.reindex(nested['exp_i']).values == intercept_revlist.reindex(nested['con_i']).values +1, index = nested.index))['category'].fillna(0) - 2* nested.where((nested['exp_p'] == nested['con_p']) & pd.Series(intercept_revlist.reindex(nested['exp_i']).values == intercept_revlist.reindex(nested['con_i']).values +1, index = nested.index))['category'].fillna(0)\n",
    "nested.set_index(['exp_i', 'con_i', 'exp_p', 'con_p'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16aa53-3ad5-47d6-a93d-82ab86fc65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_colors = [[0, plotly.colors.DEFAULT_PLOTLY_COLORS[7]],\n",
    " [0.19999999, plotly.colors.DEFAULT_PLOTLY_COLORS[7]],\n",
    " [0.2, plotly.colors.DEFAULT_PLOTLY_COLORS[1]],\n",
    " [0.399999999, plotly.colors.DEFAULT_PLOTLY_COLORS[1]],\n",
    " [0.4, plotly.colors.DEFAULT_PLOTLY_COLORS[2]],\n",
    " [0.5999999999, plotly.colors.DEFAULT_PLOTLY_COLORS[2]],\n",
    " [0.6, plotly.colors.DEFAULT_PLOTLY_COLORS[4]],\n",
    " [0.7999999999, plotly.colors.DEFAULT_PLOTLY_COLORS[4]],\n",
    " [0.8, plotly.colors.DEFAULT_PLOTLY_COLORS[0]],\n",
    " [1, plotly.colors.DEFAULT_PLOTLY_COLORS[0]],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de451d0-5b47-4b2d-9c5a-3e91eacf87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 8, cols = 8, shared_xaxes = True, shared_yaxes = True, vertical_spacing = 0.015, horizontal_spacing = 0.008, row_titles = ['<i>c</i><sub>ùúÖ</sub>=' + '{:.2e}'.format(x) for x in intercept_list[::-1]], column_titles = ['<i>c</i><sub>ùúÄ</sub>=' + '{:.2e}'.format(x) for x in intercept_list], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "col_count = 0\n",
    "for exp_i in intercept_list:\n",
    "    row_count=0; col_count +=1\n",
    "    for con_i in intercept_list[::-1]:\n",
    "        row_count+=1\n",
    "        fig.add_trace(go.Heatmap(x = nested.loc[exp_i].loc[con_i].index.get_level_values(0), y = nested.loc[exp_i].loc[con_i].index.get_level_values(1), z=(nested.loc[exp_i].loc[con_i]['category']), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale=cat_colors, colorbar = dict(title = 'Nested parameterizations:', len=0.25, x = 0.05, y = -0.16, tickvals = [0.4,1.2,2,2.8,3.6], ticktext = ['Decoupled power laws', 'Power laws with independent constants ', 'Multiplier-coupled power laws ', 'Power laws with independent exponents', 'Symmetric power law'])))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 1200, width = 1000, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a107a-a356-4570-a940-598d58763ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig_nested_model_diagram.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9838fe-d771-4263-8ac1-bd8a8a9eff28",
   "metadata": {},
   "source": [
    "#### 3 parameter multiplier-coupled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a4620-f4d2-451a-8d8c-7626f2ce55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list = intercept_list[1:]/ intercept_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1d3c4-6692-4856-915c-fc01eeeb179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 5a\n",
    "fig = make_subplots(rows = 2, cols = 7, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.02, vertical_spacing = 0.08, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[1:]], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "\n",
    "current_posterior = posteriors_all['PL']['uniform']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "posterior_contour_3M_pro_uni = posterior_contour.copy()\n",
    "row_count=1; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 1, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "current_posterior = posteriors_all['PL']['restrictive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=2; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 2, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.85, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%'], x = 1.02), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 310, width = 1000, margin={'t':50,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b26644-0753-497f-8e42-46e4e164df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/posterior_dist_contour_PL_3mult_uniform_restrictive.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a295ed-bcfe-433e-bb25-fc13165519d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S7a\n",
    "fig = make_subplots(rows = 3, cols = 7, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.02, vertical_spacing = 0.08, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[1:]], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "\n",
    "current_posterior = posteriors_all['PL']['uniform']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=1; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 1, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "current_posterior = posteriors_all['PL']['permissive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=2; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 2, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "current_posterior = posteriors_all['PL']['restrictive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=3; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 3, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.55, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%'], x = 1.05), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 420, width = 1000, margin={'t':50,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5506b-d15d-4edc-a400-f395e10d8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/posterior_dist_contour_PL_3mult_uniform_permissive_restrictive.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e9b0d-4fca-421d-be30-de2d392d66d7",
   "metadata": {},
   "source": [
    "#### 3 parameter power-law model with interpolation (Fig. S8a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2b6b4-5136-48c0-a588-c6108f944715",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 3, cols = 7, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.02, vertical_spacing = 0.08, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[1:]], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "\n",
    "current_posterior = posteriors_all['PLinterp']['uniform']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=1; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 1, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "current_posterior = posteriors_all['PLinterp']['permissive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=2; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 2, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "current_posterior = posteriors_all['PLinterp']['restrictive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=3; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 3, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.55, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%'], x = 1.05), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 420, width = 1000, margin={'t':50,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffd024-bd19-4f0e-b241-36c7bd32b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/posterior_dist_contour_PL_3mult_uniform_permissive_restrictive_interp.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680b895-472c-45b3-9b9d-2f87de498dcd",
   "metadata": {},
   "source": [
    "## Plot HDR range and posterior-weighted DRLs and rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac628be-75cf-4722-afbc-2966f0164dd8",
   "metadata": {},
   "source": [
    "#### Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f32cfa-11d0-45a3-a0d5-a712f59fc7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fig_list_contour(grid_drl, contour, motif='A', showgroups = [2,1,0], norm_range = range(4,201), xrange = False, tracename = None):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if norm_range != False:\n",
    "        grid_drl = grid_drl.copy().mul(bootstrap_counts_mean[motif].reindex(norm_range).sum())\n",
    "\n",
    "    if contour is not None:\n",
    "        for group in showgroups:\n",
    "            current_contour = contour.loc[contour['level_0'] == group].copy().reset_index()\n",
    "            if xrange == False:\n",
    "                current_contour['exp_i'] = intercept_revlist.reindex(current_contour['exp_i']).values\n",
    "                current_contour['con_i'] = intercept_revlist.reindex(current_contour['con_i']).values\n",
    "            current_contour.set_index(['exp_i', 'con_i', 'exp_p', 'con_p'], inplace = True)\n",
    "            current_drl = grid_drl.reindex(current_contour.index, axis=1)\n",
    "            \n",
    "            fig.add_trace(go.Scatter(x = (current_drl.index) * len(motif), y = current_drl.min(axis=1), mode = 'lines', line = dict(width=0 if list(current_drl.min(axis=1)) != list(current_drl.max(axis=1)) else 4, color = discrete_deep[group][1]), legendgroup = group, showlegend = False, name = group if tracename is None else tracename))\n",
    "            fig.add_trace(go.Scatter(x = (current_drl.index) * len(motif), y = current_drl.max(axis=1), fill = 'tonexty', fillcolor = 'rgba(' + pd.DataFrame(discrete_deep)[1][group][4:-1] + ', 0.8)' if len(showgroups) != 1 else 'rgba(' + pd.DataFrame(discrete_deep)[1][1][4:-1] + ', 0.5)', mode = 'lines', line = dict(width = 0, color = discrete_deep[group][1]), legendgroup = group, name = group if tracename is None else tracename))\n",
    "    \n",
    "\n",
    "    fig.add_trace(go.Scatter(x = primate_CI_high.dropna().index, y= primate_CI_high.dropna(), line = dict(width = 1, color = plotly.colors.DEFAULT_PLOTLY_COLORS[4]), legendgroup = 'primate', showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x = primate_CI_low.dropna().index, y= primate_CI_low.dropna(), line = dict(width = 1, color = plotly.colors.DEFAULT_PLOTLY_COLORS[4]), fill = 'tonexty', fillcolor = 'rgba(' + plotly.colors.DEFAULT_PLOTLY_COLORS[4][4:-1] + ', 0.2)', legendgroup = 'primate', name = 'primate range'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index * len(motif), y = bootstrap_counts_mean[motif], line = dict(width = 4, color = 'rgba(0,0,0,0.8)'), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "\n",
    "    fig.update_yaxes(type = 'log', title = 'counts <i>(normalized counts)</i>', range = [-0.05,9.05], ticktext = ['<b>1e8</b><br><i>(8e-2)</i>', '<b>1e6</b><br><i>(8e-4)</i>', '<b>1e4</b><br><i>(8e-6)</i>', '<b>1e2</b><br><i>(8e-8)</i>', '<b>1</b><br><i>(8e-10) </i>'], tickvals = [1e8, 1e6, 1e4, 1e2, 1])\n",
    "#    fig.update_yaxes(type = 'log', title = '<b>counts</b> <i>(normalized counts)</i>', range = [-0.05,9.05], ticktext = ['<i>(9e-1)</i>', '<b>1e8</b>', '<i>(8e-3)</i>', '<b>1e6</b>', '<i>(8e-5)</i>', '<b>1e4</b>', '<i>(8e-7)</i>', '<b>1e2</b>', '<i>(7e-9)</i>', '<b>1</b>'], tickvals = [1e9,1e8,1e7,1e6,1e5,1e4,1e3,1e2,1e1,1])\n",
    "    fig.update_xaxes(type = 'log', title = 'repeat tract length (units)', range = [-0.005,2.33], tickvals = [1,2,5,10,20,50,100,200], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig.update_yaxes(gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig.update_layout(width = 1000, height = 500, font=dict(family = 'Arial', size = 20), margin={'t':20,'l':100,'b':50,'r':10})\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2d585-f630-4bed-9fc3-0d3b58d6ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fig_rates_list_contour(contour, rates = rates_all, show_decode = True, priorname = 'uniform'):\n",
    "    fig_rates = go.Figure()\n",
    "    # denovo\n",
    "    fig_rates.add_trace(go.Scatter(x = denovo_exp_rate['A'].loc[:8].index, y = denovo_exp_rate['A'].loc[:8], mode = 'markers', marker = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], symbol = 'square-open', line_width = 4, size = 8), name = 'Exp. (pooled trios)'))\n",
    "    fig_rates.add_trace(go.Scatter(x = denovo_con_rate['A'].loc[:8].index, y = denovo_con_rate['A'].loc[:8], mode = 'markers', marker = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], symbol = 'square-open', line_width = 4, size = 8), name = 'Con. (pooled trios)'))\n",
    "    # deCODE\n",
    "    if show_decode == True:\n",
    "        fig_rates.add_trace(go.Scatter(x = decode_exp_rate['A'].index, y = decode_exp_rate['A'], mode = 'markers', marker = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], symbol = 'circle-open', line_width = 4, size = 8), name = 'Exp./ins. (popSTR)'))\n",
    "        fig_rates.add_trace(go.Scatter(x = decode_con_rate['A'].index, y = decode_con_rate['A'], mode = 'markers', marker = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], symbol = 'circle-open', line_width = 4, size = 8), name = 'Con. (popSTR)'))\n",
    "    \n",
    "\n",
    "    if contour is not None:\n",
    "        current_contour = contour.loc[contour['level_0'] == 1].copy().reset_index()\n",
    "        current_contour['exp_i'] = intercept_revlist.reindex(current_contour['exp_i']).values\n",
    "        current_contour['con_i'] = intercept_revlist.reindex(current_contour['con_i']).values\n",
    "        current_contour.set_index(['exp_i', 'con_i', 'exp_p', 'con_p'], inplace = True)\n",
    "        current_exp = pd.concat(list(rates[1].reindex(current_contour.index)), axis=1)\n",
    "        current_con = pd.concat(list(rates[2].reindex(current_contour.index)), axis=1)\n",
    "    \n",
    "        fig_rates.add_trace(go.Scatter(x = (current_exp.index), y = current_exp.min(axis=1), mode = 'lines', line = dict(width = 0, color = plotly.colors.DEFAULT_PLOTLY_COLORS[0]), legendgroup = 'exp', name = 'exp', showlegend = False))\n",
    "        fig_rates.add_trace(go.Scatter(x = (current_exp.index), y = current_exp.max(axis=1), fill = 'tonexty', fillcolor = 'rgba(' + plotly.colors.DEFAULT_PLOTLY_COLORS[0][4:-1] + ', 0.2)', mode = 'lines', line = dict(width = 0, color = plotly.colors.DEFAULT_PLOTLY_COLORS[0]), legendgroup = 'exp', name = 'ùúÄ 95% HDR (' + priorname + ')'))\n",
    "    \n",
    "        fig_rates.add_trace(go.Scatter(x = (current_con.index), y = current_con.min(axis=1), mode = 'lines', line = dict(width = 0, color = plotly.colors.DEFAULT_PLOTLY_COLORS[1]), legendgroup = 'con', name = 'con', showlegend = False))\n",
    "        fig_rates.add_trace(go.Scatter(x = (current_con.index), y = current_con.max(axis=1), fill = 'tonexty', fillcolor = 'rgba(' + plotly.colors.DEFAULT_PLOTLY_COLORS[1][4:-1] + ', 0.2)', mode = 'lines', line = dict(width = 0, color = plotly.colors.DEFAULT_PLOTLY_COLORS[1]), legendgroup = 'con', name = 'ùúÖ 95% HDR (' + priorname + ')'))\n",
    "   \n",
    "    fig_rates.update_yaxes(type = 'log', title = 'rate (per nt per generation)', range = [-12, -3], tickformat = '1.0e', dtick = 2)\n",
    "    fig_rates.update_xaxes(type = 'log', title = 'repeat tract length (units)', range = [-0.05,2.33], tickvals = [1,2,5,10,20,50,100,200], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig_rates.update_yaxes(gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig_rates.update_layout(width = 900, height = 500, font=dict(family = 'Arial', size = 20), margin={'t':20,'l':100,'b':50,'r':10})\n",
    "    return fig_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101d84a-5cd9-4ebb-ac1e-ead4a8b6425f",
   "metadata": {},
   "source": [
    "#### 3 parameter multiplier-coupled power-law model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bdb728-44d7-4c07-be8b-dd928cd24200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 5b\n",
    "current_model = 'PL'; current_prior = 'uniform'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_fig_list_contour(inference_grid_final_nointerp_subonly_norm_ps, posterior_contour, norm_range=(range(4,201)), showgroups=[1], tracename = '95% HDR (uniform prior)')\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].loc[current_prior].loc[current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (uninformative)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], width = 3)))\n",
    "#fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['permissive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (permissive)', line = dict(width = 3, dash = 'dash', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['restrictive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (informative)', line = dict(width = 3, dash = 'dot', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836fa3c-0f1b-4840-a145-fb2fc465f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_95HDR_PL_uniform_3mult.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4f957-7444-4abe-a259-22dbe0ab58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S7b (1of3)\n",
    "current_model = 'PL'; current_prior = 'uniform'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_fig_list_contour(inference_grid_final_nointerp_subonly_norm_ps, posterior_contour, norm_range=(range(4,201)), showgroups=[3,2,1,0])\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].loc[current_prior].loc[current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL<br>(uniform)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[3], dash = 'dash', width = 4)))\n",
    "fig.update_layout(width = 800, height = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6fcbe6-35c2-4804-b785-d5d2452acfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_CDFbands_PL_uniform_3mult.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef19067-b42a-4cae-98eb-2817f0700a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S7b (2of3)\n",
    "current_model = 'PL'; current_prior = 'permissive'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_fig_list_contour(inference_grid_final_nointerp_subonly_norm_ps, posterior_contour, norm_range=(range(4,201)), showgroups=[3,2,1,0])\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].loc[current_prior].loc[current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL<br>(permissive)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[3], dash = 'dash', width = 4)))\n",
    "fig.update_layout(width = 800, height = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dc133-33a6-4f8a-b731-18691b0196fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_CDFbands_PL_permissive_3mult.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4010b-4be8-467b-af37-b7f2e4f4a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S7b (3of3)\n",
    "current_model = 'PL'; current_prior = 'restrictive'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_fig_list_contour(inference_grid_final_nointerp_subonly_norm_ps, posterior_contour, norm_range=(range(4,201)), showgroups=[3,2,1,0])\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].loc[current_prior].loc[current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL<br>(restrictive)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[3], dash = 'dash', width = 4)))\n",
    "fig.update_layout(width = 800, height = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620de2b6-93b8-4b0d-b7ec-b61587967861",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_CDFbands_PL_restrictive_3mult.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf47bdd-6313-4d70-96ad-8c36846da879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 5c\n",
    "fig_rates = make_fig_rates_list_contour(None, rates_all)\n",
    "for prior, priorname, dash in zip(['uniform', 'restrictive'], ['uninformative', 'informative'], [None, 'dot']):\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_exp[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], dash = dash, width = 4), name = 'weighted ùúÄ|<i>L</i> (' + priorname + ')',))\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_con[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], dash = dash, width = 4), name = 'weighted ùúÖ|<i>L</i> (' + priorname + ')',))\n",
    "fig_rates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d569e-7f43-40cb-9217-a20e03fdb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/rates_95c_weighted_PL_allpriors_3mult.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db0e21-b7a3-424c-b1c7-d7bd327d0d89",
   "metadata": {},
   "source": [
    "#### 3 parameter multiplier-coupled power-law model with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b7da5-2e7c-4274-9b96-5ca90fceb76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S8b\n",
    "current_model = 'PLinterp'; current_prior = 'uniform'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_fig_list_contour(inference_grid_final_interp_subonly_norm_ps, posterior_contour, norm_range=(range(4,201)), showgroups=[1], tracename = '95% HDR (uniform prior)')\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].loc[current_prior].loc[current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (uniform)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], width = 3)))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['permissive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (permissive)', line = dict(width = 3, dash = 'dash', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['restrictive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (restrictive)', line = dict(width = 3, dash = 'dot', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c5035-b66f-45c4-89e5-68530eb21740",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_95HDR_PLinterp_uniform_3mult.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d19aa-fc63-4c3a-8311-3eb9ca0dbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S8c\n",
    "fig_rates = make_fig_rates_list_contour(None, rates_all)\n",
    "for prior, dash in zip(['uniform', 'permissive', 'restrictive'], [None, 'dash', 'dot']):\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_exp[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], dash = dash, width = 4), name = 'weighted ùúÄ|<i>L</i> (' + prior + ')',))\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_con[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], dash = dash, width = 4), name = 'weighted ùúÖ|<i>L</i> (' + prior + ')',))\n",
    "fig_rates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e00386f-608d-46b8-9818-27097be0e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/rates_95c_weighted_PLinterp_allpriors_3mult.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dfab7-91fe-4a09-93f2-e1ee98812493",
   "metadata": {},
   "source": [
    "#### 4 parameter power-law model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3ca2c-5afb-47f3-943c-8c75fda33f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 10b\n",
    "current_model = 'PL'; current_prior = 'uniform'; current_param = '4param'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "\n",
    "fig = make_fig_list_contour(inference_grid_final_nointerp_subonly_norm_ps, posterior_contour, norm_range=(range(4,201)), showgroups=[1], tracename = '95% HDR (uniform prior)')\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].loc[current_prior].loc[current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (uniform)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], width = 3)))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['permissive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (permissive)', line = dict(width = 3, dash = 'dash', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['restrictive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (restrictive)', line = dict(width = 3, dash = 'dot', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de100022-dd44-4efd-ae34-a5e8a756c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_95HDR_PL_uniform_4param.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7122f10d-7b9f-4ed4-b67c-e333894a0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 10c\n",
    "fig_rates = make_fig_rates_list_contour(None, rates_all)\n",
    "for prior, dash in zip(['uniform', 'permissive', 'restrictive'], [None, 'dash', 'dot']):\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_exp[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], dash = dash, width = 4), name = 'weighted ùúÄ|<i>L</i> (' + prior + ')',))\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_con[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], dash = dash, width = 4), name = 'weighted ùúÖ|<i>L</i> (' + prior + ')',))\n",
    "fig_rates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04685fff-90aa-43d2-ac66-c71335850b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/rates_95c_weighted_PL_allpriors_4param.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a46eb-b660-41b7-8a44-0783217031f0",
   "metadata": {},
   "source": [
    "## range of Lfis values (for Supplementary Note 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f07111-470f-4e2d-a3af-1eaf97c12c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfis_PL_uniform = posteriors_all['PL']['uniform']['3param_Mult'].copy()\n",
    "Lfis_PL_uniform['Lfis'] = 9*((denovo_substitution_context_rate.loc['A']['Afission'] / (Lfis_PL_uniform['M'] * denovo_nonexp_rate['A'][8]))**(1/Lfis_PL_uniform['exp_p'])).replace(np.inf, np.nan)\n",
    "Lfis_PL_uniform = Lfis_PL_uniform.dropna()\n",
    "num95 = (posteriors_all['PL']['uniform']['3param_Mult'][0].sort_values(ascending = False).cumsum() < 0.95).reset_index(drop=True).idxmin()\n",
    "Lfis_PL_uniform.sort_values(by = [0], ascending = False)[:num95]['Lfis'].median()\n",
    "np.average(Lfis_PL_uniform['Lfis'], weights = Lfis_PL_uniform[0]), Lfis_PL_uniform.sort_values(by = [0], ascending = False)[:num95]['Lfis'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79616a10-1426-4c0e-acbc-71f568563291",
   "metadata": {},
   "outputs": [],
   "source": [
    " Lfis_PL_uniform.sort_values(by = [0], ascending = False)[:num95]['Lfis'].min(),  Lfis_PL_uniform.sort_values(by = [0], ascending = False)[:num95]['Lfis'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549437f3-858a-454c-9202-0fb2c58bbfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfis_PL_permissive = posteriors_all['PL']['permissive']['3param_Mult'].copy()\n",
    "Lfis_PL_permissive['Lfis'] = 9*((denovo_substitution_context_rate.loc['A']['Afission'] / (Lfis_PL_permissive['M'] * denovo_nonexp_rate['A'][8]))**(1/Lfis_PL_permissive['exp_p'])).replace(np.inf, np.nan)\n",
    "Lfis_PL_permissive = Lfis_PL_permissive.dropna()\n",
    "num95 = (posteriors_all['PL']['permissive']['3param_Mult'][0].sort_values(ascending = False).cumsum() < 0.95).reset_index(drop=True).idxmin()\n",
    "np.average(Lfis_PL_permissive['Lfis'], weights = Lfis_PL_permissive[0]), Lfis_PL_permissive.sort_values(by = [0], ascending = False)[:num95]['Lfis'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024194f-05d4-4d50-a53a-c94c6f2fe1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    " Lfis_PL_permissive.sort_values(by = [0], ascending = False)[:num95]['Lfis'].min(),  Lfis_PL_permissive.sort_values(by = [0], ascending = False)[:num95]['Lfis'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1275c6a-1f3c-45da-a310-c4b19f04f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfis_PL_restrictive = posteriors_all['PL']['restrictive']['3param_Mult'].copy()\n",
    "Lfis_PL_restrictive['Lfis'] = 9*((denovo_substitution_context_rate.loc['A']['Afission'] / (Lfis_PL_restrictive['M'] * denovo_nonexp_rate['A'][8]))**(1/Lfis_PL_restrictive['exp_p'])).replace(np.inf, np.nan)\n",
    "Lfis_PL_restrictive = Lfis_PL_restrictive.dropna()\n",
    "num95 = (posteriors_all['PL']['restrictive']['3param_Mult'][0].sort_values(ascending = False).cumsum() < 0.95).reset_index(drop=True).idxmin()\n",
    "np.average(Lfis_PL_restrictive['Lfis'], weights = Lfis_PL_restrictive[0]), Lfis_PL_restrictive.sort_values(by = [0], ascending = False)[:num95]['Lfis'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7af66-fd54-467c-bd24-228be42dfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    " Lfis_PL_restrictive.sort_values(by = [0], ascending = False)[:num95]['Lfis'].min(),  Lfis_PL_restrictive.sort_values(by = [0], ascending = False)[:num95]['Lfis'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2017f2-85a1-4a2b-b2ea-c5b17b98ca7e",
   "metadata": {},
   "source": [
    "## Constant speedup for 95% HDR of power-law model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f9045-0f3e-4a3f-89aa-3c06473ebb2d",
   "metadata": {},
   "source": [
    "#### Make jobs list for running computational model on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffa4be-eb17-4dac-8e9c-ac1f3c438903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all parameters in the 95% HDR\n",
    "current_posterior = posteriors_all['PL']['uniform']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "hdr95_uniform = posterior_contour.loc[posterior_contour['level_0'] <2]\n",
    "\n",
    "current_posterior = posteriors_all['PL']['permissive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "hdr95_permissive = posterior_contour.loc[posterior_contour['level_0'] <2]\n",
    "\n",
    "current_posterior = posteriors_all['PL']['restrictive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "hdr95_restrictive = posterior_contour.loc[posterior_contour['level_0'] <2]\n",
    "\n",
    "hdr_all = pd.concat([hdr95_uniform, hdr95_permissive, hdr95_restrictive]).reset_index()[['exp_i', 'con_i', 'exp_p', 'con_p']]\n",
    "hdr_all['exp_i'] = intercept_revlist.reindex(hdr_all['exp_i']).values\n",
    "hdr_all['con_i'] = intercept_revlist.reindex(hdr_all['con_i']).values\n",
    "hdr_all = hdr_all.sort_values(by = ['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "\n",
    "hdr_all = pd.Series([(a,b,c,d) for a,b,c,d in zip(hdr_all['exp_i'], hdr_all['con_i'], hdr_all['exp_p'], hdr_all['con_p'])])\n",
    "hdr_all = hdr_all.drop_duplicates()\n",
    "\n",
    "jobs_group = dict()\n",
    "for n in range(round(len(hdr_all)/20)+1):\n",
    "    jobs_group[n] = hdr_all[n*20:n*20+20]\n",
    "jobs_group = pd.concat(jobs_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92178e-f2d8-4cd8-b08a-1bca84d4b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_group.to_pickle('95hdr_all.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d762c2f-b247-4f8c-a2e4-16fb09494616",
   "metadata": {},
   "source": [
    "#### Load data files\n",
    "- note: pause here and run computational model script for the parameter combinations determined above\n",
    "- run 'gather_grid' script to collect this data prior to running below section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbc629-d409-435c-a78f-89f694863d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_95c_constantspeedup_subonly = pd.read_pickle('simulations/completed_grids/top95constant_subonlyrerun.pickle')\n",
    "grid_95c_constantspeedup_subonly_final = pd.read_pickle('simulations/completed_grids/top95constant_subonlyrerun_final.pickle').droplevel(4, axis=1)#.dropna(how = 'all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3074af-6ae6-41fd-b7ab-67d4f0f59fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize counts (with pseudocount)\n",
    "grid_95c_constantspeedup_subonly_final_norm_ps = (grid_95c_constantspeedup_subonly_final.reindex(norm_range).fillna(0) + pseudocount) / (grid_95c_constantspeedup_subonly_final.reindex(norm_range).fillna(0) + pseudocount).sum()\n",
    "grid_95c_constantspeedup_subonly_norm_ps = (grid_95c_constantspeedup_subonly.reindex(norm_range).fillna(0) + pseudocount) / (grid_95c_constantspeedup_subonly.reindex(norm_range).fillna(0) + pseudocount).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7817e-0896-4a14-9ff9-609c6ac906e4",
   "metadata": {},
   "source": [
    "#### Calculate KL for a given timepoint compared to the final timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583f63b-2951-458e-b304-eed80cdf80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_KL_divergence_ab(dist_a, dist_b, L_range = range(4,201)):\n",
    "    return ((dist_a.reindex(L_range)) * np.log((dist_a.reindex(L_range)) / (dist_b.reindex(L_range)))).sum()\n",
    "\n",
    "KLtoend_inference_grid_subonly_timeseries = dict()\n",
    "for time in grid_95c_constantspeedup_subonly_norm_ps.columns.levels[4]:\n",
    "    KLtoend_inference_grid_subonly_timeseries[time] = calc_KL_divergence_ab(grid_95c_constantspeedup_subonly_norm_ps.xs(1e9, 1, level=4), grid_95c_constantspeedup_subonly_norm_ps.xs(time, 1, level=4), L_range=L_range)\n",
    "KLtoend_inference_grid_subonly_timeseries = pd.concat(KLtoend_inference_grid_subonly_timeseries, axis=1)\n",
    "KLtoend_inference_grid_subonly_timeseries = KLtoend_inference_grid_subonly_timeseries.replace(0, np.nan)\n",
    "KLtoend_inference_grid_subonly_timeseries[1e9] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82baa31-cc36-4bae-9a32-575d9f02601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colorscale(list_of_traces, opacity = 0.15):\n",
    "    current_colors = pd.Series(['rgb('+str(current/len(list_of_traces)*255) + ', 180, '+str((len(list_of_traces)-current)/len(list_of_traces)*255)+')' for current in range(len(list_of_traces))], index = list_of_traces)\n",
    "    return pd.Series(current_colors, index = list_of_traces), pd.Series(['rgba' + color[3:-1] + ', '+str(opacity)+')' for color in current_colors], index = list_of_traces)\n",
    "dtau_range = list(pd.Series(list(grid_95c_constantspeedup_subonly_norm_ps.columns.get_level_values(3) - grid_95c_constantspeedup_subonly_norm_ps.columns.get_level_values(2))).round(2).value_counts().sort_index().index)\n",
    "dtau_range_colorscale = make_colorscale(dtau_range[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9e241-25a7-4a3a-8a8f-cf142d1d1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint_min = KLtoend_inference_grid_subonly_timeseries.fillna(np.inf).lt((0.05* KLtoend_inference_grid_subonly_timeseries.max(axis=1)), axis=0).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423c6be-d73d-4c6f-bae5-a1665ac8d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S10b (top left)\n",
    "fig_timescale = go.Figure()\n",
    "counter = 0\n",
    "for param in KLtoend_inference_grid_subonly_timeseries.index:\n",
    "    fig_timescale.add_trace(go.Scatter(x = KLtoend_inference_grid_subonly_timeseries.loc[param].dropna().index, y = KLtoend_inference_grid_subonly_timeseries.loc[param].dropna(), line = dict(width = 4, color = dtau_range_colorscale[1][round(param[3] - param[2], 2)]), legendgroup = round(param[3] - param[2], 2), name = str(param), text = str(param), showlegend = False))\n",
    "    counter +=1\n",
    "fig_timescale.add_trace(go.Scatter(x = timepoint_min, y = [KLtoend_inference_grid_subonly_timeseries.loc[param].loc[time] for param, time in zip(KLtoend_inference_grid_subonly_timeseries.index, timepoint_min)], mode = 'markers', marker = dict(size = 4, color = 'blue'), name = '< 5% of initial KL', text = KLtoend_inference_grid_subonly_timeseries.index))\n",
    "fig_timescale.update_xaxes(title = 'time (generations)', range = [0, 1.001e9])#, type = 'log')\n",
    "fig_timescale.update_yaxes(title = 'KL (vs. final time point)')#, type = 'log')\n",
    "fig_timescale.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 500, margin={'t':10,'l':60,'b':45,'r':10}, legend=dict(yanchor=\"top\", y=0.35, xanchor=\"right\", x=0.6, borderwidth = 2))\n",
    "\n",
    "fig_timescale.add_trace(go.Scatter(x=[None], y=[None], showlegend = False, mode='markers', marker=dict(colorscale=dtau_range_colorscale[0].values, showscale=True,\n",
    "                                 colorbar=dict(len = 0.75, yanchor = 'bottom', y = 0.2, title = 'ŒîœÑ', thickness=5, tickvals = np.linspace(6.75,1.25,6), ticktext=[-0.4, -0.2, 0, 0.2, 0.4, 0.6], outlinewidth=0))))\n",
    "\n",
    "\n",
    "fig_timescale.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5238c8-55b3-4f73-ba48-27ea4c8747d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_timescale.write_image('plots/fig_timescale_95c.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c00d3-b2a6-457f-ac0b-f3584a149620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S10b (top right)\n",
    "fig_timescale = go.Figure()\n",
    "counter = 0\n",
    "for param in KLtoend_inference_grid_subonly_timeseries.index:\n",
    "    fig_timescale.add_trace(go.Scatter(x = KLtoend_inference_grid_subonly_timeseries.loc[param].dropna().index[:-1], y = KLtoend_inference_grid_subonly_timeseries.loc[param][:-1].dropna(), line = dict(width = 4, color = dtau_range_colorscale[1][round(param[3] - param[2], 2)]), legendgroup = round(param[3] - param[2], 2), name = str(param), text = str(param), showlegend = False))\n",
    "    counter +=1\n",
    "fig_timescale.add_trace(go.Scatter(x = timepoint_min, y = [KLtoend_inference_grid_subonly_timeseries.loc[param].loc[time] for param, time in zip(KLtoend_inference_grid_subonly_timeseries.index, timepoint_min)], mode = 'markers', marker = dict(size = 4, color = 'blue'), name = '< 5% of initial KL', text = KLtoend_inference_grid_subonly_timeseries.index))\n",
    "fig_timescale.update_xaxes(title = 'time (generations)', range = [0, 1.001e9])#, type = 'log')\n",
    "fig_timescale.update_yaxes(title = 'KL (vs. final time point)', type = 'log', range = [-6,-1])\n",
    "fig_timescale.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 500, margin={'t':10,'l':60,'b':45,'r':10}, legend=dict(yanchor=\"top\", y=0.2, xanchor=\"right\", x=0.6, borderwidth = 2))\n",
    "fig_timescale.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49e55e-8e23-4d85-94a5-8c291f442f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_timescale.write_image('plots/fig_timescale_95c_log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35824e55-9fe0-4882-9841-1f3c8ab76021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S10b (bottom right)\n",
    "colorscale_time = pd.Series(plotly.colors.sample_colorscale('plasma_r', 7, low = 0.1, high = 0.9), index = [1e6, 3e6, 1e7, 3e7, 1e8, 3e8, 1e9])\n",
    "\n",
    "def make_evolve_fig(input_df, motif = 'A', showlegend = True):\n",
    "    fig = go.Figure()\n",
    "    reps = [1e6, 3e6, 1e7, 3e7, 1e8, 3e8, 1e9]\n",
    "    \n",
    "    fig.add_trace(go.Scattergl(x = input_df.index, y = input_df[0] / input_df[0].loc[2:].sum() * bootstrap_counts_mean[motif].loc[2:].sum(), name = 'initial state', legendgroup = 'start', connectgaps = True, line = dict(color = 'gray', dash = 'dash', width = 2.5)))\n",
    "    for rep in reps:\n",
    "        fig.add_trace(go.Scattergl(x = input_df.index, y = input_df[rep] / input_df[rep].loc[4:].sum() * bootstrap_counts_mean[motif].loc[4:].sum(), name = '{:0.1e}'.format(rep), showlegend = showlegend, line = dict(color = colorscale_time[rep], width = 3), opacity = 0.7))\n",
    "    fig.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index, y = bootstrap_counts_mean[motif], line = dict(color = 'rgba(0,0,0,0.8)'), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "    fig.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index, y = bootstrap_counts_max[motif], line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "    fig.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index, y = bootstrap_counts_min[motif], fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "    fig.update_xaxes(type = 'log', title = 'repeat length (units)', range = [0,2])\n",
    "    fig.update_yaxes(type = 'log', title = 'repeat counts', range = [-0.05,9.05], tickformat = '1.0e', dtick = 2)\n",
    "    fig.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 800, margin={'t':10,'l':80,'b':55,'r':10})      \n",
    "    return fig\n",
    "\n",
    "fig_evolve = make_evolve_fig(grid_95c_constantspeedup_subonly[3][2][1.6][2], showlegend = False)\n",
    "fig_evolve.update_xaxes(tickvals = [1,2,5,10,20,50,80])\n",
    "fig_evolve.add_trace(go.Scatter(x=[None], y=[None], showlegend = False, mode='markers', marker=dict(colorscale=colorscale_time.values, showscale=True,\n",
    "                                 colorbar=dict(len = 0.75, yanchor = 'bottom', y = 0, title = 'generation', thickness=5, tickvals = np.linspace(6.75,0,4), ticktext=['1e6', '1e7', '1e8', '1e9'][::-1], outlinewidth=0)), hoverinfo='none'))\n",
    "fig_evolve.update_xaxes(title = 'repeat tract length (units)')\n",
    "fig_evolve.update_yaxes(title = 'counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2246ace9-1543-47f3-aac5-68ffa52105b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_evolve.write_image('plots/fig_timescale_evolve_bestpoint.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42889c5c-367e-45f1-a28a-4b8b480714d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S10b (bottom left)\n",
    "round_localmin = timepoint_min.reset_index()\n",
    "round_localmin.columns = ['exp_i',  'con_i', 'exp_p', 'con_p', 'round']\n",
    "round_localmin['M'] = pd.Series(m_list).reindex(round_localmin['exp_i']-1).values\n",
    "round_localmin = round_localmin.set_index(['M', 'exp_p', 'con_p'])['round']\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = len(round_localmin.index.levels[0]), shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.04, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[2:6]], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "row_count=1; col_count = 0\n",
    "for m in round_localmin.index.levels[0]:\n",
    "    col_count+=1\n",
    "    if m in round_localmin.index.get_level_values('M'):\n",
    "        fig.add_trace(go.Heatmap(x = round_localmin.loc[m].reindex(inference_grid_final_nointerp_subonly[0][0].columns).index.get_level_values(0), y = round_localmin.loc[m].reindex(inference_grid_final_nointerp_subonly[0][0].columns).index.get_level_values(1), z=(round_localmin.loc[m].reindex(inference_grid_final_nointerp_subonly[0][0].columns)), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='plasma_r', colorbar = dict(title = 'generation', len=1.9), cmin = 1.8e7, cmax = round_localmin.max()))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 200, width = 600, margin={'t':50,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12162557-faca-459a-9f2a-09f7653f2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig_timescale_95c_roundlocalmin.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d66e42-a062-4fce-9125-51dbf831ce1e",
   "metadata": {},
   "source": [
    "# Robustness checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7006c3-33d1-45fb-96e3-e86a6e342da9",
   "metadata": {},
   "source": [
    "## Constant speedup (sparse grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8a856-8aaf-4f46-b9de-68468a4c886a",
   "metadata": {},
   "source": [
    "### From geometric starting state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea829d39-60ad-4113-ae9a-6c8884d7ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with pseudocount\n",
    "inference_grid_final_sparse_constantspeedup_subonly_norm_PS = (inference_grid_final_sparse_constantspeedup_subonly.fillna(0) + pseudocount).reindex(L_range) / (inference_grid_final_sparse_constantspeedup_subonly.fillna(0) + pseudocount).reindex(L_range).sum()\n",
    "# Calculate KL\n",
    "KL_grid_sparse_constantspeedup_subonly = inference_grid_final_sparse_constantspeedup_subonly_norm_PS.apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range)).reset_index()\n",
    "# 3M grid with spacing 0.2\n",
    "KL_grid_sparse_constantspeedup_subonly = KL_grid_sparse_constantspeedup_subonly.loc[(KL_grid_sparse_constantspeedup_subonly['exp_i'] == 1+ KL_grid_sparse_constantspeedup_subonly['con_i']) & (KL_grid_sparse_constantspeedup_subonly['exp_p'].isin([n/10 for n in range(0,41,2)])) & (KL_grid_sparse_constantspeedup_subonly['con_p'].isin([n/10 for n in range(0,41,2)]))].set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "# Calculate acceptance probability\n",
    "grid_sparse_constantspeedup_subonly_likelihood = calc_likelihood_from_primate_metric_KL(KL_grid_sparse_constantspeedup_subonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0e0b5-0df8-482f-b698-4126786c66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors['constant'] = dict(); best_params['constant'] = dict(); avg_params['constant'] = dict(); drl_weighted_avg['constant'] = dict(); posteriors_all['constant'] = dict(); posterior_95c['constant'] = dict(); grid_drl_95c['constant'] = dict(); rates_weighted_exp['constant'] = dict(); rates_weighted_con['constant'] = dict(); grid_rates_95c['constant'] = dict(); subset_indices['constant'] = dict()\n",
    "# uniform prior\n",
    "bayesfactors['constant']['uniform'] = dict(); best_params['constant']['uniform'] = dict(); avg_params['constant']['uniform'] = dict(); drl_weighted_avg['constant']['uniform'] = dict(); posteriors_all['constant']['uniform'] = dict(); posterior_95c['constant']['uniform'] = dict(); grid_drl_95c['constant']['uniform'] = dict(); rates_weighted_exp['constant']['uniform'] = dict(); rates_weighted_con['constant']['uniform'] = dict(); grid_rates_95c['constant']['uniform'] = dict()\n",
    "\n",
    "subset_indices['constant']['3param_Mult'] = grid_sparse_constantspeedup_subonly_likelihood.index\n",
    "model_summary(grid_sparse_constantspeedup_subonly_likelihood, 'constant', 'uniform', '3param_Mult', prior = None, params = ['M', 'exp_p', 'con_p'])\n",
    "\n",
    "avg_params['constant']['uniform'] = pd.concat(avg_params['constant']['uniform']).unstack()\n",
    "avg_params['constant'] = pd.concat(avg_params['constant'])\n",
    "best_params['constant']['uniform'] = pd.concat(best_params['constant']['uniform']).unstack()\n",
    "best_params['constant'] = pd.concat(best_params['constant'])\n",
    "drl_weighted_avg['constant']['uniform'] = pd.concat(drl_weighted_avg['constant']['uniform']).unstack()\n",
    "drl_weighted_avg['constant'] = pd.concat(drl_weighted_avg['constant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd012484-2c59-49ce-9bb6-aee21255981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = 'constant'; current_prior = 'uniform'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour_3M_constant_sparse = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "# max KL value in 95% HDR\n",
    "KL_95c_constant = KL_grid_sparse_constantspeedup_subonly[0].sort_values()[:len(posterior_contour_3M_constant_sparse.loc[posterior_contour_3M_constant_sparse['level_0'] <2][0])].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dafd56-fcdd-4755-85a3-73f0e098bd4f",
   "metadata": {},
   "source": [
    "### Sparse grid subset for progressive speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9910f-4d93-486a-b054-c5363a1f4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sparse grid subset\n",
    "current_posterior = posteriors_all['PL']['uniform']['3param_Mult'].loc[(posteriors_all['PL']['uniform']['3param_Mult']['exp_p'].isin([n/10 for n in range(0,41,2)])) & (posteriors_all['PL']['uniform']['3param_Mult']['con_p'].isin([n/10 for n in range(0,41,2)]))].set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).sort_values(by = [0], ascending = False)\n",
    "# Normalize posterior\n",
    "current_posterior[0] = current_posterior[0] / current_posterior[0].sum()\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour_3M_pro_sparse = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "# max KL value in 95% HDR\n",
    "KL_95c_prospeedup = KL_inference_grid_final_nointerp.reindex(KL_grid_sparse_constantspeedup_subonly.index).sort_values()[:len(posterior_contour_3M_pro_sparse.loc[posterior_contour_3M_pro_sparse['level_0'] <2])].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2ef7f-46a7-4c1d-894f-31a3c2fb7c7f",
   "metadata": {},
   "source": [
    "### From uniform-like starting state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b1b67-af7b-491d-90d2-009bfe1567bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with pseudocount\n",
    "inference_grid_final_sparse_constantspeedup_uniform_norm_PS = (inference_grid_final_sparse_constantspeedup_uniform.fillna(0) + pseudocount).reindex(L_range) / (inference_grid_final_sparse_constantspeedup_uniform.fillna(0) + pseudocount).reindex(L_range).sum()\n",
    "# Calculate KL\n",
    "KL_grid_sparse_constantspeedup_uniform = inference_grid_final_sparse_constantspeedup_uniform_norm_PS.apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range)).reset_index()\n",
    "# 3M grid with spacing 0.2\n",
    "KL_grid_sparse_constantspeedup_uniform = KL_grid_sparse_constantspeedup_uniform.loc[(KL_grid_sparse_constantspeedup_uniform['exp_i'] == 1+ KL_grid_sparse_constantspeedup_uniform['con_i']) & (KL_grid_sparse_constantspeedup_uniform['exp_p'].isin([n/10 for n in range(0,41,2)])) & (KL_grid_sparse_constantspeedup_uniform['con_p'].isin([n/10 for n in range(0,41,2)]))].set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "# Calculate acceptance probability\n",
    "grid_sparse_constantspeedup_uniform_likelihood = calc_likelihood_from_primate_metric_KL(KL_grid_sparse_constantspeedup_uniform).reindex(grid_sparse_constantspeedup_subonly_likelihood.index).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b94565-316f-44fb-87ca-597daf564605",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors['constant-uni'] = dict(); best_params['constant-uni'] = dict(); avg_params['constant-uni'] = dict(); drl_weighted_avg['constant-uni'] = dict(); posteriors_all['constant-uni'] = dict(); posterior_95c['constant-uni'] = dict(); grid_drl_95c['constant-uni'] = dict(); rates_weighted_exp['constant-uni'] = dict(); rates_weighted_con['constant-uni'] = dict(); grid_rates_95c['constant-uni'] = dict(); subset_indices['constant-uni'] = dict()\n",
    "# uniform prior\n",
    "bayesfactors['constant-uni']['uniform'] = dict(); best_params['constant-uni']['uniform'] = dict(); avg_params['constant-uni']['uniform'] = dict(); drl_weighted_avg['constant-uni']['uniform'] = dict(); posteriors_all['constant-uni']['uniform'] = dict(); posterior_95c['constant-uni']['uniform'] = dict(); grid_drl_95c['constant-uni']['uniform'] = dict(); rates_weighted_exp['constant-uni']['uniform'] = dict(); rates_weighted_con['constant-uni']['uniform'] = dict(); grid_rates_95c['constant-uni']['uniform'] = dict()\n",
    "\n",
    "subset_indices['constant-uni']['3param_Mult'] = grid_sparse_constantspeedup_uniform_likelihood.index\n",
    "model_summary(grid_sparse_constantspeedup_uniform_likelihood, 'constant-uni', 'uniform', '3param_Mult', prior = None, params = ['M', 'exp_p', 'con_p'])\n",
    "\n",
    "avg_params['constant-uni']['uniform'] = pd.concat(avg_params['constant-uni']['uniform']).unstack()\n",
    "avg_params['constant-uni'] = pd.concat(avg_params['constant-uni'])\n",
    "best_params['constant-uni']['uniform'] = pd.concat(best_params['constant-uni']['uniform']).unstack()\n",
    "best_params['constant-uni'] = pd.concat(best_params['constant-uni'])\n",
    "drl_weighted_avg['constant-uni']['uniform'] = pd.concat(drl_weighted_avg['constant-uni']['uniform']).unstack()\n",
    "drl_weighted_avg['constant-uni'] = pd.concat(drl_weighted_avg['constant-uni'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb3621-cedb-4692-beab-4a0d0b8b2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = 'constant-uni'; current_prior = 'uniform'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour_3M_constant_uniform_sparse = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "# max KL value in 95% HDR\n",
    "KL_95c_constant_uniform = KL_grid_sparse_constantspeedup_uniform[0].sort_values()[:len(posterior_contour_3M_constant_uniform_sparse.loc[posterior_contour_3M_constant_uniform_sparse['level_0'] <2][0])].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd5828-55c8-4dd4-b3b9-e6d84e317617",
   "metadata": {},
   "source": [
    "### Plot comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f828f1-c46d-471e-8c97-1609c8be0458",
   "metadata": {},
   "source": [
    "#### Posterior space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85314e-986d-4ae0-8e0c-c8f41f740f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 3, cols = 7, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.02, vertical_spacing = 0.08, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[1:]], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "row_count=1; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour_3M_pro_sparse.loc[m].index.get_level_values(0), y = posterior_contour_3M_pro_sparse.loc[m].index.get_level_values(1), z=(posterior_contour_3M_pro_sparse.loc[m]['level_0']+1).fillna(5), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "row_count=2; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour_3M_constant_sparse.loc[m].index.get_level_values(0), y = posterior_contour_3M_constant_sparse .loc[m].index.get_level_values(1), z=(posterior_contour_3M_constant_sparse .loc[m]['level_0']+1).fillna(5), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "row_count=3; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour_3M_constant_uniform_sparse.loc[m].index.get_level_values(0), y = posterior_contour_3M_constant_uniform_sparse.loc[m].index.get_level_values(1), z=(posterior_contour_3M_constant_uniform_sparse.loc[m]['level_0']+1).fillna(5), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.55, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%'], x = 1.075, y = 0.825), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 420, width = 1000, margin={'t':50,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc376ce-32a3-4c15-801e-b971b7f1f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/posterior_sparse_prospeedup_constantspeedup_uniformstart.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c9cf9-7e9e-4a25-bf36-9628a641e1fb",
   "metadata": {},
   "source": [
    "#### Posterior-weighted DRLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229543cc-5a5f-4584-853d-864171b2a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_fig_list_contour(inference_grid_final_nointerp_subonly_norm_ps, None, norm_range=(range(4,201)), showgroups=[1], tracename = '95% HDR (uniform prior)')\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg['PL'].loc['uniform'].loc['3param_Mult'] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL<br>(step-wise speedup,<br>geometric initial state)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], width = 3)))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg['constant'].loc['uniform'].loc['3param_Mult'] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL<br>(constant speedup,<br>geometric initial state)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], dash = 'dash', width = 3)))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg['constant-uni'].loc['uniform'].loc['3param_Mult'] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL<br>(constant speedup,<br>compound initial state)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], dash = 'dot', width = 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92a14a-8487-4eb0-8aac-80308c8d82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/compare_DRL_95c_pro_constant_uniformstart.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbacef2-0a78-46d1-addb-bb01c40829cb",
   "metadata": {},
   "source": [
    "#### Comparisons of KL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27fc78-64c8-47cd-a051-e5e739c1df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_comp = go.Figure(go.Scatter(x = KL_grid_sparse_constantspeedup_subonly[0], y = KL_inference_grid_final_nointerp.reindex(KL_grid_sparse_constantspeedup_subonly.index), mode = 'markers', text = list(KL_grid_sparse_constantspeedup_subonly.index), marker = dict(color = 'rgba(31, 119, 180, 0.15)'), showlegend = False))\n",
    "fig_comp.add_trace(go.Scatter(x = [0, 5], y = [0,5], mode = 'lines', line = dict(color = 'black', width = 1), showlegend = False))\n",
    "fig_comp.add_trace(go.Scatter(y=[0, KL_95c_prospeedup, KL_95c_prospeedup, 0], x=[0, 0, KL_95c_constant, KL_95c_constant], mode = 'lines', line = dict(width = 3, dash = 'dash', color = discrete_deep[1][1]), opacity = 0.95, fill=\"toself\", fillcolor = 'rgba(' + pd.DataFrame(discrete_deep)[1][1][4:-1] + ', 0.15)', showlegend = False))\n",
    "\n",
    "fig_comp.update_yaxes(title = dict(text = 'step-wise speed-up (<i>D<sub>KL</sub></i>)', font = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])), type = 'log', dtick = 1)\n",
    "fig_comp.update_xaxes(title = 'constant speed-up (<i>D<sub>KL</sub></i>)', dtick = 1, type = 'log', scaleanchor=\"y\", scaleratio=1)\n",
    "fig_comp.update_layout(width = 400, height = 400, font=dict(family = 'Arial', size = 16), margin={'t':10,'l':60,'b':55,'r':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d0e2c2-3b8b-4c60-acf3-28f20407a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_comp.write_image('plots/KL_constant_v_prospeedup.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa31a5d-0650-445a-8ab7-8401f7ddbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_comp = go.Figure(go.Scatter(y = KL_grid_sparse_constantspeedup_uniform[0], x = KL_grid_sparse_constantspeedup_subonly[0].reindex(KL_grid_sparse_constantspeedup_uniform.index), mode = 'markers', text = list(KL_grid_sparse_constantspeedup_uniform.index), marker = dict(color = 'rgba(31, 119, 180, 0.15)'), showlegend = False))\n",
    "fig_comp.add_trace(go.Scatter(x = [0, 5], y = [0,5], mode = 'lines', line = dict(color = 'black', width = 1), showlegend = False))\n",
    "fig_comp.add_trace(go.Scatter(y=[0, KL_95c_constant_uniform, KL_95c_constant_uniform, 0], x=[0, 0, KL_95c_constant, KL_95c_constant], mode = 'lines', line = dict(width = 3, dash = 'dash', color = discrete_deep[1][1]), opacity = 0.95, fill=\"toself\", fillcolor = 'rgba(' + pd.DataFrame(discrete_deep)[1][1][4:-1] + ', 0.15)', showlegend = False))\n",
    "\n",
    "fig_comp.update_yaxes(title = dict(text = 'compound initial state (<i>D<sub>KL</sub></i>)', font = dict(color = 'red')), type = 'log', dtick = 1)\n",
    "fig_comp.update_xaxes(title = 'geometric initial state (<i>D<sub>KL</sub></i>)', dtick = 1, type = 'log', scaleanchor=\"y\", scaleratio=1)\n",
    "fig_comp.update_layout(width = 400, height = 400, font=dict(family = 'Arial', size = 16), margin={'t':10,'l':60,'b':55,'r':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eca22a-9101-4f8c-a438-1417f87dbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_comp.write_image('plots/KL_constant_subonly_v_uniform.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37134c-ae80-4d42-8335-c8dd46358eed",
   "metadata": {},
   "source": [
    "## Effect of stochastics\n",
    "- note: pause here and run computational model script for the parameter combinations determined above\n",
    "- run 'gather_grid' script to collect this data prior to running below section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56df8a-e9d3-4cc7-9340-f665c7077b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "stoch_all = dict()\n",
    "for stoch in range(1,11):\n",
    "    stoch_all[stoch] = pd.read_pickle('simulations/completed_grids/grid_top95c_stoch_'+str(stoch)+'.pickle').sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c90c5c-8842-4d6a-ba8d-877e3533344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_grid_top95c_norm_PS_stoch = dict(); KL_grid_top95c_timepoints_stoch = dict(); KL_final_top95c_stoch = dict()\n",
    "for stoch in range(1,11):\n",
    "    # Normalize with pseudocount\n",
    "    inference_grid_top95c_norm_PS_stoch[stoch] = (stoch_all[stoch].fillna(0) + pseudocount).reindex(L_range) / (stoch_all[stoch].fillna(0) + pseudocount).reindex(L_range).sum()\n",
    "    # Calculate KL\n",
    "    KL_grid_top95c_timepoints_stoch[stoch] = inference_grid_top95c_norm_PS_stoch[stoch].apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range)).unstack()\n",
    "    KL_final_top95c_stoch[stoch] = KL_grid_top95c_timepoints_stoch[stoch].stack().reindex([(param[0], param[1], param[2], param[3], stoch_all[stoch][param].columns.max()) for param in stoch_all[stoch].xs(0, 1, level=4).columns])\n",
    "    KL_final_top95c_stoch[stoch] = KL_final_top95c_stoch[stoch].reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667da4b-78d6-4202-88cd-3dfef660bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_comp = go.Figure()\n",
    "for stoch in range(1,11):\n",
    "    fig_comp.add_trace(go.Scatter(x = KL_inference_grid_final_nointerp.reindex(KL_final_top95c_stoch[stoch].index), y = KL_final_top95c_stoch[stoch][0], mode = 'markers', marker = dict(size = 4, opacity = 0.3), text = KL_final_top95c_stoch[stoch].index, showlegend = False))\n",
    "fig_comp.add_trace(go.Scatter(x = [0.0032, 0.0051], y = [0.0032, 0.0051], mode = 'lines', line = dict(color = 'black', width = 1), showlegend = False))\n",
    "fig_comp.update_yaxes(title = 'stochastics (<i>D<sub>KL</sub></i>)')\n",
    "fig_comp.update_xaxes(title = 'deterministic (<i>D<sub>KL</sub></i>)', scaleanchor=\"y\", scaleratio=1)\n",
    "fig_comp.update_layout(width = 400, height = 400, font=dict(family = 'Arial', size = 16), margin={'t':10,'l':90,'b':55,'r':10})\n",
    "fig_comp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23840d01-b253-48ce-9ee8-c29db500440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_comp.write_image('plots/KL_stochastics_top95c.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592e28e-457a-41c1-b9e1-816e49754dea",
   "metadata": {},
   "source": [
    "# Alternate parameterizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba30bd-307f-40f2-882b-6f80119b04ae",
   "metadata": {},
   "source": [
    "## Pure power-law model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e862b6-b2ba-4030-b0a2-7db6f7ff2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to contraction-biased parameters\n",
    "inference_grid_final_xrange = inference_grid_final_xrange.T.reset_index()\n",
    "inference_grid_final_xrange = inference_grid_final_xrange.where(inference_grid_final_xrange['exp_p'] < inference_grid_final_xrange['con_p']).dropna(how = 'all').set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e2b8b-73ae-48f1-ab3c-5b2a6ab1cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize counts (with pseudocount)\n",
    "inference_grid_final_xrange_norm_ps = (inference_grid_final_xrange.reindex(norm_range) + pseudocount) / (inference_grid_final_xrange.reindex(norm_range) + pseudocount).sum()\n",
    "# Calculate KL\n",
    "KL_inference_grid_final_xrange = inference_grid_final_xrange_norm_ps.apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range))\n",
    "# Calculate acceptance probability\n",
    "grid_likelihood_xrange_KL = calc_likelihood_from_primate_metric_KL(KL_inference_grid_final_xrange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912dda9-ff8b-4884-b3e9-aa3f4d891702",
   "metadata": {},
   "source": [
    "#### grid of rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fea2c7-d000-45b6-be29-7ad7dd400519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### alternate rate functional forms\n",
    "def power_law_rate_at_L(power, L, rate = 1e-8, bins = 200):\n",
    "    return pd.Series([np.exp(np.log(rate) - power * np.log(L) + np.log(length)*power) for length in range(1,bins)], index = range(1,bins))\n",
    "mu_nu_all = pd.read_pickle('denovo/mu_nu_1-3.pickle')\n",
    "rates_all_xrange = pd.DataFrame([((exp_i, con_i, exp_p, con_p), power_law_rate_at_L(exp_p, exp_i, rate = mu_nu_all['mu'][1]['A']), power_law_rate_at_L(con_p, con_i, rate = mu_nu_all['nu'][1]['A'])) for (exp_i, con_i, exp_p, con_p) in inference_grid_final_xrange.columns], index = inference_grid_final_xrange.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ab45a-c0c9-42e8-bc15-04063676cb11",
   "metadata": {},
   "source": [
    "### Calculate Bayes factors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe4110-443d-4d07-9714-a6216ef28cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors['PL_only'] = dict(); best_params['PL_only'] = dict(); avg_params['PL_only'] = dict(); drl_weighted_avg['PL_only'] = dict(); posteriors_all['PL_only'] = dict(); posterior_95c['PL_only'] = dict(); grid_drl_95c['PL_only'] = dict(); rates_weighted_exp['PL_only'] = dict(); rates_weighted_con['PL_only'] = dict(); grid_rates_95c['PL_only'] = dict()\n",
    "\n",
    "# uninformative prior\n",
    "bayesfactors['PL_only']['uninformative'] = dict(); best_params['PL_only']['uninformative'] = dict(); avg_params['PL_only']['uninformative'] = dict(); drl_weighted_avg['PL_only']['uninformative'] = dict(); posteriors_all['PL_only']['uninformative'] = dict(); posterior_95c['PL_only']['uninformative'] = dict(); grid_drl_95c['PL_only']['uninformative'] = dict(); rates_weighted_exp['PL_only']['uninformative'] = dict(); rates_weighted_con['PL_only']['uninformative'] = dict(); grid_rates_95c['PL_only']['uninformative'] = dict()\n",
    "model_summary(grid_likelihood_xrange_KL, 'PL_only', 'uninformative', '4param', prior = None, params = ['exp_i', 'con_i', 'exp_p', 'con_p'], use_intercepts=False, grid_drl = inference_grid_final_xrange_norm_ps, rates = rates_all_xrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ffba7-eeba-4500-b549-357ebd44d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load informative prior\n",
    "prior_rates = pd.read_pickle('simulations/priors/prior_plonly.pickle')\n",
    "prior_rates = prior_rates.reindex(grid_likelihood_xrange_KL.index)\n",
    "prior_rates /= prior_rates.sum()\n",
    "\n",
    "# informative prior\n",
    "bayesfactors['PL_only']['informative'] = dict(); best_params['PL_only']['informative'] = dict(); avg_params['PL_only']['informative'] = dict(); drl_weighted_avg['PL_only']['informative'] = dict(); posteriors_all['PL_only']['informative'] = dict(); posterior_95c['PL_only']['informative'] = dict(); grid_drl_95c['PL_only']['informative'] = dict(); rates_weighted_exp['PL_only']['informative'] = dict(); rates_weighted_con['PL_only']['informative'] = dict(); grid_rates_95c['PL_only']['informative'] = dict()\n",
    "model_summary(grid_likelihood_xrange_KL, 'PL_only', 'informative', '4param', prior = prior_rates, params = ['exp_i', 'con_i', 'exp_p', 'con_p'], use_intercepts=False, grid_drl = inference_grid_final_xrange_norm_ps, rates = rates_all_xrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17238cc3-1222-453a-82af-2927c165864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_params['PL_only']['uninformative'] = pd.concat(avg_params['PL_only']['uninformative']).unstack()\n",
    "avg_params['PL_only']['informative'] = pd.concat(avg_params['PL_only']['informative']).unstack()\n",
    "avg_params['PL_only'] = pd.concat(avg_params['PL_only'])\n",
    "\n",
    "best_params['PL_only']['uninformative'] = pd.concat(best_params['PL_only']['uninformative']).unstack()\n",
    "best_params['PL_only']['informative'] = pd.concat(best_params['PL_only']['informative']).unstack()\n",
    "best_params['PL_only'] = pd.concat(best_params['PL_only'])\n",
    "\n",
    "drl_weighted_avg['PL_only']['uninformative'] = pd.concat(drl_weighted_avg['PL_only']['uninformative']).unstack()\n",
    "drl_weighted_avg['PL_only']['informative'] = pd.concat(drl_weighted_avg['PL_only']['informative']).unstack()\n",
    "drl_weighted_avg['PL_only'] = pd.concat(drl_weighted_avg['PL_only'])\n",
    "\n",
    "rates_weighted_exp['PL_only']['uninformative'] = pd.concat(rates_weighted_exp['PL_only']['uninformative']).unstack().T\n",
    "rates_weighted_exp['PL_only']['informative'] = pd.concat(rates_weighted_exp['PL_only']['informative']).unstack().T\n",
    "rates_weighted_exp['PL_only'] = pd.concat(rates_weighted_exp['PL_only'])\n",
    "\n",
    "rates_weighted_con['PL_only']['uninformative'] = pd.concat(rates_weighted_con['PL_only']['uninformative']).unstack().T\n",
    "rates_weighted_con['PL_only']['informative'] = pd.concat(rates_weighted_con['PL_only']['informative']).unstack().T\n",
    "rates_weighted_con['PL_only'] = pd.concat(rates_weighted_con['PL_only'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139acf6-1593-489b-acb7-0c52e388b20c",
   "metadata": {},
   "source": [
    "### Plot marginal posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206472f4-ba33-43e8-a000-37a0248d1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plonly_lambda_list = list(range(5,21))\n",
    "fig = make_subplots(rows = 1, cols = 2, shared_yaxes = True, horizontal_spacing = 0.08, subplot_titles = ['uninformative', 'informative'], x_title = 'onset length Œª<sub>ùúÄ</sub> (nt)', y_title = 'onset length Œª<sub>ùúÖ</sub> (nt)')\n",
    "\n",
    "current_posterior = posteriors_all['PL_only']['uninformative']['4param'].set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])[0]\n",
    "current_posterior_marginal = pd.Series([current_posterior.reset_index().loc[(current_posterior.reset_index()['exp_i'] == exp) & (current_posterior.reset_index()['con_i'] == con)][0].sum() for exp in plonly_lambda_list for con in plonly_lambda_list], index = pd.MultiIndex.from_tuples([(exp, con)  for exp in plonly_lambda_list for con in plonly_lambda_list]))\n",
    "current_posterior_marginal_cumulative = current_posterior_marginal.sort_values(ascending = False).cumsum()\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior_marginal_cumulative.where((current_posterior_marginal_cumulative > spacing[num]) & (current_posterior_marginal_cumulative <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['level_1', 'level_2']).reindex(current_posterior_marginal_cumulative.index)\n",
    "fig.add_trace(go.Heatmap(x = posterior_contour.index.get_level_values(0), y = posterior_contour.index.get_level_values(1), z=((posterior_contour['level_0']+1).fillna(5)), coloraxis='coloraxis1'), row = 1, col = 1)\n",
    "\n",
    "current_posterior = posteriors_all['PL_only']['informative']['4param'].set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])[0]\n",
    "current_posterior_marginal = pd.Series([current_posterior.reset_index().loc[(current_posterior.reset_index()['exp_i'] == exp) & (current_posterior.reset_index()['con_i'] == con)][0].sum() for exp in plonly_lambda_list for con in plonly_lambda_list], index = pd.MultiIndex.from_tuples([(exp, con)  for exp in plonly_lambda_list for con in plonly_lambda_list]))\n",
    "current_posterior_marginal_cumulative = current_posterior_marginal.sort_values(ascending = False).cumsum()\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior_marginal_cumulative.where((current_posterior_marginal_cumulative > spacing[num]) & (current_posterior_marginal_cumulative <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['level_1', 'level_2']).reindex(current_posterior_marginal_cumulative.index)\n",
    "fig.add_trace(go.Heatmap(x = posterior_contour.index.get_level_values(0), y = posterior_contour.index.get_level_values(1), z=((posterior_contour['level_0']+1).fillna(5)), coloraxis='coloraxis1'), row = 1, col = 2)\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.7, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%']), cmin = 1, cmax = 5))\n",
    "fig.update_yaxes(tickvals = plonly_lambda_list)\n",
    "fig.update_xaxes(tickvals = plonly_lambda_list, scaleanchor=\"y\", scaleratio=1)\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 320, width = 680, margin={'t':30,'l':60,'b':70,'r':10})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ddb795-d6d1-4ed1-ae33-a9b54fc2ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig_xrange_marginalposterior_uniform_restrictive.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef43ba-9f31-4319-ab91-e06aeb5a17d1",
   "metadata": {},
   "source": [
    "### Plot HDR range and poster-weighted DRLs and rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886bcf4-f4fd-44fc-95a1-c7dd77291709",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = 'PL_only'; current_prior = 'uninformative'; current_param = '4param'\n",
    "current_posterior = posteriors_all['PL_only'][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() <= spacing[num+1])).dropna(how = 'all')\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750c77f-f450-46f5-bd16-a00bd9a6dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_fig_list_contour(inference_grid_final_xrange_norm_ps, posterior_contour, showgroups = [3,2,1,0], norm_range=(range(4,201)), xrange = True)\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = (drl_weighted_avg['PL_only'].loc[current_prior].loc[current_param] / drl_weighted_avg['PL_only'].loc[current_prior].loc[current_param].sum())* bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (uninformative)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[3], dash = 'dash', width = 4)))\n",
    "fig.update_xaxes(range = [0, 2.33], tickvals = [1,2,5,10,20,50,100,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533a2d2-552c-4af3-bee0-95f7eaf3d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_CDFbands_PL_uniform_3mult_log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40b7fec-25a5-44d4-ab2c-6231f74350b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = 'PL_only'; current_prior = 'informative'; current_param = '4param'\n",
    "current_posterior = posteriors_all['PL_only'][current_prior][current_param].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() <= spacing[num+1])).dropna(how = 'all')\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588f91c-d15c-4243-ad67-99c98e4736fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_fig_list_contour(inference_grid_final_xrange_norm_ps, posterior_contour, showgroups = [3,2,1,0], norm_range=(range(4,201)), xrange = True)\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = (drl_weighted_avg['PL_only'].loc[current_prior].loc[current_param] / drl_weighted_avg['PL_only'].loc[current_prior].loc[current_param].sum())* bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (informative)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[3], dash = 'dash', width = 4)))\n",
    "fig.update_xaxes(range = [0, 2.33], tickvals = [1,2,5,10,20,50,100,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf5aa5-f61a-46d9-82bb-d10f9fab5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_CDFbands_PL_informative_3mult_log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb6a7e-8f11-4ca4-b6cc-87bfcd07f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates = make_fig_rates_list_contour(None, rates_all_xrange)\n",
    "for prior, dash in zip(['uninformative', 'informative'], [None, 'dot']):\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(1,200)), y = rates_weighted_exp[current_model].loc[prior][current_param].reindex(range(1,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], dash = dash, width = 4), name = 'weighted ùúÄ|<i>L</i> (' + prior + ')',))\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(1,200)), y = rates_weighted_con[current_model].loc[prior][current_param].reindex(range(1,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], dash = dash, width = 4), name = 'weighted ùúÖ|<i>L</i> (' + prior + ')',))\n",
    "fig_rates.update_xaxes(range = [0, 2.33], tickvals = [1,2,5,10,20,50,100,200])\n",
    "fig_rates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76836d78-0569-4888-aeb7-2c8cd4094fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/rates_weighted_PL_priors_3mult_log.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b67485-cc35-41af-bca9-fd9cc94a3d00",
   "metadata": {},
   "source": [
    "### Onset length analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c66de-baff-4016-bd5a-cae866d2f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange_cols_sorted = inference_grid_final_xrange.sort_index(axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109d09c-75d2-4c5d-9111-c1e448a7801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_nu_comparision(param, threshold = 1.5, DRL_threshold = 1.5):\n",
    "    diff_from_subonly = (inference_grid_final_xrange[param] * subonly_counts['A']['A'][1] / inference_grid_final_xrange[param][1]) / subonly_counts['A']['A'].dropna()\n",
    "    L_diff_from_subonly = ((diff_from_subonly > threshold) | (diff_from_subonly < (1/threshold))).idxmax()\n",
    "#    L_diff_from_subonly = ((diff_from_subonly > DRL_threshold)).idxmax()\n",
    "    L_diff_from_subonly = np.nan if L_diff_from_subonly == 1 else L_diff_from_subonly\n",
    "    exp_v_mu = ((rates_all_xrange.loc[param][1] * rates_all_xrange.loc[param][1].index) > threshold * 2*mu_nu_all['mu'][1]['A']).idxmax()\n",
    "    con_v_mu = ((rates_all_xrange.loc[param][2] * rates_all_xrange.loc[param][2].index) > threshold * 2*mu_nu_all['mu'][1]['A']).idxmax()\n",
    "    exp_v_nu = ((rates_all_xrange.loc[param][1] * rates_all_xrange.loc[param][1].index) > threshold * mu_nu_all['nu'][1]['A'] * rates_all_xrange.loc[param][1].index).idxmax()\n",
    "    con_v_nu = ((rates_all_xrange.loc[param][2] * rates_all_xrange.loc[param][2].index) > threshold * mu_nu_all['nu'][1]['A'] * rates_all_xrange.loc[param][2].index).idxmax()\n",
    "\n",
    "    con_exp_v_nu_mu = (((rates_all_xrange.loc[param][2] * rates_all_xrange.loc[param][2].index) - (rates_all_xrange.loc[param][1] * rates_all_xrange.loc[param][1].index)) > (mu_nu_all['nu'][1]['A'] * rates_all_xrange.loc[param][1].index - 2*mu_nu_all['mu'][1]['A'])).idxmax()\n",
    "\n",
    "\n",
    "    max_con_exp_v_mu = ((pd.concat([(rates_all_xrange.loc[param][2] * rates_all_xrange.loc[param][2].index), (rates_all_xrange.loc[param][1] * rates_all_xrange.loc[param][1].index)], axis=1).max(axis=1)) > threshold * 2*mu_nu_all['mu'][1]['A']).idxmax()\n",
    "\n",
    "    \n",
    "    exp_v_mu_L = ((rates_all_xrange.loc[param][1] * rates_all_xrange.loc[param][1].index) > 0.1 * 2*mu_nu_all['mu'][1]['A'] / rates_all_xrange.loc[param][1].index).idxmax()\n",
    "\n",
    "    if L_diff_from_subonly >1:\n",
    "        exp_over_mu_at_L = (rates_all_xrange.loc[param][1][L_diff_from_subonly] * L_diff_from_subonly) /  (2*mu_nu_all['mu'][1]['A'])\n",
    "        exp_over_muexp_at_L = (rates_all_xrange.loc[param][1][L_diff_from_subonly] * L_diff_from_subonly)  /  ((rates_all_xrange.loc[param][1][L_diff_from_subonly] * L_diff_from_subonly) + (2*mu_nu_all['mu'][1]['A']))\n",
    "    else:\n",
    "        exp_over_mu_at_L = np.nan; exp_over_muexp_at_L = np.nan\n",
    "    \n",
    "    return (L_diff_from_subonly, exp_v_mu, con_v_mu, exp_v_nu, con_v_nu, con_exp_v_nu_mu, exp_v_mu_L, exp_over_mu_at_L, exp_over_muexp_at_L, max_con_exp_v_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da0612b-85d3-48a8-aef2-4704949b3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "mu_comparison = pd.Series([(((denovo_exp_rate[motif] * denovo_exp_rate[motif].index) / (2*mu_nu_all['mu'][len(motif)][motif])) > threshold).idxmax() for motif in subonly_counts['A']], index = subonly_counts['A'].columns)\n",
    "mu_comparison_decode = pd.Series([(((decode_exp_rate[motif] * decode_exp_rate[motif].index) / (2*mu_nu_all['mu'][len(motif)][motif])) > threshold).idxmax() for motif in subonly_counts['A']], index = subonly_counts['A'].columns)\n",
    "subonly_comparison = pd.Series([(((((bootstrap_counts_mean[motif] * (subonly_counts['A'][motif][1] / bootstrap_counts_mean[motif][1])) / subonly_counts['A'][motif]).dropna()) > threshold) | ((((bootstrap_counts_mean[motif] * (subonly_counts['A'][motif][1] / bootstrap_counts_mean[motif][1])) / subonly_counts['A'][motif]).dropna()) < 1/threshold)).idxmax() for motif in subonly_counts['A']], index = subonly_counts['A'].columns)\n",
    "mu_expcon_comparison = pd.Series([((pd.concat([(denovo_exp_rate[motif] * denovo_exp_rate[motif].index), (denovo_con_rate[motif] * denovo_con_rate[motif].index)], axis=1).max(axis=1) > (threshold * 2*mu_nu_all['mu'][len(motif)][motif])) ).idxmax() for motif in subonly_counts['A']], index = subonly_counts['A'].columns)\n",
    "\n",
    "mu_comparison_empirical = pd.concat([mu_comparison, mu_comparison_decode, subonly_comparison, mu_expcon_comparison], axis=1)\n",
    "mu_comparison_empirical.columns = ['mu_L', 'mu_L_decode', 'DRL_L', 'mu_expcon_max']\n",
    "mu_comparison_empirical['exp_over_mu_at_L'] = [(denovo_exp_rate[motif].replace(0, np.nan)[DRL_L] * DRL_L) / (2*mu_nu_all['mu'][len(motif)][motif]) for motif, DRL_L in zip(mu_comparison_empirical['DRL_L'].index, mu_comparison_empirical['DRL_L'])]\n",
    "mu_comparison_empirical['exp_over_mu_at_L_decode'] = [(decode_exp_rate[motif][DRL_L] * DRL_L) / (2*mu_nu_all['mu'][len(motif)][motif]) for motif, DRL_L in zip(mu_comparison_empirical['DRL_L'].index, mu_comparison_empirical['DRL_L'])]\n",
    "mu_comparison_empirical['exp_over_muexp_at_L'] = [(denovo_exp_rate[motif].replace(0, np.nan)[DRL_L] * DRL_L) / ((denovo_exp_rate[motif].replace(0, np.nan)[DRL_L] * DRL_L) + (2*mu_nu_all['mu'][len(motif)][motif])) for motif, DRL_L in zip(mu_comparison_empirical['DRL_L'].index, mu_comparison_empirical['DRL_L'])]\n",
    "mu_comparison_empirical['exp_over_muexp_at_L_decode'] = [(decode_exp_rate[motif].replace(0, np.nan)[DRL_L] * DRL_L) / ((decode_exp_rate[motif].replace(0, np.nan)[DRL_L] * DRL_L) + (2*mu_nu_all['mu'][len(motif)][motif])) for motif, DRL_L in zip(mu_comparison_empirical['DRL_L'].index, mu_comparison_empirical['DRL_L'])]\n",
    "\n",
    "for lam in ['mu_L', 'mu_L_decode', 'DRL_L', 'mu_expcon_max']:\n",
    "    mu_comparison_empirical[lam] *= mu_comparison_empirical.index.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedebc99-1eeb-4514-aac0-9534a5cba95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mu_nu_comparison = go.Figure()\n",
    "fig_mu_nu_comparison.add_trace(go.Scatter(x = mu_comparison_empirical['DRL_L'], y = mu_comparison_empirical['mu_expcon_max'], name = 'max_expcon_v_mu_empirical', mode = 'markers', showlegend = False, text = list(mu_comparison_empirical.index), marker = dict(size = 30, opacity = 0.3)))\n",
    "fig_mu_nu_comparison.add_trace(go.Scatter(x = [0,30], y = [0,30], mode = 'lines', line = dict(color = 'black', width = 2), opacity = 0.3, showlegend = False))\n",
    "\n",
    "for motif in mu_comparison_empirical.index:\n",
    "    fig_mu_nu_comparison.add_annotation(x=np.log10(mu_comparison_empirical['DRL_L'][motif]), y=np.log10(mu_comparison_empirical['mu_expcon_max'][motif]), \n",
    "            text=motif,\n",
    "            font=dict(color=\"black\", size=12),\n",
    "            ax = 0,\n",
    "            ay = -6 if motif in ['AG','AAG','ACC','AAC'] else 6 if motif in ['AT','AGG','ATC','ACG'] else 0,\n",
    "            showarrow=True,\n",
    "            arrowcolor = 'rgba(255,0,0,0)')\n",
    "\n",
    "fig_mu_nu_comparison.update_yaxes(type = 'log', range = [0,1.333], tickvals = [1,3,6,9,12,15], title = 'onset length (nt) from rate estimates')\n",
    "fig_mu_nu_comparison.update_xaxes(type = 'log', range = [0,1.333], tickvals = [1,3,6,9,12,15], title = 'onset length (nt) from DRLs', scaleanchor=\"y\", scaleratio=1)\n",
    "fig_mu_nu_comparison.update_layout(width = 600, height = 600,  font=dict(family = 'Arial', size = 20), margin={'t':20,'l':100,'b':60,'r':10})\n",
    "fig_mu_nu_comparison.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fabfb7-ab64-4d5f-baab-e927d5158ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mu_nu_comparison.write_image('plots/lambda_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80812e3d-c9c8-41ff-8ae5-fc35dab38dcf",
   "metadata": {},
   "source": [
    "## Logarithmic power parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3462fbc-4c1b-4410-9953-cb79eb17a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize counts (with pseudocount)\n",
    "inference_grid_final_log_norm_ps = (inference_grid_final_log.reindex(norm_range) + pseudocount) / (inference_grid_final_log.reindex(norm_range) + pseudocount).sum()\n",
    "# Calculate KL\n",
    "KL_inference_grid_final_log = inference_grid_final_log_norm_ps.apply(lambda y: calc_KL_divergence_CHM13(y, L_range=L_range))\n",
    "# Calculate acceptance probability\n",
    "grid_likelihood_log_KL = calc_likelihood_from_primate_metric_KL(KL_inference_grid_final_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf235e30-2bb2-4346-89e3-4b40972e4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_likelihood = grid_likelihood_log_KL.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16e13e-eec2-4830-8cdd-23d61cc809ed",
   "metadata": {},
   "source": [
    "#### grid of rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a68bb8-72cd-4506-a317-e6560bbd8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_curve_from_L9(power, intercept, bins = 200):\n",
    "    return pd.Series([intercept_list[intercept] * (np.log(1+L-8) / np.log(1+9 -8))**power for L in range(9,bins+1)], index = range(9,bins+1))\n",
    "rates_all_log = pd.DataFrame([((exp_i, con_i, exp_p, con_p,), pd.concat([denovo_exp_rate['A'].loc[:8], log_curve_from_L9(exp_p, exp_i, 200)]), pd.concat([denovo_con_rate['A'].loc[:8], log_curve_from_L9(con_p, con_i, 200)])) for (exp_i, con_i, exp_p, con_p,) in inference_grid_final_log.columns], index = inference_grid_final_log.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ff08f-035f-4ffe-b0da-8a01d5fe874f",
   "metadata": {},
   "source": [
    "### Calculate Bayes factors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb743b-8faa-4afa-9273-d4ed85d719e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors['log'] = dict(); best_params['log'] = dict(); avg_params['log'] = dict(); drl_weighted_avg['log'] = dict(); posteriors_all['log'] = dict(); posterior_95c['log'] = dict(); grid_drl_95c['log'] = dict(); rates_weighted_exp['log'] = dict(); rates_weighted_con['log'] = dict(); grid_rates_95c['log'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d205966-3819-45a6-a009-d37d558d0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform prior\n",
    "bayesfactors['log']['uniform'] = dict(); best_params['log']['uniform'] = dict(); avg_params['log']['uniform'] = dict(); drl_weighted_avg['log']['uniform'] = dict(); posteriors_all['log']['uniform'] = dict(); posterior_95c['log']['uniform'] = dict(); grid_drl_95c['log']['uniform'] = dict(); rates_weighted_exp['log']['uniform'] = dict(); rates_weighted_con['log']['uniform'] = dict(); grid_rates_95c['log']['uniform'] = dict()\n",
    "\n",
    "model_summary(grid_likelihood_log_KL, 'log', 'uniform', '4param', prior = None, params = ['exp_i', 'con_i', 'exp_p', 'con_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)\n",
    "\n",
    "# 2 parameter Bayes factor, model where power law is same, intercept is same\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p']) & (partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'log', 'uniform', '2param', prior = None, params = ['exp_i', 'exp_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'log', 'uniform', '3param_Mult', prior = None, params = ['M', 'exp_p', 'con_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ee0ba-2235-41e0-9285-ae194f668dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrictive prior\n",
    "prior_rates = pd.read_pickle('simulations/grid_4param_v2/prior_log_restrictive.pickle')\n",
    "prior_rates = prior_rates.reindex(grid_likelihood.index)\n",
    "prior_rates /= prior_rates.sum()\n",
    "\n",
    "# restrictive prior\n",
    "bayesfactors['log']['restrictive'] = dict(); best_params['log']['restrictive'] = dict(); avg_params['log']['restrictive'] = dict(); drl_weighted_avg['log']['restrictive'] = dict(); posteriors_all['log']['restrictive'] = dict(); posterior_95c['log']['restrictive'] = dict(); grid_drl_95c['log']['restrictive'] = dict(); rates_weighted_exp['log']['restrictive'] = dict(); rates_weighted_con['log']['restrictive'] = dict(); grid_rates_95c['log']['restrictive'] = dict()\n",
    "\n",
    "model_summary(grid_likelihood, 'log', 'restrictive', '4param', prior = prior_rates, params = ['exp_i', 'con_i', 'exp_p', 'con_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)\n",
    "\n",
    "# 2 parameter Bayes factor, model where power law is same, intercept is same\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p']) & (partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'log', 'restrictive', '2param', prior = prior_rates, params = ['exp_i', 'exp_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)\n",
    "\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'log', 'restrictive', '3param_Mult', prior = prior_rates, params = ['M', 'exp_p', 'con_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df2fdd-4971-466b-b43f-e0391d7188d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permissive prior\n",
    "prior_rates = pd.read_pickle('simulations/grid_4param_v2/prior_log_relaxed.pickle')\n",
    "prior_rates = prior_rates.reindex(grid_likelihood.index)\n",
    "prior_rates /= prior_rates.sum()\n",
    "\n",
    "# permissive prior\n",
    "bayesfactors['log']['permissive'] = dict(); best_params['log']['permissive'] = dict(); avg_params['log']['permissive'] = dict(); drl_weighted_avg['log']['permissive'] = dict(); posteriors_all['log']['permissive'] = dict(); posterior_95c['log']['permissive'] = dict(); grid_drl_95c['log']['permissive'] = dict(); rates_weighted_exp['log']['permissive'] = dict(); rates_weighted_con['log']['permissive'] = dict(); grid_rates_95c['log']['permissive'] = dict()\n",
    "model_summary(grid_likelihood, 'log', 'permissive', '4param', prior = prior_rates, params = ['exp_i', 'con_i', 'exp_p', 'con_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)\n",
    "\n",
    "# 2 parameter Bayes factor, model where power law is same, intercept is same\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_p'] == partial_grid['con_p']) & (partial_grid['exp_i'] == partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'log', 'permissive', '2param', prior = prior_rates, params = ['exp_i', 'exp_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)\n",
    "\n",
    "# Multiplier 3 parameter model\n",
    "partial_grid = grid_likelihood.copy().reset_index()\n",
    "partial_grid = partial_grid.where((partial_grid['exp_i'] == 1+ partial_grid['con_i'])).dropna()\n",
    "model_summary(partial_grid, 'log', 'permissive', '3param_Mult', prior = prior_rates, params = ['M', 'exp_p', 'con_p'], grid_drl = inference_grid_final_log_norm_ps, rates = rates_all_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06dc117-18f7-419d-ae07-5c67a9fd2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_params['log']['uniform'] = pd.concat(avg_params['log']['uniform']).unstack()\n",
    "avg_params['log']['restrictive'] = pd.concat(avg_params['log']['restrictive']).unstack()\n",
    "avg_params['log']['permissive'] = pd.concat(avg_params['log']['permissive']).unstack()\n",
    "avg_params['log'] = pd.concat(avg_params['log'])\n",
    "\n",
    "best_params['log']['uniform'] = pd.concat(best_params['log']['uniform']).unstack()\n",
    "best_params['log']['restrictive'] = pd.concat(best_params['log']['restrictive']).unstack()\n",
    "best_params['log']['permissive'] = pd.concat(best_params['log']['permissive']).unstack()\n",
    "best_params['log'] = pd.concat(best_params['log'])\n",
    "\n",
    "drl_weighted_avg['log']['uniform'] = pd.concat(drl_weighted_avg['log']['uniform']).unstack()\n",
    "drl_weighted_avg['log']['restrictive'] = pd.concat(drl_weighted_avg['log']['restrictive']).unstack()\n",
    "drl_weighted_avg['log']['permissive'] = pd.concat(drl_weighted_avg['log']['permissive']).unstack()\n",
    "drl_weighted_avg['log'] = pd.concat(drl_weighted_avg['log'])\n",
    "\n",
    "rates_weighted_exp['log']['uniform'] = pd.concat(rates_weighted_exp['log']['uniform']).unstack().T\n",
    "rates_weighted_exp['log']['restrictive'] = pd.concat(rates_weighted_exp['log']['restrictive']).unstack().T\n",
    "rates_weighted_exp['log']['permissive'] = pd.concat(rates_weighted_exp['log']['permissive']).unstack().T\n",
    "rates_weighted_exp['log'] = pd.concat(rates_weighted_exp['log'])\n",
    "\n",
    "rates_weighted_con['log']['uniform'] = pd.concat(rates_weighted_con['log']['uniform']).unstack().T\n",
    "rates_weighted_con['log']['restrictive'] = pd.concat(rates_weighted_con['log']['restrictive']).unstack().T\n",
    "rates_weighted_con['log']['permissive'] = pd.concat(rates_weighted_con['log']['permissive']).unstack().T\n",
    "rates_weighted_con['log'] = pd.concat(rates_weighted_con['log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd95d66-78ec-4acb-9265-315309e65af4",
   "metadata": {},
   "source": [
    "### Plot posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ae431-a563-410a-a813-001de7a80f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 3, cols = 7, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.02, vertical_spacing = 0.08, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[1:]], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "\n",
    "current_posterior = posteriors_all['log']['uniform']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=1; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 1, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "current_posterior = posteriors_all['log']['permissive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=2; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 2, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "current_posterior = posteriors_all['log']['restrictive']['3param_Mult'].sort_values(by = [0], ascending = False)\n",
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])\n",
    "row_count=3; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = posterior_contour.loc[m].index.get_level_values(0), y = posterior_contour.loc[m].index.get_level_values(1), z=(posterior_contour.loc[m]['level_0']+1), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "# best parameter combination\n",
    "fig.add_annotation(x=current_posterior.iloc[0]['exp_p'], y=current_posterior.iloc[0]['con_p'], showarrow=True, arrowhead=1, arrowcolor = 'red', row = 3, col = pd.Series(range(1,8), index = m_list).loc[current_posterior.iloc[0]['M']])\n",
    "\n",
    "fig.update_layout(coloraxis1=dict(colorscale=discrete_deep_range, colorbar = dict(title = 'HDR', len=0.55, tickvals = [1.5,2.5,3.5,4.5], ticktext = ['68%', '95%', '99.7%', '99.99%'], x = 1.05), cmin = 1, cmax = 5))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 420, width = 1000, margin={'t':50,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62ece8-4ad4-4052-a3b3-9188a150b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/posterior_dist_contour_PL_3mult_uniform_permissive_restrictive_log.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d04fe-4e71-4702-8662-06776f86c396",
   "metadata": {},
   "source": [
    "### Plot HDR range and posterior-weighted DRLs and rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb40f5d-96f9-4dd0-8922-137a1e739d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = 'log'; current_prior = 'uniform'; current_param = '3param_Mult'\n",
    "current_posterior = posteriors_all[current_model][current_prior][current_param].sort_values(by = [0], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a799d4b-e4e7-4731-ad24-71258f6b675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_contour = dict()\n",
    "for num in range(len(spacing)-1):\n",
    "    posterior_contour[num] = current_posterior.where((current_posterior[0].cumsum() > spacing[num]) & (current_posterior[0].cumsum() <= spacing[num+1])).dropna()\n",
    "posterior_contour = pd.concat(posterior_contour).reset_index().set_index(['M', 'exp_p', 'con_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ffcc5c-c502-4147-a3c6-4a80230fc138",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_fig_list_contour(inference_grid_final_log_norm_ps, posterior_contour, norm_range=(range(4,201)), showgroups=[1], tracename = '95% HDR (uniform prior)')\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].loc[current_prior].loc[current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (uniform)', line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], width = 3)))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['permissive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (permissive)', line = dict(width = 3, dash = 'dash', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))\n",
    "fig.add_trace(go.Scatter(x = list(L_range), y = drl_weighted_avg[current_model].T['restrictive'][current_param] * bootstrap_counts_mean['A'].reindex(L_range).sum(), name = 'weighted DRL (restrictive)', line = dict(width = 3, dash = 'dot', color = plotly.colors.DEFAULT_PLOTLY_COLORS[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be157f1-64bc-4931-8b57-75351d8a7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/DRL_95HDR_log_uniform_3mult.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087169e-fdc6-420b-957c-1fbea444720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates = make_fig_rates_list_contour(None, rates_all)\n",
    "for prior, dash in zip(['uniform', 'permissive', 'restrictive'], [None, 'dash', 'dot']):\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_exp[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], dash = dash, width = 4), name = 'weighted ùúÄ|<i>L</i> (' + prior + ')',))\n",
    "    fig_rates.add_trace(go.Scatter(x = list(range(9,200)), y = rates_weighted_con[current_model].loc[prior][current_param].reindex(range(9,200)), mode = 'lines', legendgroup = prior, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], dash = dash, width = 4), name = 'weighted ùúÖ|<i>L</i> (' + prior + ')',))\n",
    "fig_rates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f043da-a033-4d40-8e4a-5c0a4604f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/rates_95c_weighted_log_allpriors_3mult.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926fc85-7911-4429-a3f7-69ef9e100efe",
   "metadata": {},
   "source": [
    "# Collection of info for Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da809b-56b8-4a08-bdab-b2434d3cbe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors_summary = pd.DataFrame.from_dict(bayesfactors).T.stack().apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bb508-163e-43ed-96b7-19a230656023",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60e2b6-2489-49b0-9aa2-1d7f38cadbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesfactors_summary.div(bayesfactors_summary['2param'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b6989-2c74-4789-a232-f77ed93cde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a28cd-91e3-442b-a7ad-432ad3bdc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(avg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c8f29-1720-4cda-8a65-88d0c6656b14",
   "metadata": {},
   "source": [
    "# Genome size plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b73a4-940f-4460-a9c6-eda7e89b7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_size_final = inference_grid_final_nointerp_subonly.mul(inference_grid_final_nointerp_subonly.index, axis=0).sum()# + inference_grid_final_nointerp_subonly_Bdist.mul(inference_grid_final_nointerp_subonly_Bdist.index, axis=0).sum()\n",
    "genome_size_final = genome_size_final.reset_index()\n",
    "genome_size_final['M'] = pd.Series(intercept_list / intercept_list[1]).reindex(genome_size_final['exp_i']).values\n",
    "genome_size_final = genome_size_final.set_index(['M', 'exp_p', 'con_p'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084e182-76da-4421-bc62-4067ebd4f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S12a\n",
    "fig = make_subplots(rows = 1, cols = 7, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.01, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[1:]], x_title = 'expansion power ùúè<sub>ùúÄ</sub>', y_title = 'contraction power ùúè<sub>ùúÖ</sub>')\n",
    "row_count=1; col_count = 0\n",
    "for m in m_list:\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = genome_size_final.loc[m].index.get_level_values(0), y = genome_size_final.loc[m].index.get_level_values(1), z=np.log10(genome_size_final.loc[m].replace(0, 1e50)), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='deep_R', colorbar = dict(title = 'log<sub>10</sub>(total nt)', len=1), cmin = 9.3, cmax= 50))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 200, width = 1000, margin={'t':30,'l':50,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power ùúè<sub>ùúÄ</sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power ùúè<sub>ùúÖ</sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663fde8-3df8-4d48-b195-d5c9ab73fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig_S12a.png', scale=10)\n",
    "fig.write_image('plots/fig_S12a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d29734-6723-4a60-8a74-9e097adee39d",
   "metadata": {},
   "source": [
    "# Plot DRLs according to delta-tau values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad5b21-d24a-485e-a67e-98de9e2adce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_index = inference_grid_final_nointerp_subonly.T.reset_index()[['exp_i', 'con_i', 'exp_p', 'con_p']]\n",
    "\n",
    "# ignore lower left corner\n",
    "exp_i = 3; con_i = 2\n",
    "corner_size = 1\n",
    "diagonal_groups = dict()\n",
    "for diag in [0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2, -1.3, -1.4, -1.5, -1.6, -1.7, -1.8, -1.9, -2, -2.1, -2.2, -2.3, -2.4, -2.5, -2.6, -2.7, -2.8, -2.9, -3, -3.1, -3.2, -3.3, -3.4, -3.5, -3.6, -3.7, -3.8, -3.9, -4]:\n",
    "    diagonal_groups[diag] = grid_index.loc[(grid_index['exp_i'] == exp_i) & (grid_index['con_i'] == con_i) & (grid_index['exp_p'] - grid_index['con_p'] >= diag-0.01) & (grid_index['exp_p'] - grid_index['con_p'] <= diag+0.01)].copy()#  & ((grid_index['exp_p'] >corner_size) | (grid_index['con_p'] >corner_size))].copy()\n",
    "    if len(diagonal_groups[diag]) == 0:\n",
    "        del diagonal_groups[diag]\n",
    "\n",
    "diagonal_groups_exp = dict()\n",
    "for diag in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4]:\n",
    "    diagonal_groups_exp[diag] = grid_index.loc[(grid_index['exp_i'] == exp_i) & (grid_index['con_i'] == con_i) & (grid_index['exp_p'] - grid_index['con_p'] >= diag-0.01) & (grid_index['exp_p'] - grid_index['con_p'] <= diag+0.01)].copy()#  & ((grid_index['exp_p'] >corner_size) | (grid_index['con_p'] >corner_size))].copy()\n",
    "    if len(diagonal_groups_exp[diag]) == 0:\n",
    "        del diagonal_groups_exp[diag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea9dab7-8b1f-46b9-b672-3c334d87e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_adjustment = 5\n",
    "current_colorscale = plotly.colors.sample_colorscale(plotly.colors.sequential.Rainbow, np.linspace(0,(len(diagonal_groups.keys())+color_adjustment) / (len(diagonal_groups.keys())+color_adjustment), len(diagonal_groups.keys())+color_adjustment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e401e-3117-46c3-8d93-7c75bb3d66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 6a (illustration of dtau in parameter space)\n",
    "fig_phases = go.Figure()\n",
    "for diag in list(diagonal_groups_exp.keys())[:-1]:\n",
    "    fig_phases.add_trace(go.Scatter(x = diagonal_groups_exp[diag]['exp_p'], y = diagonal_groups_exp[diag]['con_p'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 6, color = 'rgba(120,120,120,0.65)')))\n",
    "colornum = 0\n",
    "for diag in diagonal_groups:\n",
    "    fig_phases.add_trace(go.Scatter(x = diagonal_groups[diag]['exp_p'], y = diagonal_groups[diag]['con_p'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 6, color = current_colorscale[colornum])))\n",
    "    colornum +=1\n",
    "\n",
    "fig_phases.add_trace(go.Scatter(x = [0], y = [3.5], marker = dict(color = 'red', size = 8, line_width = 1, line_color = 'white', symbol = 'circle'), mode = 'markers', name = 'i'))\n",
    "fig_phases.add_trace(go.Scatter(x = [1], y = [2.5], marker = dict(color = 'red', size = 9, line_width = 1, line_color = 'white', symbol = 'diamond'), mode = 'markers', name = 'ii'))\n",
    "fig_phases.add_trace(go.Scatter(x = [1.5], y = [2], marker = dict(color = 'red', size = 8, line_width = 1, line_color = 'white', symbol = 'square'), mode = 'markers', name = 'iii'))\n",
    "fig_phases.add_trace(go.Scatter(x = [1.7], y = [1.8], marker = dict(color = 'red', size = 11, line_width = 1, line_color = 'white', symbol = 'triangle-up'), mode = 'markers', name = 'iv'))\n",
    "fig_phases.add_trace(go.Scatter(x = [2.5], y = [1], marker = dict(color = 'red', size = 11, line_width = 1, line_color = 'white', symbol = 'triangle-down'), mode = 'markers', name = 'v'))\n",
    "\n",
    "fig_phases.update_layout(font=dict(family = 'Arial', size = 14), height = 250, width = 270, margin={'t':30,'l':35,'b':40,'r':0})\n",
    "fig_phases.update_xaxes(range = [-0.2, 3.5], dtick = 1, title = 'expansion power ùúè<sub>ùúÄ</sub>', gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_phases.update_yaxes(range = [0, 3.58], dtick = 1, title = 'contraction power ùúè<sub>ùúÖ</sub>', gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"x\", scaleratio=1)\n",
    "fig_phases.update_layout(legend=dict(indentation = -15))\n",
    "fig_phases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e7d21-44d1-48cc-b30b-bf2b41413789",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_phases.write_image('plots/fig6a.svg')\n",
    "fig_phases.write_image('plots/fig6a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dffe370-23ba-4077-abb5-37f2a1c7b653",
   "metadata": {},
   "source": [
    "#### Plots for Fig. S11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569f635-2948-46f5-97ae-b1ee3bd2d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_add_paramlist(fig, param_list, group_name, colorlist = plotly.colors.cyclical.Phase, motif = 'A', colornum = 0, df = inference_grid_final_nointerp_subonly, opacity = 0.5, show_CHM13 = False):\n",
    "    group = df.reindex(param_list.set_index(['exp_i', 'con_i', 'exp_p', 'con_p']).index, axis=1).copy()\n",
    "    group.columns = list(range(len(group.columns)))\n",
    "    group = group[group >1].fillna(1,limit=1, axis=0)\n",
    "    group.loc[len(group)+1] = np.nan\n",
    "    \n",
    "    # remove last n bins (if part of reflective boundary)\n",
    "    for i in range(8):\n",
    "        group_last = group[group >1].isna().idxmax().replace(1,200) -1; group_cols = group.columns\n",
    "        group = group.unstack()\n",
    "        group.loc[zip(group_cols, group_last)] = [np.nan if val > 1e2 else val for val in group.loc[zip(group_cols, group_last)]]\n",
    "        group = group.unstack().T\n",
    "    group_index = np.array(([group.index]*200)).flatten()\n",
    "    # normalize\n",
    "    group = group / group.sum()\n",
    "    group = pd.Series(group.transpose().to_numpy().flatten())\n",
    "\n",
    "    fig.add_trace(go.Scatter(x = group_index, y = group, mode = 'lines', line = dict(width = 1.5, color = colorlist[colornum] if colornum != -1 else 'rgba(120,120,120,0.2)'), name = group_name, connectgaps = False, opacity = opacity))\n",
    "    if show_CHM13 == True:\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_mean[motif].index, y = bootstrap_counts_mean[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,1)', width = 3), legendgroup = 'ci', name = 'T2T-CHM13'))\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_max[motif].index, y = bootstrap_counts_max[motif] / bootstrap_counts_mean[motif].sum(), line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 95%'))\n",
    "            fig.add_trace(go.Scatter(x = bootstrap_counts_min[motif].index, y = bootstrap_counts_min[motif] / bootstrap_counts_mean[motif].sum(), fill='tonexty', fillcolor = 'rgba(0,0,0,0.25)', line = dict(color = 'rgba(0,0,0,0)'), legendgroup = 'ci', showlegend = False, name = 'CHM13 bootstrap 5%'))\n",
    "    fig.update_xaxes(type = 'log', title = 'repeat tract length (units)', range = [0,2.5], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig.update_yaxes(type = 'log', title = 'counts (normalized)', range = [-9.1,0], gridcolor = 'rgba(0,0,0,0.2)', tickformat = '1.0e', dtick = 2)\n",
    "    fig.update_layout(font=dict(family = 'Arial', size = 16), height = 300, width = 780, margin={'t':20,'l':60,'b':40,'r':10}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b00e01-e7af-457d-a35b-999d1d734e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore lower left corner\n",
    "for exp_i, con_i, corner_size in zip(range(1,8), range(7), [1.8, 1.6, 1.4, 1.2, 1, 0.8, 0.6]):\n",
    "    diagonal_groups = dict()\n",
    "    for diag in [0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2, -1.3, -1.4, -1.5, -1.6, -1.7, -1.8, -1.9, -2, -2.1, -2.2, -2.3, -2.4, -2.5, -2.6, -2.7, -2.8, -2.9, -3, -3.1, -3.2, -3.3, -3.4, -3.5, -3.6, -3.7, -3.8, -3.9, -4]:\n",
    "        diagonal_groups[diag] = grid_index.loc[(grid_index['exp_i'] == exp_i) & (grid_index['con_i'] == con_i) & (grid_index['exp_p'] - grid_index['con_p'] >= diag-0.01) & (grid_index['exp_p'] - grid_index['con_p'] <= diag+0.01)  & ((grid_index['exp_p'] >corner_size) | (grid_index['con_p'] >corner_size))].copy()\n",
    "        if len(diagonal_groups[diag]) == 0:\n",
    "            del diagonal_groups[diag]\n",
    "    \n",
    "    diagonal_groups_exp = dict()\n",
    "    for diag in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4]:\n",
    "        diagonal_groups_exp[diag] = grid_index.loc[(grid_index['exp_i'] == exp_i) & (grid_index['con_i'] == con_i) & (grid_index['exp_p'] - grid_index['con_p'] >= diag-0.01) & (grid_index['exp_p'] - grid_index['con_p'] <= diag+0.01)  & ((grid_index['exp_p'] >corner_size) | (grid_index['con_p'] >corner_size))].copy()\n",
    "        if len(diagonal_groups_exp[diag]) == 0:\n",
    "            del diagonal_groups_exp[diag]\n",
    "\n",
    "    fig_phases = go.Figure()\n",
    "    for diag in list(diagonal_groups_exp.keys())[:-1]:\n",
    "        fig_phases.add_trace(go.Scatter(x = diagonal_groups_exp[diag]['exp_p'], y = diagonal_groups_exp[diag]['con_p'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 4.5, color = 'rgba(120,120,120,0.65)')))\n",
    "    colornum = 0\n",
    "    for diag in diagonal_groups:\n",
    "        fig_phases.add_trace(go.Scatter(x = diagonal_groups[diag]['exp_p'], y = diagonal_groups[diag]['con_p'], name = str(diag), mode = 'markers', opacity = 0.75, showlegend = False, marker = dict(symbol = 'square', size = 4.5, color = current_colorscale[colornum])))\n",
    "        colornum +=1\n",
    "    fig_phases.update_layout(title = '<i>m</i>='+str(round(intercept_list[exp_i] / intercept_list[1], 2)), font=dict(family = 'Arial', size = 12), height = 220, width = 220, margin={'t':30,'l':35,'b':40,'r':10})\n",
    "    fig_phases.update_xaxes(range = [0,4.1], dtick = 1, title = 'expansion power ùúè<sub>ùúÄ</sub>', gridcolor = 'rgba(0,0,0,0.2)')\n",
    "    fig_phases.update_yaxes(range = [0,4.1], dtick = 1, title = 'contraction power ùúè<sub>ùúÖ</sub>', gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"x\", scaleratio=1)\n",
    "    \n",
    "\n",
    "    fig = go.Figure()\n",
    "    for diag in list(diagonal_groups_exp.keys())[:-1]:\n",
    "        fig_add_paramlist(fig, diagonal_groups_exp[diag], group_name = str(diag), colornum = -1, show_CHM13 = False)\n",
    "    colornum = 0\n",
    "    for diag in list(diagonal_groups.keys())[:-1]:\n",
    "        fig_add_paramlist(fig, diagonal_groups[diag], group_name = str(diag), colorlist = current_colorscale, colornum = colornum, opacity = 0.4, show_CHM13 = False)\n",
    "        colornum +=1\n",
    "    for diag in list(diagonal_groups.keys())[-1:]:\n",
    "        fig_add_paramlist(fig, diagonal_groups[diag], group_name = str(diag), colorlist = current_colorscale, colornum = colornum, opacity = 0.4, show_CHM13 = True)\n",
    "    fig.update_xaxes(range=[0,2.33], tickvals = [1,2,5,10,20,50,100,200])\n",
    "    fig.update_layout(font=dict(family = 'Arial', size = 14), height = 250, width = 520, margin={'t':30,'l':60,'b':40,'r':10}, showlegend = False)\n",
    "    \n",
    "    fig_phases.write_image('plots/figS5a_mult'+str(exp_i)+'_' + str(con_i)+'.pdf')\n",
    "    fig.write_image('plots/figS5b_mult'+str(exp_i)+'_' + str(con_i)+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7941b2-3f79-4f0b-aa1e-1c9bd271c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example\n",
    "fig_phases.show()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f96c33-63e4-460a-adf2-e847e8805462",
   "metadata": {},
   "source": [
    "# Flux plots for analytics comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd5750-f987-4f84-83ff-0ec7756cce05",
   "metadata": {},
   "source": [
    "#### Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3bd52-5cc4-4325-8446-1ad343b201cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolve function\n",
    "def mut_evolve_dist_AB(A_count_input, B_count_input, starting_conditions, boot = None, input_nuc = 'A', mut = True, mutonly = False, speedup_multiplier = 1, output_components = False, stochastics = None, reflective = True, boundary_count = 1000):\n",
    "    exp_rate_A_AA, con_rate_A_AA, nonexp_rate_A_AB, B_indel_rates = starting_conditions\n",
    "    A_count_output = A_count_input.copy(); B_count_output = B_count_input.copy()\n",
    "    A_bins = len(A_count_input)\n",
    "    B_bins = len(B_count_input)\n",
    "    A_length_array = np.array(range(1,A_bins+3))\n",
    "    A_length_array_bases = np.array(range(1,A_bins+3)) * len(input_nuc) ### including motif length\n",
    "    B_length_array = np.array(range(1,B_bins+3))\n",
    "    B_length_array_bases = np.array(range(1,B_bins+3)) * len(input_nuc) ### including motif length\n",
    "    A_count_input = np.insert(A_count_input, A_bins, [0,0])\n",
    "    B_count_input = np.insert(B_count_input, B_bins, [0,0])\n",
    "    if boot is None:\n",
    "        denovo_sub = denovo_substitution_context_rate.loc[input_nuc]\n",
    "    else:\n",
    "        denovo_sub = denovo_substitution_context_rate_poisson.loc[boot].loc[input_nuc]\n",
    "    # distribution info\n",
    "    total_B_bases = (B_count_input[:B_bins] * B_length_array_bases[:B_bins]).sum()\n",
    "    B_L1_base_portion = ((B_count_input[0] * len(input_nuc)) / (B_count_input[:B_bins]* B_length_array_bases[:B_bins]).sum()) ### including motif length\n",
    "    B_nonflank_base_portion = (B_count_input[2:B_bins+2] * B_length_array_bases[:B_bins]).sum() / total_B_bases  ### include portion of triplets 1nt away???\n",
    "    B_flank_base_portion = (B_count_input[1:B_bins] * 2 * len(input_nuc)).sum() / total_B_bases ### including motif length\n",
    "    total_A_bases = (A_count_input[:A_bins] * A_length_array_bases[:A_bins]).sum()\n",
    "    A_nonflank_base_portion = (A_count_input[2:A_bins+2] * A_length_array_bases[:A_bins]).sum() / total_A_bases\n",
    "    A_flank_base_portion = (A_count_input[1:A_bins] * 2 * len(input_nuc)).sum() / total_A_bases ### including motif length\n",
    "    total_A_change_in = np.array([0.0]*A_bins); total_B_change_in = np.array([0.0]*B_bins)\n",
    "    total_A_change_out = np.array([0.0]*A_bins); total_B_change_out = np.array([0.0]*B_bins)\n",
    "    if mut == True:\n",
    "        # A>B which adds to the A count locally. add these to A\n",
    "        A_mut_in_local_A_B = 2 * len(input_nuc) * denovo_sub['Acontraction'] * A_count_input[1:]\n",
    "        A_mut_out_local_A_B = -2 * len(input_nuc) * denovo_sub['Acontraction'] * A_count_input\n",
    "        A_mut_out_local_A_B[0] = -1 * len(input_nuc) * A_count_input[0] * denovo_sub['A10']\n",
    "        # total number of A>B fission events\n",
    "        A_mut_out_fission = np.insert((-denovo_sub['Afission'] * A_count_input[2:] * A_length_array_bases[:A_bins]), 0, [0, 0]) # used to subtract from A_count, starting from L=3 (with 0 for L=1,2)\n",
    "        # each fission creates 2 As. add these to A\n",
    "        A_mut_in_fission = ((2/A_length_array[:A_bins]) * -A_mut_out_fission[2:A_bins+2])[::-1].cumsum()[::-1]\n",
    "         # B>A which adds to the A count locally (which must come from B_L>1)\n",
    "        # A from B>A leaving the -1 bin\n",
    "        A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "        A_mut_out_local_B_A = -denovo_sub['Aexpansion'] * B_flank_base_portion * total_B_bases * A_len_freq\n",
    "        # B>A creating A_L=1 from B_L>2\n",
    "        B_A_into_L1 = total_B_bases * B_nonflank_base_portion * denovo_sub['A01']\n",
    "        A_mut_in_local_B_A = np.insert(-A_mut_out_local_B_A, 0, B_A_into_L1)     \n",
    "        # fusion process for A\n",
    "        A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "        A_fusion_freq_in = np.bincount((np.add.outer(A_length_array[:A_bins], A_length_array[:A_bins])+1).ravel(), weights = np.outer(A_len_freq, A_len_freq).ravel())[1:]\n",
    "        A_mut_in_fusion_A_B = A_fusion_freq_in * denovo_sub['Afusion'] * B_L1_base_portion * total_B_bases\n",
    "        A_mut_out_fusion_A_B = (-2) *A_len_freq * denovo_sub['Afusion'] * B_L1_base_portion * total_B_bases \n",
    "        # total B>A\n",
    "        # B>A which adds to the B count locally. add these to B\n",
    "        B_mut_in_local_B_A = 2 * len(input_nuc) * denovo_sub['Aexpansion'] * B_count_input[1:]\n",
    "        B_mut_out_local_B_A = -2 * len(input_nuc) * denovo_sub['Aexpansion'] * B_count_input\n",
    "        B_mut_out_local_B_A[0] = -1 * B_L1_base_portion * total_B_bases * denovo_sub['Afusion']\n",
    "        # total number of B>A fission events\n",
    "        B_mut_out_fission = np.insert((-denovo_sub['A01'] * B_count_input[2:] * B_length_array_bases[:B_bins]), 0, [0, 0]) # used to subtract from B_count, starting from L=3 (with 0 for L=1,2)\n",
    "        # each fission creates 2 Bs. add these to B\n",
    "        B_mut_in_fission = ((2/B_length_array[:B_bins]) * -B_mut_out_fission[2:B_bins+2])[::-1].cumsum()[::-1]\n",
    "        # A>B which adds to the B count locally (which must come from A_L>1)\n",
    "        # B from A>B leaving the -1 bin\n",
    "        B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "        B_mut_out_local_A_B = -denovo_sub['Acontraction'] * A_flank_base_portion * total_A_bases * B_len_freq\n",
    "        # A>B creating B_L=1 from A_L>2\n",
    "        A_B_into_L1 = total_A_bases * A_nonflank_base_portion * denovo_sub['Afission']\n",
    "        B_mut_in_local_A_B = np.insert(-B_mut_out_local_A_B, 0, A_B_into_L1)\n",
    "        # fusion process for B\n",
    "        B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "        B_fusion_freq_in = np.bincount((np.add.outer(B_length_array[:B_bins], B_length_array[:B_bins])+1).ravel(), weights = np.outer(B_len_freq, B_len_freq).ravel())[1:]\n",
    "        B_mut_in_fusion_B_A = B_fusion_freq_in * denovo_sub['A10'] * A_count_input[0] * len(input_nuc)\n",
    "        B_mut_out_fusion_B_A = (-2) * B_len_freq * denovo_sub['A10'] * A_count_input[0] * len(input_nuc)\n",
    "        # update counts for next round (with absorbing boundary)\n",
    "        total_A_change_in += A_mut_in_local_A_B[:A_bins] + A_mut_in_local_B_A[:A_bins] + A_mut_in_fission[:A_bins] + A_mut_in_fusion_A_B[:A_bins]\n",
    "        total_B_change_in += B_mut_in_local_B_A[:B_bins] + B_mut_in_local_A_B[:B_bins] + B_mut_in_fission[:B_bins] + B_mut_in_fusion_B_A[:B_bins]\n",
    "        total_A_change_out += A_mut_out_local_A_B[:A_bins] + A_mut_out_local_B_A[:A_bins] + A_mut_out_fission[:A_bins] + A_mut_out_fusion_A_B[:A_bins]\n",
    "        total_B_change_out += B_mut_out_local_B_A[:B_bins] + B_mut_out_local_A_B[:B_bins] + B_mut_out_fission[:B_bins] + B_mut_out_fusion_B_A[:B_bins]\n",
    "        # apply reflecting boundary\n",
    "        if reflective == True:\n",
    "            total_A_change_in[A_bins-1] += A_mut_in_local_A_B[A_bins:].sum() + A_mut_in_local_B_A[A_bins:].sum() + A_mut_in_fission[A_bins:].sum() + A_mut_in_fusion_A_B[A_bins:].sum()\n",
    "            total_B_change_in[B_bins-1] += B_mut_in_local_B_A[B_bins:].sum() + B_mut_in_local_A_B[B_bins:].sum() + B_mut_in_fission[B_bins:].sum() + B_mut_in_fusion_B_A[B_bins:].sum()\n",
    "            total_A_change_out[A_bins-1] += A_mut_out_local_A_B[A_bins:].sum() + A_mut_out_local_B_A[A_bins:].sum() + A_mut_out_fission[A_bins:].sum() + A_mut_out_fusion_A_B[A_bins:].sum()\n",
    "            total_B_change_out[B_bins-1] += B_mut_out_local_B_A[B_bins:].sum() + B_mut_out_local_A_B[B_bins:].sum() + B_mut_out_fission[B_bins:].sum() + B_mut_out_fusion_B_A[B_bins:].sum()\n",
    "           \n",
    "    if mutonly == False:\n",
    "        # A expansions in and out\n",
    "        A_exp_out = A_count_input[:A_bins] * -exp_rate_A_AA[:A_bins]\n",
    "        A_exp_in = np.insert(-A_exp_out, 0, B_indel_rates[0]*total_B_bases)\n",
    "        # A contractions in and out\n",
    "        A_con_out = A_count_input[:A_bins+1] * -con_rate_A_AA[:A_bins+2]\n",
    "        A_con_in = -A_con_out[1:]\n",
    "        # A fusions from B1>B0 deletions\n",
    "        if (mut != True):\n",
    "            A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "            A_fusion_freq_in = np.bincount((np.add.outer(A_length_array[:A_bins], A_length_array[:A_bins])+1).ravel(), weights = np.outer(A_len_freq, A_len_freq).ravel())[1:]\n",
    "        A_mut_in_fusion_Bdel = A_fusion_freq_in[1:A_bins+1] * B_indel_rates[1] * B_L1_base_portion * total_B_bases\n",
    "        A_mut_out_fusion_Bdel = (-2) *A_len_freq * B_indel_rates[1] * B_L1_base_portion * total_B_bases\n",
    "        # A fission events from insertions\n",
    "        A_nonexp_out_fission = -A_count_input * nonexp_rate_A_AB # used to calculate fission_in, starting with L=2 going to 2x L=1\n",
    "        # each fission creates 2 As. add these to A\n",
    "        A_nonexp_in_fission = ((2/A_length_array[:A_bins]) * -A_nonexp_out_fission[1:A_bins+1])[::-1].cumsum()[::-1]\n",
    "        # B expansions in and out\n",
    "        B_exp_out = B_count_input[:B_bins] * -B_indel_rates[2] * B_length_array[:B_bins] # B>BB rates are flat, per base\n",
    "        B_exp_in = np.insert(-B_exp_out, 0, A_nonexp_out_fission.sum())\n",
    "        # B contractions in and out\n",
    "        B_con_out = B_count_input[:B_bins+1] * -B_indel_rates[1] * B_length_array[:B_bins+1] # B>_ rates are flat, per base\n",
    "        B_con_in = -B_con_out[1:]\n",
    "        # B fusions from A1>A0 deletions\n",
    "        if (mut != True):\n",
    "            B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "            B_fusion_freq_in = np.bincount((np.add.outer(B_length_array[:B_bins], B_length_array[:B_bins])+1).ravel(), weights = np.outer(B_len_freq, B_len_freq).ravel())[1:]\n",
    "        B_mut_in_fusion_Adel = B_fusion_freq_in[1:B_bins+1] * A_count_input[0] * con_rate_A_AA[0]\n",
    "        B_mut_out_fusion_Adel = 2 *B_len_freq * A_count_input[0] * -con_rate_A_AA[0]\n",
    "        # B fission events from insertions\n",
    "        B_nonexp_out_fission = -B_count_input * B_indel_rates[0] * B_length_array # used to calculate fission_in, starting with L=2 going to 2x L=1\n",
    "        # each fission creates 2 Bs. add these to B\n",
    "        B_nonexp_in_fission = ((2/B_length_array[:B_bins]) * -B_nonexp_out_fission[1:B_bins+1])[::-1].cumsum()[::-1]\n",
    "       # update counts for next round (with absorbing boundary)\n",
    "        total_A_change_in += A_exp_in[:A_bins] + A_con_in[:A_bins] + A_mut_in_fusion_Bdel[:A_bins] + A_nonexp_in_fission[:A_bins]\n",
    "        total_B_change_in += B_exp_in[:B_bins] + B_con_in[:B_bins] + B_mut_in_fusion_Adel[:B_bins] + B_nonexp_in_fission[:B_bins]\n",
    "        total_A_change_out += A_exp_out[:A_bins] + A_con_out[:A_bins] + A_mut_out_fusion_Bdel[:A_bins] + A_nonexp_out_fission[:A_bins]\n",
    "        total_B_change_out += B_exp_out[:B_bins] + B_con_out[:B_bins] + B_mut_out_fusion_Adel[:B_bins] + B_nonexp_out_fission[:B_bins]\n",
    "        # apply reflecting boundary\n",
    "        if reflective == True:\n",
    "            total_A_change_in[A_bins-1] += A_exp_in[A_bins:].sum() + A_con_in[A_bins:].sum() + A_mut_in_fusion_Bdel[A_bins:].sum() + A_nonexp_in_fission[A_bins:].sum()\n",
    "            total_B_change_in[B_bins-1] += B_exp_in[B_bins:].sum() + B_con_in[B_bins:].sum() + B_mut_in_fusion_Adel[B_bins:].sum() + B_nonexp_in_fission[B_bins:].sum()\n",
    "            total_A_change_out[A_bins-1] += A_exp_out[A_bins:].sum() + A_con_out[A_bins:].sum() + A_mut_out_fusion_Bdel[A_bins:].sum() + A_nonexp_out_fission[A_bins:].sum()\n",
    "            total_B_change_out[B_bins-1] += B_exp_out[B_bins:].sum() + B_con_out[B_bins:].sum() + B_mut_out_fusion_Adel[B_bins:].sum() + B_nonexp_out_fission[B_bins:].sum()\n",
    "    # flag to stop the simulation if more repeats are removed from a bin than exist in that bin (excluding the last 10 noisy bins)\n",
    "    flag = ((np.abs(total_A_change_out[:A_bins-10]) * speedup_multiplier > A_count_output[:A_bins-10]).sum()) > 0\n",
    "    # apply speedup\n",
    "    total_A_change_in *= speedup_multiplier; total_A_change_out *= speedup_multiplier\n",
    "    total_B_change_in *= speedup_multiplier; total_B_change_out *= speedup_multiplier\n",
    "    if stochastics is not None:\n",
    "        # the sum of poisson random variables is poisson-distributed. not necessary to run n poisson samples\n",
    "        total_A_change_in = np.random.poisson(total_A_change_in.clip(0))\n",
    "        total_A_change_out = -1 * np.random.poisson(np.abs(total_A_change_out.clip(max=0)))\n",
    "        total_B_change_in = np.random.poisson(total_B_change_in.clip(0))\n",
    "        total_B_change_out = -1 * np.random.poisson(np.abs(total_B_change_out.clip(max=0)))   \n",
    "    total_A_change = total_A_change_in + total_A_change_out\n",
    "    total_B_change = total_B_change_in + total_B_change_out\n",
    "    # update counts for next round\n",
    "    A_count_output = A_count_output[:A_bins] + total_A_change[:A_bins]\n",
    "    B_count_output = B_count_output[:B_bins] + total_B_change[:B_bins]\n",
    "    # remove negative values\n",
    "    A_count_output[A_count_output <0] = 0            \n",
    "    B_count_output[B_count_output <0] = 0\n",
    "    boundary_flag = ((A_count_output[A_bins-1] > boundary_count) | (B_count_output[B_bins-1] > boundary_count))\n",
    "    if output_components == True:\n",
    "        if mutonly == False:\n",
    "            return  A_mut_in_local_A_B[:A_bins], A_mut_out_local_A_B[:A_bins], A_mut_in_local_B_A[:A_bins], A_mut_out_local_B_A[:A_bins], A_mut_in_fission[:A_bins], A_mut_out_fission[:A_bins], A_mut_in_fusion_A_B[:A_bins], A_mut_out_fusion_A_B[:A_bins], A_exp_in[:A_bins], A_exp_out[:A_bins], A_con_in[:A_bins], A_con_out[:A_bins], A_mut_in_fusion_Bdel[:A_bins], A_mut_out_fusion_Bdel[:A_bins], A_nonexp_in_fission[:A_bins], A_nonexp_out_fission[:A_bins]\n",
    "        else:\n",
    "            return  A_mut_in_local_A_B[:A_bins], A_mut_out_local_A_B[:A_bins], A_mut_in_local_B_A[:A_bins], A_mut_out_local_B_A[:A_bins], A_mut_in_fission[:A_bins], A_mut_out_fission[:A_bins], A_mut_in_fusion_A_B[:A_bins], A_mut_out_fusion_A_B[:A_bins]\n",
    "    else:\n",
    "        return A_count_output, B_count_output, flag, boundary_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd9273-1926-42be-991f-41b60b3b1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pin_power_law(power, pin_rate, pin_len=9, start_len=1, end_len=200):\n",
    "    denom = (pin_len**power) / pin_rate\n",
    "    return pd.Series([i**power for i in range(start_len, end_len+1)], index = list(range(start_len,end_len+1))) / denom\n",
    "\n",
    "def intercept_then_powerlaw(exp_power, con_power, exp_int, con_int, pin_len = 9, A_bins = 200, boot = None, motif = 'A', interp = False, nonexp_factor = 0.01, intercept_list = intercept_list):\n",
    "    if boot is None:\n",
    "        bootname = ''\n",
    "        denovo_exp_rate_current = denovo_exp_rate[motif].copy()\n",
    "        denovo_con_rate_current = denovo_con_rate[motif].copy()\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate[motif].copy()\n",
    "    else:\n",
    "        bootname = '_boot'+str(boot)\n",
    "        denovo_exp_rate_current = denovo_exp_rate_poisson[motif][boot].copy()\n",
    "        denovo_con_rate_current = denovo_con_rate_poisson[motif][boot].copy()\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate_poisson[motif][boot].copy()\n",
    "    exp = pd.concat([denovo_exp_rate_current.reindex(range(pin_len)), pin_power_law(exp_power, intercept_list[exp_int], start_len=pin_len, end_len=A_bins+3)])\n",
    "    con = pd.concat([denovo_con_rate_current.reindex(range(pin_len)), pin_power_law(con_power, intercept_list[con_int], start_len=pin_len, end_len=A_bins+3)])\n",
    "    nonexp = pd.concat([denovo_nonexp_rate_current.reindex(range(pin_len)), pin_power_law(exp_power, intercept_list[exp_int] * nonexp_factor, start_len=pin_len, end_len=A_bins+3)])\n",
    "    nonexpname = '_nex' + str(nonexp_factor)\n",
    "    nonexp.loc[1] = 0\n",
    "    if interp == True:\n",
    "        interpname = '_interp'\n",
    "        exp.loc[8:13] = np.nan\n",
    "        con.loc[8:13] = np.nan\n",
    "        nonexp.loc[8:13] = np.nan\n",
    "        exp = exp.interpolate(method = 'quadratic')\n",
    "        con = con.interpolate(method = 'quadratic')\n",
    "        nonexp = nonexp.interpolate(method = 'quadratic')\n",
    "    else:\n",
    "        interpname = ''\n",
    "    name = '_interceptPL_tE' + str(exp_power) + '_tC' + str(con_power) +'_iE' + str(exp_int) + '_iC' + str(con_int) + nonexpname + interpname + bootname\n",
    "    return name, exp, con, nonexp\n",
    "\n",
    "#### alternate rate functional forms\n",
    "def power_law_rate_at_L(power, L, rate = 1e-8, bins = 200):\n",
    "    return pd.Series([np.exp(np.log(rate) - power * np.log(L) + np.log(length)*power) for length in range(1,bins)], index = range(1,bins))\n",
    "\n",
    "def log_curve_from_L9(power, intercept, bins = 200):\n",
    "    return pd.Series([intercept_list[intercept] * (np.log(1+L-8) / np.log(1+9 -8))**power for L in range(9,bins+1)], index = range(9,bins+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce1e4c-5c0d-4929-bfb8-7e7bf3604988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup function\n",
    "def setup_evolve(exp_int, con_int, exp_power, con_power, starting_counts, boot = None, stochastics = None, interp = False, pin_len = 9, nonexp_factor = 0.01, A_bins = 200, B_bins = 200, input_nuc = 'A', exp_zero = False, con_zero = False, nonexp_zero = False, ceiling = None, rates_function = 'powerlaw'):\n",
    "# set up counts\n",
    "    A_length_array = np.array(range(1,A_bins+1))\n",
    "    B_length_array = np.array(range(1,A_bins+1))\n",
    "\n",
    "    A_count_input = np.nan_to_num(starting_counts[0].reindex(range(1,A_bins+1)).values)\n",
    "    B_count_input = np.nan_to_num(starting_counts[1].reindex(range(1,B_bins+1)).values)\n",
    "# set up rates    \n",
    "    if rates_function == 'powerlaw':\n",
    "        name, exp_rate, con_rate, nonexp_rate = intercept_then_powerlaw(exp_power = exp_power, con_power = con_power, exp_int = exp_int, con_int=con_int, pin_len=pin_len, A_bins = A_bins, boot = boot, motif = input_nuc, interp = interp, nonexp_factor = nonexp_factor)\n",
    "        B_indel_rate = np.array([exp_rate[0], con_rate[0], nonexp_rate[0]])        \n",
    "    if rates_function == 'powerlaw_x':\n",
    "        name = '_PL1e-8atL_tE' + str(exp_power) + '_tC' + str(con_power) +'_LE' + str(exp_int) + '_LC' + str(con_int)\n",
    "        exp_rate = power_law_rate_at_L(exp_power, exp_int, bins = A_bins+3).reindex(range(A_bins+3))\n",
    "        con_rate = power_law_rate_at_L(con_power, con_int, bins = A_bins+3).reindex(range(A_bins+3))\n",
    "        nonexp_rate = exp_rate * nonexp_factor\n",
    "        B_indel_rate = np.array([denovo_exp_rate[input_nuc][0], denovo_con_rate[input_nuc][0], denovo_nonexp_rate[input_nuc][0]])\n",
    "    if rates_function == 'log':\n",
    "        name = '_logrates_tE' + str(exp_power) + '_tC' + str(con_power) +'_LE' + str(exp_int) + '_LC' + str(con_int)\n",
    "        exp_rate = pd.concat([denovo_exp_rate['A'].loc[:8], log_curve_from_L9(exp_power, exp_int, A_bins+3)])\n",
    "        con_rate = pd.concat([denovo_con_rate['A'].loc[:8], log_curve_from_L9(con_power, con_int, A_bins+3)])\n",
    "        nonexp_rate = pd.concat([denovo_nonexp_rate['A'].loc[:8], log_curve_from_L9(exp_power, exp_int, A_bins+3) * nonexp_factor])\n",
    "        B_indel_rate = np.array([denovo_exp_rate[input_nuc][0], denovo_con_rate[input_nuc][0], denovo_nonexp_rate[input_nuc][0]])\n",
    "    if rates_function == 'custom':\n",
    "        exp_rate, con_rate, name = custom_rates\n",
    "        exp_rate = exp_rate.reindex(range(A_bins+3))\n",
    "        con_rate = con_rate.reindex(range(A_bins+3))\n",
    "        nonexp_rate = exp_rate * nonexp_factor\n",
    "        B_indel_rate = np.array([denovo_exp_rate[input_nuc][0], denovo_con_rate[input_nuc][0], denovo_nonexp_rate[input_nuc][0]])\n",
    "    # change rates from per unit to per STR\n",
    "    exp_rate = exp_rate.values[1:A_bins+1] * A_length_array\n",
    "    con_rate = con_rate.values[1:A_bins+2] * np.array(range(1,A_bins+2))\n",
    "    nonexp_rate = nonexp_rate.values[1:A_bins+3] * np.array(range(1,A_bins+3))\n",
    "    if ceiling != None:\n",
    "        ceiling_loc = []\n",
    "        if (exp_rate > ceiling).sum() > 0:\n",
    "            ceiling_loc.append(pd.Series(exp_rate > ceiling).idxmax())\n",
    "        if (con_rate > ceiling).sum() > 0:\n",
    "            ceiling_loc.append(pd.Series(con_rate > ceiling).idxmax())\n",
    "        if len(ceiling_loc) > 0:\n",
    "            ceiling_loc = min(np.array(ceiling_loc))\n",
    "            print( '\\r' + 'rate ceiling reached at L=' + str(ceiling_loc), end = ' ')\n",
    "            exp_rate[ceiling_loc:] = ceiling\n",
    "            con_rate[ceiling_loc:] = ceiling\n",
    "            nonexp_rate[ceiling_loc:] = ceiling\n",
    "        name = name + '_ceiling_' + str(ceiling)\n",
    "    return A_count_input, B_count_input, exp_rate, con_rate, nonexp_rate, B_indel_rate, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dd6b2-61ab-4a4a-b223-6d351b7de96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_processes(exp_int, con_int, exp_power, con_power, starting_counts, interp = False, pin_len = 9, nonexp_factor = 0.01, motif = 'A', ceiling = None, rates_function = 'powerlaw', show = False, norm = True, returndata = False, separate = False, A_bins = 200, B_bins = 200, cut_at_n1 = False):\n",
    "    starting_conditions = setup_evolve(exp_int, con_int, exp_power, con_power, starting_counts = starting_counts, pin_len = pin_len, interp = interp, nonexp_factor = nonexp_factor, ceiling = ceiling, rates_function = rates_function, input_nuc = motif, A_bins = A_bins, B_bins = B_bins)\n",
    "    A_components = mut_evolve_dist_AB(starting_conditions[0][:A_bins], starting_conditions[1][:B_bins], starting_conditions[2:6], output_components=True, input_nuc = motif, speedup_multiplier = 0)\n",
    "    A_components = pd.DataFrame(A_components)\n",
    "    A_components.columns = A_components.columns + 1\n",
    "    A_components.index = ['mut_in_local_A_B', 'mut_out_local_A_B', 'mut_in_local_B_A', 'mut_out_local_B_A', 'mut_in_fission', 'mut_out_fission', 'mut_in_fusion_A_B', 'mut_out_fusion_A_B', 'exp_in', 'exp_out', 'con_in', 'con_out', 'mut_in_fusion_Bdel', 'mut_out_fusion_Bdel', 'nonexp_in_fission', 'nonexp_fissions_out']\n",
    "    A_components_in = A_components.loc[A_components.index[::2]]\n",
    "    A_components_out = A_components.loc[A_components.index[1::2]]\n",
    "    A_components_in.index = ['substitution -1', 'substitution +1', 'substitution fission', 'substitution fusion', 'expansion +1', 'contraction -1', 'deletion fusion', 'non-motif insertion fission']\n",
    "    A_components_out.index = ['substitution -1', 'substitution +1', 'substitution fission', 'substitution fusion', 'expansion +1', 'contraction -1', 'deletion fusion', 'non-motif insertion fission']\n",
    "    A_components_sum = A_components_in + A_components_out\n",
    "    if norm == True:\n",
    "        abs_total = A_components_in.abs().sum() + A_components_out.abs().sum()\n",
    "        A_components_in = A_components_in / abs_total\n",
    "        A_components_out = A_components_out / abs_total\n",
    "        A_components_sum = A_components_sum / A_components_sum.abs().sum()\n",
    "    if returndata == 'sum':\n",
    "        return A_components_sum\n",
    "    if returndata == 'in':\n",
    "        return A_components_in\n",
    "    if returndata == 'out':\n",
    "        return A_components_out\n",
    "    else:\n",
    "        last_int_bin = (pd.Series(starting_conditions[0]) >= 1).idxmin()\n",
    "        fig_components = go.Figure()\n",
    "        if separate == True:\n",
    "            for component in A_components_sum.index:\n",
    "                fig_components.add_trace(go.Bar(name = component, x = A_components_in.columns, y = A_components_in.loc[component], legendgroup = component))\n",
    "            for component in A_components_sum.index:\n",
    "                fig_components.add_trace(go.Bar(name = component, x = A_components_out.columns, y = A_components_out.loc[component], legendgroup = component, showlegend = False))\n",
    "        else:\n",
    "            for component in A_components_sum.index:\n",
    "                fig_components.add_trace(go.Bar(name = component, x = A_components_sum.columns, y = A_components_sum.loc[component]))\n",
    "        fig_components.add_trace(go.Scatter(x = [last_int_bin] *2, y = [-0.505, 0.55], name = 'count <1', mode = 'lines', line = dict(color = 'rgba(0,0,0,0.5)', dash = 'dash', width = 3)))\n",
    "        fig_components.update_layout(barmode='relative', colorway = plotly.colors.qualitative.Plotly[:8], height = 250, margin={'t':20,'l':60,'b':40,'r':10})        \n",
    "        if cut_at_n1 == True:\n",
    "            if last_int_bin > 10:\n",
    "                fig_components.update_xaxes(range = [0.5, last_int_bin + 0.5], title = 'repeat length (nt)')\n",
    "                fig_components.update_yaxes(range = [-0.51, 0.51])\n",
    "        if cut_at_n1 == 'sup':\n",
    "            if last_int_bin > 10:\n",
    "                fig_components.update_xaxes(range = [0.5, last_int_bin + 0.5], title = 'repeat length (nt)')\n",
    "                fig_components.update_yaxes(range = [-0.51, 0.51])\n",
    "        else:\n",
    "            fig_components.update_xaxes(range = [0.5, A_bins + 0.5], title = 'repeat length (nt)')\n",
    "        fig_components.update_yaxes(title = 'relative contribution', gridcolor = 'rgba(0,0,0,0.5)')\n",
    "        if show == True:\n",
    "            fig_components.show()\n",
    "        return fig_components, last_int_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ad2a5-cad0-47ca-b900-be604b4c476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flux_combinations(comb_list, separate = False, show_plot = True, showlegend = True, showlabels = True, write = False, cut_at_n1 = False, norm = True, legend_size = False, A_bins = 200, xpos = None):\n",
    "    all_plots = dict()\n",
    "    if xpos is None:\n",
    "        xpos = pd.Series([0] * len(comb_list), index = [parameters for parameters in comb_list])\n",
    "    else:\n",
    "        xpos = pd.Series(xpos, index = [tuple(parameters) for parameters in comb_list])\n",
    "    for parameters in comb_list:\n",
    "        fig_flux, last_int_bin = plot_relative_processes(parameters[0],parameters[1],parameters[2],parameters[3], [inference_grid_final_nointerp_subonly[parameters[0]][parameters[1]][parameters[2]][parameters[3]], inference_grid_final_nointerp_subonly_Bdist[parameters[0]][parameters[1]][parameters[2]][parameters[3]]], norm=norm, separate=separate, cut_at_n1=cut_at_n1, A_bins=A_bins)\n",
    "        if cut_at_n1 == False:\n",
    "            fig_flux.update_xaxes(range = [0.5, 99])\n",
    "        fig_flux.update_xaxes(dtick = 10)\n",
    "        fig_flux.update_layout(font=dict(family = 'Arial', size = 12), title = str((parameters[2],parameters[3])), height = 210, width = 550, margin={'t':60,'l':60,'b':40,'r':10}, showlegend = showlegend)\n",
    "        if legend_size == True:\n",
    "            fig_flux.update_layout(font=dict(family = 'Arial', size = 12), title = str((parameters[2],parameters[3])), height = 500, width = 500, margin={'t':60,'l':60,'b':40,'r':10}, showlegend = showlegend)\n",
    "        if cut_at_n1 == True:\n",
    "            if last_int_bin > 10:\n",
    "                fig_flux.update_xaxes(range = [0.5, last_int_bin+0.5])\n",
    "\n",
    "                fig_flux.update_layout(width = 80 + 7*last_int_bin)\n",
    "            else:\n",
    "                fig_flux.update_xaxes(dtick = 50)\n",
    "        if showlabels == False:\n",
    "            fig_flux.update_xaxes(title = None, position = xpos[tuple(parameters)]); fig_flux.update_yaxes(title = None); fig_flux.update_layout(title = None, height = 140, margin={'t':10,'l':60,'b':20,'r':10})\n",
    "        if show_plot == True:\n",
    "            fig_flux.show()\n",
    "        if write != False:\n",
    "            if separate == False:\n",
    "                if cut_at_n1 == 'sup':\n",
    "                    fig_flux.write_image('plots/fig_sup_flux_'+str(parameters[0])+'_'+str(parameters[1])+'_'+str(parameters[2])+'_'+str(parameters[3])+'.'+ write)\n",
    "                else:\n",
    "                    fig_flux.write_image('plots/fig_flux_'+str(parameters[0])+'_'+str(parameters[1])+'_'+str(parameters[2])+'_'+str(parameters[3])+'.'+ write)\n",
    "            else:\n",
    "                if cut_at_n1 == 'sup':\n",
    "                    fig_flux.write_image('plots/fig_sup_flux_separated_'+str(parameters[0])+'_'+str(parameters[1])+'_'+str(parameters[2])+'_'+str(parameters[3])+'.'+ write)\n",
    "                else:\n",
    "                    fig_flux.write_image('plots/fig_flux_separated_'+str(parameters[0])+'_'+str(parameters[1])+'_'+str(parameters[2])+'_'+str(parameters[3])+'.'+ write)\n",
    "        all_plots[str(list(parameters))] = fig_flux\n",
    "    return all_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d917bb-03b9-45ee-8b3f-d791302e5359",
   "metadata": {},
   "source": [
    "#### Plots for Fig. 6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da436ef9-bc05-410a-8c7b-bb1826130fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_combination_examples = [[4,3,0,3.5], [4,3,0.5, 3], [4,3,1,2.5], [4,3,1.1,2.4], [4,3,1.2,2.3],  [4,3,1.3,2.2],  [4,3,1.4,2.1], [4,3, 1.5, 2], [4,3, 1.6, 1.9], [4,3, 2.8, 3.3], [4,3, 1.7, 1.8], [4,3, 1.7, 1.7], [4,3, 2.5, 1], [3,2,0,0]]\n",
    "flux_plots = plot_flux_combinations(parameter_combination_examples, showlegend = False, separate = False, cut_at_n1=True, A_bins=200, show_plot=False, showlabels = False, xpos = [0,0,0,0,0,0,0,0,0,0,0, 0.05, 0.05, 0], write = False)#'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565a553-643f-474d-829c-0ae306f5a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example\n",
    "flux_plots['[4, 3, 1.5, 2]'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582fa68-8186-4c0c-98bf-8de9a98858fb",
   "metadata": {},
   "source": [
    "#### additional plots for Supplemental Note 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665e334-2efb-4ac8-bec2-a5cf801b1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_plots_a = plot_flux_combinations(parameter_combination_examples, showlegend = False, separate = False, cut_at_n1='sup', A_bins=200, show_plot=False, showlabels = False, xpos = [0,0,0,0,0,0,0,0,0,0,0, 0.05, 0.05, 0], write = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac452bb-b7cc-4191-a706-fbba6e71bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_plots_b = plot_flux_combinations(parameter_combination_examples, showlegend = False, separate = True, cut_at_n1='sup', A_bins=200, show_plot=False, showlabels = False, xpos = [0,0,0,0,0,0,0,0,0,0,0, 0.05, 0.05, 0], write = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8404d9-115a-482a-8195-eaa12be2a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_net_flux_lineplot(comb_list, show_sum = False, show_plot = True, show_legend = True, showlabels = True, write = False, A_bins = 200, xpos = None):\n",
    "    all_plots = dict()\n",
    "    for parameters in comb_list:      \n",
    "        data = plot_relative_processes(parameters[0],parameters[1],parameters[2],parameters[3], [inference_grid_final_nointerp_subonly[parameters[0]][parameters[1]][parameters[2]][parameters[3]], inference_grid_final_nointerp_subonly_Bdist[parameters[0]][parameters[1]][parameters[2]][parameters[3]]], A_bins=200, norm = False, returndata = 'sum')\n",
    "        data_ins = plot_relative_processes(parameters[0],parameters[1],parameters[2],parameters[3], [inference_grid_final_nointerp_subonly[parameters[0]][parameters[1]][parameters[2]][parameters[3]], inference_grid_final_nointerp_subonly_Bdist[parameters[0]][parameters[1]][parameters[2]][parameters[3]]], A_bins=200, norm = False, returndata = 'in')\n",
    "        data_outs = plot_relative_processes(parameters[0],parameters[1],parameters[2],parameters[3], [inference_grid_final_nointerp_subonly[parameters[0]][parameters[1]][parameters[2]][parameters[3]], inference_grid_final_nointerp_subonly_Bdist[parameters[0]][parameters[1]][parameters[2]][parameters[3]]], A_bins=200, norm = False, returndata = 'out')\n",
    "        Lmax = (inference_grid_final_nointerp_subonly[parameters[0]][parameters[1]][parameters[2]][parameters[3]] >= 1).idxmin()\n",
    "        if Lmax < 10:\n",
    "            Lmax = 200\n",
    "        components_fission_in = data_ins.loc['substitution fission'] + data_ins.loc['non-motif insertion fission']\n",
    "        components_fission_out = data_outs.loc['substitution fission'] + data_outs.loc['non-motif insertion fission']\n",
    "        local_terms = data_ins.loc['expansion +1'] + data_ins.loc['contraction -1'] + (data_outs.loc['expansion +1'] + data_outs.loc['contraction -1'])\n",
    "        local_terms_wsub = data_ins.loc['expansion +1'] + data_ins.loc['contraction -1'] + data_ins.loc['substitution +1'] + data_ins.loc['substitution -1'] + (data_outs.loc['expansion +1'] + data_outs.loc['contraction -1'] + data_outs.loc['substitution +1'] + data_outs.loc['substitution -1'])\n",
    "        local_subonly = data_ins.loc['substitution +1'] + data_ins.loc['substitution -1'] + (data_outs.loc['substitution +1'] + data_outs.loc['substitution -1'])\n",
    "        all_subonly = data_ins.loc['substitution +1'] + data_ins.loc['substitution -1'] + data_ins.loc['substitution fission'] + data_ins.loc['substitution fusion'] + (data_outs.loc['substitution +1'] + data_outs.loc['substitution -1'] + data_outs.loc['substitution fission'] + data_outs.loc['substitution fusion'])\n",
    "        local_plus_fission_out = local_terms + components_fission_out\n",
    "        local_plus_fission_all = local_terms + components_fission_in + components_fission_out\n",
    "        all_terms = (data_ins + data_outs).sum()\n",
    "       \n",
    "        fig_components = go.Figure()\n",
    "        fig_components.add_trace(go.Scatter(x = all_terms.index[:Lmax], y = all_terms[:Lmax], mode = 'lines', line = dict(color = 'rgba(1,1,1,0.8)', width = 3), name = 'computational model: all terms'))\n",
    "        fig_components.add_trace(go.Scatter(x = local_terms.index[:Lmax], y = local_terms[:Lmax], mode = 'lines', line = dict(color = 'rgba(255,178,101,0.8)', width = 3), name = 'local terms (no fission, no fusion)'))\n",
    "        fig_components.add_trace(go.Scatter(x = local_plus_fission_out.index[:Lmax], y = local_plus_fission_out[:Lmax], mode = 'lines', line = dict(color = 'rgba(255,101,101,0.8)', width = 3), name = 'no fission in, no fusion'))\n",
    "        fig_components.add_trace(go.Scatter(x = local_plus_fission_all.index[:Lmax], y = local_plus_fission_all[:Lmax], mode = 'lines', line = dict(color = 'rgba(178,101,178,0.8)', width = 3), name = 'no fusion'))\n",
    "        fig_components.update_xaxes(title = 'repeat length (nt)')\n",
    "        yrange = max(0.05, all_terms[5:15].abs().max())\n",
    "        fig_components.update_yaxes(title = 'net flux (mut. per gen.)', range = [-yrange, yrange])\n",
    "        fig_components.update_layout(font=dict(family = 'Arial', size = 12), title = str((float(round(m_list[parameters[1]],1)),parameters[2],parameters[3])), height = 210, width = 550, margin={'t':60,'l':60,'b':40,'r':10}, showlegend = show_legend)\n",
    "        if show_plot == True:\n",
    "            fig_components.show()\n",
    "        if show_sum == True:\n",
    "            print(all_terms.sum())\n",
    "        if write != False:\n",
    "            fig_components.write_image('plots/fig_netfluxlines_finaltimepoint_'+str(round(m_list[parameters[1]],1))+'_'+str(parameters[2])+'_'+str(parameters[3])+'.'+ write)\n",
    "        all_plots[str(list(parameters))] = fig_components\n",
    "    return all_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b36639-de46-472c-a8ab-5969714edbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_plots_c = plot_net_flux_lineplot(parameter_combination_examples, show_plot=False, show_legend=False, write = 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe49291-7a37-4188-bb41-736863e1972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples\n",
    "flux_plots_a['[4, 3, 1.5, 2]'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690bcaa-4020-407b-94fe-a04d6abe1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_plots_b['[4, 3, 1.5, 2]'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860234b-4ce6-4e0c-bfd4-49732ca7a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_plots_c['[4, 3, 1.5, 2]'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc54f6-f468-4b4b-94a3-edfca26a3af2",
   "metadata": {},
   "source": [
    "## Substitution-only simulations\n",
    "- data processed in Notebook 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcf282-aff1-4753-8bc3-1388a9490c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "subonly_counts_unit = subonly_counts['A'].T.reset_index().dropna(how='all', axis=1)\n",
    "subonly_counts_unit['unit'] = subonly_counts_unit['index'].str.len()\n",
    "subonly_counts_unit = subonly_counts_unit.set_index(['unit', 'index']).groupby(['unit']).sum().transpose()\n",
    "CHM13_counts_byunit = CHM13_counts.T.groupby(['unit_len']).sum().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540d782-be00-4887-8fb2-f2d57f117a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S15b\n",
    "fig_mutonly = go.Figure()\n",
    "for unit in [1,2,3]:\n",
    "    fig_mutonly.add_trace(go.Scatter(x = CHM13_counts_byunit.index * unit, y = CHM13_counts_byunit[unit] / CHM13_counts_byunit[unit].sum(), opacity = 0.6, mode = 'lines', line = dict(width = 3), legendgroup = unit, name = 'unit='+str(unit)))\n",
    "for unit in [1,2,3]:\n",
    "    fig_mutonly.add_trace(go.Scatter(x = subonly_counts_unit.index * unit, y = subonly_counts_unit[unit] / subonly_counts_unit[unit].sum(), opacity = 0.5, mode = 'lines', line = dict(dash = 'dash', width = 3), legendgroup = unit, name = 'substitutions only'))\n",
    "\n",
    "fig_mutonly.update_yaxes(type = 'log', title = 'repeat counts (normalized)', range = [-9.05,0], tickformat = '1.0e', dtick = 2, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_mutonly.update_xaxes(type = 'log', title = 'repeat tract length (nt)', range = [0,2.2], tickvals = [1,2,5,10,20,50,100], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_mutonly.update_layout(font=dict(family = 'Arial', size = 14), height = 400, width = 520, margin={'t':20,'l':65,'b':45,'r':20}, colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:3], legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b5851-f89e-4b7b-aa09-cad2cab8d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mutonly.write_image('plots/figS15b.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b597db-640c-437b-aa7e-4b7c6a47a25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
