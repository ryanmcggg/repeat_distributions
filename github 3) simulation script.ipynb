{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d37459-9d47-4f21-8c70-601428918d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2346055-eac0-4a45-8217-24e5b2bee871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "CHM13_counts = pd.read_pickle('repeat_distributions/CHM13_counts.pickle')\n",
    "random_counts = pd.read_pickle('repeat_distributions/random_counts.pickle')\n",
    "subonly_counts = pd.read_pickle('repeat_distributions/subonly_counts.pickle')\n",
    "\n",
    "denovo_exp_rate = pd.read_pickle('denovo/denovo_exp_rate.pickle')\n",
    "denovo_con_rate = pd.read_pickle('denovo/denovo_con_rate.pickle')\n",
    "denovo_nonexp_rate = pd.read_pickle('denovo/denovo_nonexp_rate.pickle')\n",
    "\n",
    "denovo_exp_rate_poisson = pd.read_pickle('denovo/denovo_exp_rate_poisson.pickle')\n",
    "denovo_con_rate_poisson = pd.read_pickle('denovo/denovo_con_rate_poisson.pickle')\n",
    "denovo_nonexp_rate_poisson = pd.read_pickle('denovo/denovo_nonexp_rate_poisson.pickle')\n",
    "\n",
    "decode_exp_rate_poisson = pd.read_pickle('decode/decode_expansion_rates_poisson.pickle')\n",
    "decode_con_rate_poisson = pd.read_pickle('decode/decode_contraction_rates_poisson.pickle')\n",
    "\n",
    "denovo_substitution_context_rate = pd.read_pickle('denovo/denovo_mut_freq_triplets.pickle')\n",
    "denovo_substitution_context_rate_poisson = pd.read_pickle('denovo/denovo_mut_freq_triplets_poisson.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76f99b-3c02-4754-809d-330c02b7aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolve function\n",
    "def mut_evolve_dist_AB(A_count_input, B_count_input, starting_conditions, boot = None, input_nuc = 'A', mut = True, mutonly = False, speedup_multiplier = 1, output_components = False, stochastics = None, reflective = True):\n",
    "    exp_rate_A_AA, con_rate_A_AA, nonexp_rate_A_AB, B_indel_rates = starting_conditions\n",
    "    A_count_output = A_count_input.copy(); B_count_output = B_count_input.copy()\n",
    "    A_bins = len(A_count_input)\n",
    "    B_bins = len(B_count_input)\n",
    "    A_length_array = np.array(range(1,A_bins+3))\n",
    "    A_length_array_bases = np.array(range(1,A_bins+3)) * len(input_nuc) ### including motif length\n",
    "    B_length_array = np.array(range(1,B_bins+3))\n",
    "    B_length_array_bases = np.array(range(1,B_bins+3)) * len(input_nuc) ### including motif length\n",
    "    A_count_input = np.insert(A_count_input, A_bins, [0,0])\n",
    "    B_count_input = np.insert(B_count_input, B_bins, [0,0])\n",
    "    #A_count_input = A_count_input.astype('int64')\n",
    "    #B_count_input = B_count_input.astype('int64')\n",
    "\n",
    "    if boot is None:\n",
    "        denovo_sub = denovo_substitution_context_rate.loc[input_nuc]\n",
    "    else:\n",
    "        denovo_sub = denovo_substitution_context_rate_poisson.loc[boot].loc[input_nuc]\n",
    "\n",
    "    # distribution info\n",
    "    total_B_bases = (B_count_input[:B_bins] * B_length_array_bases[:B_bins]).sum()\n",
    "    B_L1_base_portion = ((B_count_input[0] * len(input_nuc)) / (B_count_input[:B_bins]* B_length_array_bases[:B_bins]).sum()) ### including motif length\n",
    "    B_nonflank_base_portion = (B_count_input[2:B_bins+2] * B_length_array_bases[:B_bins]).sum() / total_B_bases  ### include portion of triplets 1nt away???\n",
    "    B_flank_base_portion = (B_count_input[1:B_bins] * 2 * len(input_nuc)).sum() / total_B_bases ### including motif length\n",
    "    \n",
    "    total_A_bases = (A_count_input[:A_bins] * A_length_array_bases[:A_bins]).sum()\n",
    "    A_nonflank_base_portion = (A_count_input[2:A_bins+2] * A_length_array_bases[:A_bins]).sum() / total_A_bases\n",
    "    A_flank_base_portion = (A_count_input[1:A_bins] * 2 * len(input_nuc)).sum() / total_A_bases ### including motif length\n",
    "    \n",
    "    total_A_change_in = np.array([0.0]*A_bins); total_B_change_in = np.array([0.0]*B_bins)\n",
    "    total_A_change_out = np.array([0.0]*A_bins); total_B_change_out = np.array([0.0]*B_bins)\n",
    "\n",
    "    if mut == True:\n",
    "        # A>B which adds to the A count locally. add these to A\n",
    "        A_mut_in_local_A_B = 2 * len(input_nuc) * denovo_sub['Acontraction'] * A_count_input[1:]\n",
    "        A_mut_out_local_A_B = -2 * len(input_nuc) * denovo_sub['Acontraction'] * A_count_input\n",
    "        A_mut_out_local_A_B[0] = -1 * len(input_nuc) * A_count_input[0] * denovo_sub['A10']\n",
    "        #A_mut_in_local_A_B = A_mut_out_local_A_B[1:]\n",
    "\n",
    "        # total number of A>B fission events\n",
    "        A_mut_out_fission = np.insert((-denovo_sub['Afission'] * A_count_input[2:] * A_length_array_bases[:A_bins]), 0, [0, 0]) # used to subtract from A_count, starting from L=3 (with 0 for L=1,2)\n",
    "        # each fission creates 2 As. add these to A\n",
    "        A_mut_in_fission =  np.array([np.sum(((2/A_length_array[:A_bins]) * -A_mut_out_fission[2:A_bins+2])[L-1:]) for L in A_length_array[:A_bins]]) ### use length_array_bases???\n",
    " \n",
    "        # B>A which adds to the A count locally (which must come from B_L>1)\n",
    "        # A from B>A leaving the -1 bin\n",
    "        A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "        A_mut_out_local_B_A = -denovo_sub['Aexpansion'] * B_flank_base_portion * total_B_bases * A_len_freq\n",
    "        # B>A creating A_L=1 from B_L>2\n",
    "        B_A_into_L1 = total_B_bases * B_nonflank_base_portion * denovo_sub['A01']\n",
    "        A_mut_in_local_B_A = np.insert(-A_mut_out_local_B_A, 0, B_A_into_L1)\n",
    "        \n",
    "        # fusion process for A\n",
    "        A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "        A_fusion_freq_in = np.bincount((np.add.outer(A_length_array[:A_bins], A_length_array[:A_bins])+1).ravel(), weights = np.outer(A_len_freq, A_len_freq).ravel())[1:]\n",
    "        A_mut_in_fusion_A_B = A_fusion_freq_in * denovo_sub['Afusion'] * B_L1_base_portion * total_B_bases\n",
    "        A_mut_out_fusion_A_B = (-2) *A_len_freq * denovo_sub['Afusion'] * B_L1_base_portion * total_B_bases\n",
    "        \n",
    "        \n",
    "        # total B>A\n",
    "        # B>A which adds to the B count locally. add these to B\n",
    "        B_mut_in_local_B_A = 2 * len(input_nuc) * denovo_sub['Aexpansion'] * B_count_input[1:]\n",
    "        B_mut_out_local_B_A = -2 * len(input_nuc) * denovo_sub['Aexpansion'] * B_count_input\n",
    "        B_mut_out_local_B_A[0] = -1 * B_L1_base_portion * total_B_bases * denovo_sub['Afusion']\n",
    "\n",
    "        # total number of B>A fission events\n",
    "        B_mut_out_fission = np.insert((-denovo_sub['A01'] * B_count_input[2:] * B_length_array_bases[:B_bins]), 0, [0, 0]) # used to subtract from B_count, starting from L=3 (with 0 for L=1,2)\n",
    "        # each fission creates 2 Bs. add these to B\n",
    "        B_mut_in_fission =  np.array([np.sum(((2/B_length_array[:B_bins]) * -B_mut_out_fission[2:B_bins+2])[L-1:]) for L in B_length_array[:B_bins]]) ### use length_array_bases???\n",
    "\n",
    "        # A>B which adds to the B count locally (which must come from A_L>1)\n",
    "        # B from A>B leaving the -1 bin\n",
    "        B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "        B_mut_out_local_A_B = -denovo_sub['Acontraction'] * A_flank_base_portion * total_A_bases * B_len_freq\n",
    "        # A>B creating B_L=1 from A_L>2\n",
    "        A_B_into_L1 = total_A_bases * A_nonflank_base_portion * denovo_sub['Afission']\n",
    "#        A_B_into_L1 = -A_mut_out_fission.sum()\n",
    "        B_mut_in_local_A_B = np.insert(-B_mut_out_local_A_B, 0, A_B_into_L1)\n",
    "        \n",
    "        # fusion process for B\n",
    "        B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "        B_fusion_freq_in = np.bincount((np.add.outer(B_length_array[:B_bins], B_length_array[:B_bins])+1).ravel(), weights = np.outer(B_len_freq, B_len_freq).ravel())[1:]\n",
    "        B_mut_in_fusion_B_A = B_fusion_freq_in * denovo_sub['A10'] * A_count_input[0] * len(input_nuc)\n",
    "        B_mut_out_fusion_B_A = (-2) * B_len_freq * denovo_sub['A10'] * A_count_input[0] * len(input_nuc)\n",
    "\n",
    "        # update counts for next round (with absorbing boundary)\n",
    "        total_A_change_in += A_mut_in_local_A_B[:A_bins] + A_mut_in_local_B_A[:A_bins] + A_mut_in_fission[:A_bins] + A_mut_in_fusion_A_B[:A_bins]\n",
    "        total_B_change_in += B_mut_in_local_B_A[:B_bins] + B_mut_in_local_A_B[:B_bins] + B_mut_in_fission[:B_bins] + B_mut_in_fusion_B_A[:B_bins]\n",
    "        total_A_change_out += A_mut_out_local_A_B[:A_bins] + A_mut_out_local_B_A[:A_bins] + A_mut_out_fission[:A_bins] + A_mut_out_fusion_A_B[:A_bins]\n",
    "        total_B_change_out += B_mut_out_local_B_A[:B_bins] + B_mut_out_local_A_B[:B_bins] + B_mut_out_fission[:B_bins] + B_mut_out_fusion_B_A[:B_bins]\n",
    "\n",
    "        # apply reflecting boundary\n",
    "        if reflective == True:\n",
    "            total_A_change_in[A_bins-1] += A_mut_in_local_A_B[A_bins:].sum() + A_mut_in_local_B_A[A_bins:].sum() + A_mut_in_fission[A_bins:].sum() + A_mut_in_fusion_A_B[A_bins:].sum()\n",
    "            total_B_change_in[B_bins-1] += B_mut_in_local_B_A[B_bins:].sum() + B_mut_in_local_A_B[B_bins:].sum() + B_mut_in_fission[B_bins:].sum() + B_mut_in_fusion_B_A[B_bins:].sum()\n",
    "            total_A_change_out[A_bins-1] += A_mut_out_local_A_B[A_bins:].sum() + A_mut_out_local_B_A[A_bins:].sum() + A_mut_out_fission[A_bins:].sum() + A_mut_out_fusion_A_B[A_bins:].sum()\n",
    "            total_B_change_out[B_bins-1] += B_mut_out_local_B_A[B_bins:].sum() + B_mut_out_local_A_B[B_bins:].sum() + B_mut_out_fission[B_bins:].sum() + B_mut_out_fusion_B_A[B_bins:].sum()\n",
    "           \n",
    "            \n",
    "    if mutonly == False:\n",
    "        # A expansions in and out\n",
    "        A_exp_out = A_count_input[:A_bins] * -exp_rate_A_AA[:A_bins]\n",
    "        A_exp_in = np.insert(-A_exp_out, 0, B_indel_rates[0]*total_B_bases)\n",
    "\n",
    "        # A contractions in and out\n",
    "        A_con_out = A_count_input[:A_bins+1] * -con_rate_A_AA[:A_bins+2]\n",
    "        A_con_in = -A_con_out[1:]\n",
    "\n",
    "        # A fusions from B1>B0 deletions\n",
    "        if (mut != True):\n",
    "            A_len_freq = (A_count_input / A_count_input.sum())[:A_bins]\n",
    "            A_fusion_freq_in = np.bincount((np.add.outer(A_length_array[:A_bins], A_length_array[:A_bins])+1).ravel(), weights = np.outer(A_len_freq, A_len_freq).ravel())[1:]\n",
    "        A_mut_in_fusion_Bdel = A_fusion_freq_in[1:A_bins+1] * B_indel_rates[1] * B_L1_base_portion * total_B_bases\n",
    "        A_mut_out_fusion_Bdel = (-2) *A_len_freq * B_indel_rates[1] * B_L1_base_portion * total_B_bases\n",
    "\n",
    "        # A fission events from insertions\n",
    "        A_nonexp_fissions_out = -A_count_input * nonexp_rate_A_AB # used to calculate fission_in, starting with L=2 going to 2x L=1\n",
    "        # each fission creates 2 As. add these to A\n",
    "        A_nonexp_in_fission =  np.array([np.sum(((2/A_length_array[:A_bins]) * -A_nonexp_fissions_out[1:A_bins+1])[L-1:]) for L in A_length_array[:A_bins]])\n",
    "\n",
    "\n",
    "        # B expansions in and out\n",
    "        B_exp_out = B_count_input[:B_bins] * -B_indel_rates[2] * B_length_array[:B_bins] # B>BB rates are flat, per base\n",
    "        B_exp_in = np.insert(-B_exp_out, 0, A_nonexp_fissions_out.sum())\n",
    "\n",
    "        # B contractions in and out\n",
    "        B_con_out = B_count_input[:B_bins+1] * -B_indel_rates[1] * B_length_array[:B_bins+1] # B>_ rates are flat, per base\n",
    "        B_con_in = -B_con_out[1:]\n",
    "\n",
    "        # B fusions from A1>A0 deletions\n",
    "        if (mut != True):\n",
    "            B_len_freq = (B_count_input / B_count_input.sum())[:B_bins]\n",
    "            B_fusion_freq_in = np.bincount((np.add.outer(B_length_array[:B_bins], B_length_array[:B_bins])+1).ravel(), weights = np.outer(B_len_freq, B_len_freq).ravel())[1:]\n",
    "        B_mut_in_fusion_Adel = B_fusion_freq_in[1:B_bins+1] * A_count_input[0] * con_rate_A_AA[0]\n",
    "        B_mut_out_fusion_Adel = 2 *B_len_freq * A_count_input[0] * -con_rate_A_AA[0]\n",
    "                    \n",
    "        # B fission events from insertions\n",
    "        B_nonexp_fissions_out = -B_count_input * B_indel_rates[0] * B_length_array # used to calculate fission_in, starting with L=2 going to 2x L=1\n",
    "        # each fission creates 2 Bs. add these to B\n",
    "        B_nonexp_in_fission =  np.array([np.sum(((2/B_length_array[:B_bins]) * -B_nonexp_fissions_out[1:B_bins+1])[L-1:]) for L in B_length_array[:B_bins]])\n",
    "            \n",
    "       # update counts for next round (with absorbing boundary)\n",
    "        total_A_change_in += A_exp_in[:A_bins] + A_con_in[:A_bins] + A_mut_in_fusion_Bdel[:A_bins] + A_nonexp_in_fission[:A_bins]\n",
    "        total_B_change_in += B_exp_in[:B_bins] + B_con_in[:B_bins] + B_mut_in_fusion_Adel[:B_bins] + B_nonexp_in_fission[:B_bins]\n",
    "        total_A_change_out += A_exp_out[:A_bins] + A_con_out[:A_bins] + A_mut_out_fusion_Bdel[:A_bins] + A_nonexp_fissions_out[:A_bins]\n",
    "        total_B_change_out += B_exp_out[:B_bins] + B_con_out[:B_bins] + B_mut_out_fusion_Adel[:B_bins] + B_nonexp_fissions_out[:B_bins]\n",
    "\n",
    "        # apply reflecting boundary\n",
    "        if reflective == True:\n",
    "            total_A_change_in[A_bins-1] += A_exp_in[A_bins:].sum() + A_con_in[A_bins:].sum() + A_mut_in_fusion_Bdel[A_bins:].sum() + A_nonexp_in_fission[A_bins:].sum()\n",
    "            total_B_change_in[B_bins-1] += B_exp_in[B_bins:].sum() + B_con_in[B_bins:].sum() + B_mut_in_fusion_Adel[B_bins:].sum() + B_nonexp_in_fission[B_bins:].sum()\n",
    "            total_A_change_out[A_bins-1] += A_exp_out[A_bins:].sum() + A_con_out[A_bins:].sum() + A_mut_out_fusion_Bdel[A_bins:].sum() + A_nonexp_fissions_out[A_bins:].sum()\n",
    "            total_B_change_out[B_bins-1] += B_exp_out[B_bins:].sum() + B_con_out[B_bins:].sum() + B_mut_out_fusion_Adel[B_bins:].sum() + B_nonexp_fissions_out[B_bins:].sum()\n",
    "\n",
    "    \n",
    "    # flag to stop the simulation if more repeats are removed from a bin than exist in that bin (excluding the last 10 noisy bins)\n",
    "    flag = ((np.abs(total_A_change_out[:A_bins-10]) * speedup_multiplier > A_count_output[:A_bins-10]).sum()) > 0\n",
    "\n",
    "    # apply speedup\n",
    "    total_A_change_in *= speedup_multiplier; total_A_change_out *= speedup_multiplier\n",
    "    total_B_change_in *= speedup_multiplier; total_B_change_out *= speedup_multiplier\n",
    "    \n",
    "    if stochastics is not None:\n",
    "        # the sum of poisson random variables is poisson-distributed. not necessary to run n poisson samples\n",
    "        total_A_change_in = np.random.poisson(total_A_change_in.clip(0))\n",
    "        total_A_change_out = -1 * np.random.poisson(np.abs(total_A_change_out.clip(max=0)))\n",
    "        total_B_change_in = np.random.poisson(total_B_change_in.clip(0))\n",
    "        total_B_change_out = -1 * np.random.poisson(np.abs(total_B_change_out.clip(max=0)))   \n",
    "    \n",
    "    total_A_change = total_A_change_in + total_A_change_out\n",
    "    total_B_change = total_B_change_in + total_B_change_out\n",
    "    \n",
    "    # update counts for next round\n",
    "    A_count_output = A_count_output[:A_bins] + total_A_change[:A_bins]\n",
    "    B_count_output = B_count_output[:B_bins] + total_B_change[:B_bins]\n",
    "\n",
    "    # remove negative values\n",
    "    A_count_output[A_count_output <0] = 0            \n",
    "    B_count_output[B_count_output <0] = 0\n",
    "\n",
    "    boundary_flag = ((A_count_output[A_bins-1] > 1000) | (B_count_output[B_bins-1] > 1000))\n",
    "    \n",
    "    if output_components == True:\n",
    "        if mutonly == False:\n",
    "            return  A_mut_in_local_A_B[:A_bins], A_mut_out_local_A_B[:A_bins], A_mut_in_local_B_A[:A_bins], A_mut_out_local_B_A[:A_bins], A_mut_in_fission[:A_bins], A_mut_out_fission[:A_bins], A_mut_in_fusion_A_B[:A_bins], A_mut_out_fusion_A_B[:A_bins], A_exp_in[:A_bins], A_exp_out[:A_bins], A_con_in[:A_bins], A_con_out[:A_bins], A_mut_in_fusion_Bdel[:A_bins], A_mut_out_fusion_Bdel[:A_bins], A_nonexp_in_fission[:A_bins], A_nonexp_fissions_out[:A_bins]\n",
    "        else:\n",
    "            return  A_mut_in_local_A_B[:A_bins], A_mut_out_local_A_B[:A_bins], A_mut_in_local_B_A[:A_bins], A_mut_out_local_B_A[:A_bins], A_mut_in_fission[:A_bins], A_mut_out_fission[:A_bins], A_mut_in_fusion_A_B[:A_bins], A_mut_out_fusion_A_B[:A_bins]\n",
    "    else:\n",
    "        return A_count_output, B_count_output, flag, boundary_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eafdb4-7737-4630-b89b-9d2d3281f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_power_law(power, start_rate, start_len, end_len=100):\n",
    "    denom = (start_len**power) / start_rate\n",
    "    return pd.Series([i**power for i in range(start_len+1, end_len+1)], index = list(range(start_len+1,end_len+1))) / denom\n",
    "\n",
    "def multiply_then_powerlaw(exp_power, con_power, mult, A_bins = 100, boot = None, L_mult = 9, L_mult_nonexp = 9, motif = 'A', fill = False, nonexp_factor = False):\n",
    "    if boot is None:\n",
    "        bootname = ''\n",
    "        denovo_exp_rate_current = denovo_exp_rate[motif]\n",
    "        denovo_con_rate_current = denovo_con_rate[motif]\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate[motif]\n",
    "    else:\n",
    "        bootname = '_boot'+str(boot)\n",
    "        denovo_exp_rate_current = denovo_exp_rate_poisson[motif][boot]\n",
    "        denovo_con_rate_current = denovo_con_rate_poisson[motif][boot]\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate_poisson[motif][boot]\n",
    "    if fill == True:\n",
    "        fillname = '_fill'\n",
    "        denovo_exp_rate_current = denovo_exp_rate_current.replace(0, np.nan).interpolate(method = 'from_derivatives')\n",
    "        denovo_con_rate_current = denovo_con_rate_current.replace(0, np.nan).interpolate(method = 'from_derivatives')\n",
    "        denovo_nonexp_rate_current = denovo_nonexp_rate_current.replace(0, np.nan).interpolate(method = 'from_derivatives')\n",
    "    else:\n",
    "        fillname = ''\n",
    "    exp = pd.concat([denovo_exp_rate_current.reindex(range(L_mult)), pd.Series(denovo_exp_rate_current[L_mult-1] * mult, index = [L_mult]), extend_power_law(exp_power, denovo_exp_rate_current[L_mult-1]*mult, L_mult, A_bins+3)])\n",
    "    con = pd.concat([denovo_con_rate_current.reindex(range(L_mult)), pd.Series(denovo_con_rate_current[L_mult-1] * mult, index = [L_mult]), extend_power_law(con_power, denovo_con_rate_current[L_mult-1]*mult, L_mult, A_bins+3)])\n",
    "    if nonexp_factor == False:\n",
    "        nonexpname = ''\n",
    "        nonexp = pd.concat([denovo_nonexp_rate_current.reindex(range(L_mult_nonexp)), pd.Series(denovo_nonexp_rate_current[L_mult_nonexp-1] * mult, index = [L_mult_nonexp]), extend_power_law(exp_power, denovo_nonexp_rate_current[L_mult_nonexp-1]*mult, L_mult_nonexp, A_bins+3)])\n",
    "    else:\n",
    "        nonexpname = '_nonexp_x' + str(nonexp_factor)\n",
    "        nonexp = exp * nonexp_factor\n",
    "    nonexp.loc[1] = 0\n",
    "    name = 'mult_L'+str(L_mult)+'_x'+str(mult)+'_extend_pl_' + str(exp_power) + '_' + str(con_power) + nonexpname + fillname + bootname\n",
    "    return name, exp, con, nonexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbef5e6-bf2d-45a5-81f4-62ea25a1d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup function\n",
    "def setup_evolve(exp_power=1, con_power=1, mult=1, boot = None, stochastics = None, L_mult = 9, L_mult_nonexp = 9, fill = False, nonexp_factor = False, A_bins = 100, B_bins = 100, input_nuc = 'A', mutonly = False, exp_zero = False, con_zero = False, nonexp_zero = False, different_input = False, random_start = False, subonly_start = False, ceiling = None, custom_rates = False):\n",
    "# set up counts\n",
    "    A_length_array = np.array(range(1,A_bins+1))\n",
    "    B_length_array = np.array(range(1,A_bins+1))\n",
    "    if different_input == False:\n",
    "        if random_start == False:\n",
    "            if subonly_start == False:\n",
    "                A_count_input = np.nan_to_num(CHM13_counts['A'][input_nuc].reindex(range(1,A_bins+1)).values)\n",
    "                B_count_input = np.nan_to_num(CHM13_counts['B'][input_nuc].reindex(range(1,B_bins+1)).values)\n",
    "            if subonly_start == True:\n",
    "                A_count_input = np.nan_to_num(subonly_counts['A'][input_nuc].reindex(range(1,A_bins+1)).values)\n",
    "                B_count_input = np.nan_to_num(subonly_counts['B'][input_nuc].reindex(range(1,B_bins+1)).values)\n",
    "        if random_start == True:\n",
    "            A_count_input = np.nan_to_num(random_counts['A'][input_nuc].reindex(range(1,A_bins+1)).values)\n",
    "            B_count_input = np.nan_to_num(random_counts['B'][input_nuc].reindex(range(1,B_bins+1)).values)\n",
    "    else:\n",
    "        A_count_input = np.nan_to_num(different_input[0].reindex(range(1,A_bins+1)).values)\n",
    "        B_count_input = np.nan_to_num(different_input[1].reindex(range(1,B_bins+1)).values)\n",
    "# set up rates    \n",
    "    if mutonly == False:\n",
    "        if custom_rates == False:\n",
    "            name, exp_rate, con_rate, nonexp_rate = multiply_then_powerlaw(exp_power = exp_power, con_power = con_power, A_bins = A_bins, mult=mult, boot = boot, L_mult = 9, L_mult_nonexp = 9, motif = input_nuc, fill = fill, nonexp_factor = nonexp_factor)\n",
    "            B_indel_rate = np.array([exp_rate[0], con_rate[0], nonexp_rate[0]])        \n",
    "        else:\n",
    "            exp_rate, con_rate, name = custom_rates\n",
    "            nonexp_rate = exp_rate * nonexp_factor\n",
    "            B_indel_rate = np.array([denovo_exp_rate[input_nuc][0], denovo_con_rate[input_nuc][0], denovo_nonexp_rate[input_nuc][0]])        \n",
    "        # change rates from per unit to per STR\n",
    "        exp_rate = exp_rate.values[1:A_bins+1] * A_length_array\n",
    "        con_rate = con_rate.values[1:A_bins+2] * np.array(range(1,A_bins+2))\n",
    "        nonexp_rate = nonexp_rate.values[1:A_bins+3] * np.array(range(1,A_bins+3))\n",
    "        if ceiling != None:\n",
    "            ceiling_loc = []\n",
    "            if (exp_rate > ceiling).sum() > 0:\n",
    "                ceiling_loc.append(pd.Series(exp_rate > ceiling).idxmax())\n",
    "            if (con_rate > ceiling).sum() > 0:\n",
    "                ceiling_loc.append(pd.Series(con_rate > ceiling).idxmax())\n",
    "            if len(ceiling_loc) > 0:\n",
    "                ceiling_loc = min(np.array(ceiling_loc))\n",
    "                print( '\\r' + 'rate ceiling reached at L=' + str(ceiling_loc), end = ' ')\n",
    "                exp_rate[ceiling_loc:] = ceiling\n",
    "                con_rate[ceiling_loc:] = ceiling\n",
    "                nonexp_rate[ceiling_loc:] = ceiling\n",
    "            name = name + '_ceiling_' + str(ceiling)\n",
    "        if exp_zero == True:\n",
    "            exp_rate *= 0\n",
    "        if con_zero == True:\n",
    "            con_rate *= 0\n",
    "        if nonexp_zero == True:\n",
    "            nonexp_rate *= 0\n",
    "        if random_start == False:\n",
    "            if subonly_start == True:\n",
    "                name = name + '_subonlystart'\n",
    "            else:\n",
    "                name = name + '_CHM13start'\n",
    "        else:\n",
    "            if random_start == True:\n",
    "                name = name + '_randomstart'        \n",
    "        if stochastics is None:\n",
    "            name = name\n",
    "        else:\n",
    "            name = name + '_stochastics_' + str(stochastics)\n",
    "        return A_count_input, B_count_input, exp_rate, con_rate, nonexp_rate, B_indel_rate, name\n",
    "    else:\n",
    "        if boot is None:\n",
    "            name = 'mutonly'\n",
    "        else:\n",
    "            name = 'mutonly_boot' + str(boot)\n",
    "        if random_start == False:\n",
    "            if subonly_start == True:\n",
    "                name = name + '_subonlystart'\n",
    "            else:\n",
    "                name = name + '_CHM13start'\n",
    "        else:\n",
    "            if random_start == True:\n",
    "                name = name + '_randomstart'  \n",
    "        if stochastics is None:\n",
    "            name = name\n",
    "        else:\n",
    "            name = name + '_stochastics_' + str(stochastics)\n",
    "        return A_count_input, B_count_input, None, None, None, None, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05bb94-e2aa-4d51-b6b5-f2ed0af24f8a",
   "metadata": {},
   "source": [
    "## Constant speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc3dd6-c705-4d90-9e76-2e1a320a3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(exp_power=1, con_power=1, mult=1, boot = None, L_mult = 9, L_mult_nonexp = 9, fill = False, nonexp_factor = False, A_bins = 100, B_bins = 100, input_nuc = 'A', mutonly = False, speedup = 3, rounds = 5, overwrite = False, stochastics = None, random_start = False, subonly_start = False, ceiling = False, reflective = True, sim_dir = 'grid_output/'):\n",
    "    starting_conditions = setup_evolve(exp_power=exp_power, con_power=con_power, mult=mult, boot = boot, stochastics = stochastics, L_mult = L_mult, L_mult_nonexp = L_mult_nonexp, fill = fill, nonexp_factor = nonexp_factor, A_bins = A_bins, B_bins = B_bins, input_nuc = input_nuc, mutonly = mutonly, random_start = random_start, subonly_start = subonly_start, ceiling = ceiling)\n",
    "\n",
    "    if overwrite == False:\n",
    "        if 'Adist_bins'+str(A_bins)+'_sp1e'+str(speedup)+'_rounds1e'+str(rounds)+'_'+starting_conditions[6]+'.pickle' in finished:\n",
    "            print('already done: ' + starting_conditions[6])\n",
    "            return None\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass        \n",
    "    print('\\r' + '         ' + starting_conditions[6], end = '     ')\n",
    "    A_counts_timeseries = dict(); B_counts_timeseries = dict()\n",
    "    A_counts_timeseries[0] = starting_conditions[0]; B_counts_timeseries[0] = starting_conditions[1]\n",
    "    A_counts_current = A_counts_timeseries[0]; B_counts_current = B_counts_timeseries[0]; flag = False; boundary_flag = False\n",
    "    for rep in range(1, 1 + 10**rounds):\n",
    "        if (flag == False):# & (max(A_counts_current[~np.isnan(A_counts_current)]) < 1e12):\n",
    "            A_counts_current, B_counts_current, flag, boundary_flag = mut_evolve_dist_AB(A_counts_current, B_counts_current, starting_conditions[2:6], boot=boot, input_nuc = input_nuc, mutonly=mutonly, speedup_multiplier=10**speedup, stochastics = stochastics, reflective = reflective)\n",
    "            if rep%int(max(1, 1e6/(10**speedup))) == 0:\n",
    "                print('\\r' + str(rep), end = '   ')\n",
    "                A_counts_timeseries[rep], B_counts_timeseries[rep] = A_counts_current, B_counts_current\n",
    "        else:\n",
    "            print('\\r' + 'ending due to numerical error at round '+str(rep))\n",
    "            break\n",
    "    A_counts_timeseries = pd.DataFrame(A_counts_timeseries)\n",
    "    B_counts_timeseries = pd.DataFrame(B_counts_timeseries)\n",
    "    A_counts_timeseries.to_pickle(sim_dir + 'Adist_'+input_nuc+'_bins'+str(A_bins)+'_sp1e'+str(speedup)+'_rounds1e'+str(rounds)+'_'+starting_conditions[6]+'.pickle')\n",
    "    B_counts_timeseries.to_pickle(sim_dir + 'Bdist_'+input_nuc+'_bins'+str(A_bins)+'_sp1e'+str(speedup)+'_rounds1e'+str(rounds)+'_'+starting_conditions[6]+'.pickle')\n",
    "    return A_counts_timeseries, B_counts_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac09a8-5b53-47be-82e6-c94102fda7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='repeat distribution simulation')\n",
    "\n",
    "parser.add_argument('--dir', action=\"store\", dest='dir', default = 'simulations/grid_output/', type=str)\n",
    "parser.add_argument('--mult', action=\"store\", dest='mult', type=float)\n",
    "parser.add_argument('--exp', action=\"store\", dest='exp', type=float)\n",
    "parser.add_argument('--con', action=\"store\", dest='con', type=float)\n",
    "parser.add_argument('--L_mult', action=\"store\", dest='L_mult', default = 9, type=int)\n",
    "parser.add_argument('--L_mult_nonexp', action=\"store\", dest='L_mult_nonexp', default = 9, type=int)\n",
    "parser.add_argument('--motif', action=\"store\", dest='motif', default = 'A', type=str)\n",
    "parser.add_argument('--speedup', action=\"store\", dest='speedup', default = 3, type=int)\n",
    "parser.add_argument('--rounds', action=\"store\", dest='rounds', default = 5, type=int)\n",
    "parser.add_argument('--A_bins', action=\"store\", dest='A_bins', default = 200, type=int)\n",
    "parser.add_argument('--B_bins', action=\"store\", dest='B_bins', default = 200, type=int)\n",
    "parser.add_argument('--boot', action=\"store\", dest='boot', type = int)\n",
    "parser.add_argument('--mutonly', default=False, action=\"store_true\")\n",
    "parser.add_argument('--random_start', default=False, action=\"store_true\")\n",
    "parser.add_argument('--overwrite', default=False, action=\"store_true\")\n",
    "parser.add_argument('--stochastics', action=\"store\", dest='stochastics', type = int)\n",
    "parser.add_argument('--ceiling', action=\"store\", dest='ceiling', default=None, type=float)\n",
    "parser.add_argument('--reflective', default=True, action=\"store_false\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "finished = os.listdir(args.dir)\n",
    "run_simulation(mult=args.mult, exp_power=args.exp, con_power=args.con, boot = args.boot, L_mult = args.L_mult, L_mult_nonexp = args.L_mult_nonexp, input_nuc = args.motif, A_bins = args.A_bins, B_bins = args.B_bins, mutonly = args.mutonly, random_start = args.random_start, speedup = args.speedup, rounds = args.rounds, sim_dir = args.dir, overwrite = args.overwrite, stochastics = args.stochastics, ceiling = args.ceiling, reflective = args.reflective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd684e52-a228-4b08-a4e4-8b11183c5bf0",
   "metadata": {},
   "source": [
    "## Progressive speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da036aa8-2a07-41ad-81e1-063e1454641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_custom(mult, exp_power, con_power, max_speedup = 5, rounds_mult = 0, fill = False, nonexp_factor = False, A_bins = 100, B_bins = 100, input_nuc = 'A', mutonly = False, stochastics = None, boot = None, overwrite = False, random_start = False, subonly_start = True, reflective = True, sim_dir = 'simulations/test/'):\n",
    "    A_counts_timeseries = dict(); B_counts_timeseries = dict()\n",
    "    starting_conditions = setup_evolve(exp_power, con_power, mult, nonexp_factor = nonexp_factor, A_bins = A_bins, B_bins = B_bins, input_nuc = input_nuc, mutonly = mutonly, random_start = random_start, subonly_start = subonly_start, ceiling = None, boot = boot)\n",
    "    A_counts_timeseries[0] = starting_conditions[0]; B_counts_timeseries[0] = starting_conditions[1]\n",
    "    A_counts_current = A_counts_timeseries[0]; B_counts_current = B_counts_timeseries[0]; flag = False; boundary_flag = False\n",
    "\n",
    "    if overwrite == False:\n",
    "        if sim_dir + 'Adist_'+input_nuc+'_bins'+str(A_bins)+'_sp1e0_prospeedup_'+starting_conditions[6]+'.pickle' in finished:\n",
    "            print('already done: ' + starting_conditions[6])\n",
    "            return None\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    current_rep = 1\n",
    "    while max_speedup >= 0:\n",
    "        rounds = max(3, 5 - max_speedup) + rounds_mult; speedup = max_speedup; ceiling = 10**-(speedup+1)\n",
    "        starting_conditions = setup_evolve(exp_power, con_power, mult, nonexp_factor = nonexp_factor, A_bins = A_bins, B_bins = B_bins, input_nuc = input_nuc, mutonly = mutonly, random_start = random_start, subonly_start = subonly_start, ceiling = None, boot=boot, stochastics = stochastics)\n",
    "        if mutonly != True:\n",
    "            exp_rate, con_rate, nonexp_rate, B_indel_rate = starting_conditions[2:6]\n",
    "            exp_rate[exp_rate > ceiling] = ceiling\n",
    "            con_rate[con_rate > ceiling] = ceiling\n",
    "            nonexp_rate[nonexp_rate > ceiling] = ceiling\n",
    "            conditions_ceiling = (exp_rate, con_rate, nonexp_rate, B_indel_rate)\n",
    "        else:\n",
    "            conditions_ceiling = (None, None, None, None)\n",
    "\n",
    "        for rep in range(current_rep, current_rep + 10**rounds):\n",
    "            if flag == True:\n",
    "                print('\\r' + 'ending due to numerical error at round '+str(rep))\n",
    "                A_counts_timeseries = pd.DataFrame(A_counts_timeseries)\n",
    "                B_counts_timeseries = pd.DataFrame(B_counts_timeseries)\n",
    "                A_counts_timeseries.to_pickle(sim_dir + 'Adist_'+input_nuc+'_bins'+str(A_bins)+'_sp1e0_prospeedup_'+starting_conditions[6]+'.pickle')\n",
    "                B_counts_timeseries.to_pickle(sim_dir + 'Bdist_'+input_nuc+'_bins'+str(A_bins)+'_sp1e0_prospeedup_'+starting_conditions[6]+'.pickle')\n",
    "                return A_counts_timeseries, B_counts_timeseries\n",
    "            if (boundary_flag == True) & (max_speedup > 0): # move to next lower speedup if boundary is hit\n",
    "                break\n",
    "            else:\n",
    "                A_counts_current, B_counts_current, flag, boundary_flag = mut_evolve_dist_AB(A_counts_current, B_counts_current, conditions_ceiling, input_nuc = input_nuc, mutonly=mutonly, speedup_multiplier=10**speedup, stochastics = stochastics, reflective = reflective, boot=boot)\n",
    "                if rep%int(max(1, 10**(rounds-2))) == 0:\n",
    "                    print('\\r' + str(rep), end = '   ')\n",
    "                    A_counts_timeseries[rep], B_counts_timeseries[rep] = A_counts_current, B_counts_current        \n",
    "        current_rep += 10**rounds\n",
    "        max_speedup -= 1\n",
    "        # forgo next speedup round if rate ceiling has not been hit at current speedup\n",
    "        if exp_rate.max() + con_rate.max() < ceiling:\n",
    "            break\n",
    "        \n",
    "    A_counts_timeseries = pd.DataFrame(A_counts_timeseries)\n",
    "    B_counts_timeseries = pd.DataFrame(B_counts_timeseries)\n",
    "    A_counts_timeseries.to_pickle(sim_dir + 'Adist_'+input_nuc+'_bins'+str(A_bins)+'_sp1e0_prospeedup_'+starting_conditions[6]+'.pickle')\n",
    "    B_counts_timeseries.to_pickle(sim_dir + 'Bdist_'+input_nuc+'_bins'+str(A_bins)+'_sp1e0_prospeedup_'+starting_conditions[6]+'.pickle')\n",
    "    return A_counts_timeseries, B_counts_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c8a3f-c942-43f9-ac4f-50076418727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='repeat distribution simulation')\n",
    "\n",
    "parser.add_argument('--dir', action=\"store\", dest='dir', default = 'simulations/grid_output/', type=str)\n",
    "parser.add_argument('--mult', action=\"store\", dest='mult', type=float)\n",
    "parser.add_argument('--exp', action=\"store\", dest='exp', type=float)\n",
    "parser.add_argument('--con', action=\"store\", dest='con', type=float)\n",
    "parser.add_argument('--motif', action=\"store\", dest='motif', default = 'A', type=str)\n",
    "parser.add_argument('--speedup', action=\"store\", dest='speedup', default = 5, type=int)\n",
    "parser.add_argument('--rounds', action=\"store\", dest='rounds', default = 0, type=int)\n",
    "parser.add_argument('--A_bins', action=\"store\", dest='A_bins', default = 200, type=int)\n",
    "parser.add_argument('--B_bins', action=\"store\", dest='B_bins', default = 200, type=int)\n",
    "parser.add_argument('--boot', action=\"store\", dest='boot', type = int)\n",
    "parser.add_argument('--mutonly', default=False, action=\"store_true\")\n",
    "parser.add_argument('--random_start', default=False, action=\"store_true\")\n",
    "parser.add_argument('--subonly_start', default=False, action=\"store_true\")\n",
    "parser.add_argument('--overwrite', default=False, action=\"store_true\")\n",
    "parser.add_argument('--stochastics', action=\"store\", dest='stochastics', type = int)\n",
    "parser.add_argument('--reflective', default=True, action=\"store_false\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "finished = os.listdir(args.dir)\n",
    "run_simulation_custom(mult=args.mult, exp_power=args.exp, con_power=args.con, boot = args.boot, input_nuc = args.motif, A_bins = args.A_bins, B_bins = args.B_bins, mutonly = args.mutonly, random_start = args.random_start, subonly_start = args.subonly_start, max_speedup = args.speedup, rounds_mult = args.rounds, sim_dir = args.dir, overwrite = args.overwrite, stochastics = args.stochastics, reflective = args.reflective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c840295-5944-4afe-a85d-d8780397f7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18968b64-19d2-4db5-8f04-e297c8c3d95e",
   "metadata": {},
   "source": [
    "## Run tests\n",
    "- remove below from simulation_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb9267-5360-4472-af30-2ed0dc158b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to store simulation results (can be changed as needed)\n",
    "sim_dir = 'simulations/test/'\n",
    "finished = os.listdir(sim_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64688902-07d6-482c-b220-59ffba6acb1c",
   "metadata": {},
   "source": [
    "#### with constant speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83c54a-a6dc-445e-9b65-12dd812c470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_simulation(mult=1, exp_power=1, con_power=1, input_nuc = 'A', mutonly = False, speedup = 4, rounds = 4, fill = True, A_bins = 100, B_bins = 200, random_start = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd336e-8ef9-4a95-903a-22c77ca20eac",
   "metadata": {},
   "source": [
    "#### with progressive speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865082d-efe5-438a-a2c5-434118a8afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dict()\n",
    "test[0] = run_simulation_custom(1, 0, 0.5, max_speedup=5, rounds_mult = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adeef1e-c5d5-4570-98d0-d4e056ada8ad",
   "metadata": {},
   "source": [
    "## substitution only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c44a09-498f-41c7-8624-52713be03610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to store simulation results (can be changed as needed)\n",
    "sim_dir = 'simulations/subonly_output/'\n",
    "finished = os.listdir(sim_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ddde6-1baf-4cb2-8e66-b8da9f161b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_simulation(input_nuc='A', B_bins = 200, mutonly = True, speedup = 5, random_start=True, rounds = 5, ceiling = 1e-5, sim_dir='simulations/subonly_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526fdf4-7a80-423f-9799-aeb44176374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_simulation(input_nuc='AC', B_bins = 500, mutonly = True, speedup = 5, random_start=True, rounds = 5, ceiling = 1e-5, sim_dir='simulations/subonly_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd398c-2129-489e-a51c-78a95c271297",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_simulation(input_nuc='AAC', B_bins = 500, mutonly = True, speedup = 5, random_start=True, rounds = 5, ceiling = 1e-5, sim_dir='simulations/subonly_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f572c0c-b29b-47d0-ac90-61152770fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_simulation(input_nuc='AAAC', B_bins = 2000, mutonly = True, speedup = 5, random_start=True, rounds = 5, ceiling = 1e-5, sim_dir='simulations/subonly_output/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
