{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f705ba-0c57-4e10-881d-46c1e6ff6716",
   "metadata": {},
   "source": [
    "# Supplemental Code\n",
    "- Inherent instability of simple DNA repeats shapes an evolutionarily stable distribution of repeat lengths \n",
    "- McGinty et al. 2025\n",
    "- Part 2 of 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3dc6a-1715-4063-8afd-8bd43f4254c1",
   "metadata": {},
   "source": [
    "### Load Python libraries and define functions\n",
    "- Links included for instructions on how to install libraries using pip or conda (if libraries not included with conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2a275-c34c-4249-a230-ac95de1d4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import gzip\n",
    "import regex as re\n",
    "import fastapy\n",
    "from liftover import ChainFile    # https://pypi.org/project/liftover/\n",
    "from liftover import get_lifter\n",
    "import gc\n",
    "import scipy\n",
    "from multiprocessing import Process, Manager\n",
    "manager = Manager()\n",
    "\n",
    "import kaleido    # https://github.com/plotly/Kaleido\n",
    "import plotly     # https://plotly.com/python/getting-started/\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "pio.templates.default = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755a1e3-2714-4f0f-82e1-13cb431615c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = ['A', 'T', 'G', 'C']\n",
    "def reverse_complement(dna):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return ''.join([complement[base] for base in dna[::-1]]) \n",
    "def repeat_frames_RC(input_seq):\n",
    "    return list(pd.Series([''.join(input_seq*2)[i:len(input_seq)+i] for i in range(len(input_seq))] + [reverse_complement(seq) for seq in [''.join(input_seq*2)[i:len(input_seq)+i] for i in range(len(input_seq))]]).sort_values().drop_duplicates())\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea27c1-89f4-4ecf-b2fb-b191ec1a33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(chrom, start, end, genome):\n",
    "    chrom_list_current = genome.keys()\n",
    "    start_min = min(start, end); end_max = max(start, end)\n",
    "    if chrom in chrom_list_current:\n",
    "        return genome[chrom][int(start_min):int(end_max)]\n",
    "    elif chrom[3:] in chrom_list_current:\n",
    "        return genome[chrom[3:]][int(start_min):int(end_max)]\n",
    "    elif int(chrom[3:]) in chrom_list_current:\n",
    "        return genome[int(chrom[3:])][int(start_min):int(end_max)]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a668be0-171a-4111-b4ea-e7c9811b610d",
   "metadata": {},
   "source": [
    "### Load reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3606da-ad2f-428e-8c23-47f554886f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_list = list(range(1,23))\n",
    "chrom_list_XY = list(range(1,23)) + ['X', 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f35ff-ced6-4beb-91d7-f833b72edbd8",
   "metadata": {},
   "source": [
    "#### T2T-CHM13 genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8687f7c8-a55e-481f-aac8-3b7ad4eb53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHM13_genome_fasta = list(fastapy.parse('genomes/hs1.fa.gz'))\n",
    "CHM13_genome = dict()\n",
    "for seq in CHM13_genome_fasta:\n",
    "    try:\n",
    "        name = int(seq.id[3:])\n",
    "    except:\n",
    "        name = seq.id[3:]\n",
    "    if name in chrom_list_XY:\n",
    "        CHM13_genome[name] = seq.seq.upper()\n",
    "del CHM13_genome_fasta\n",
    "gc.collect()\n",
    "CHM13_genome.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9282c-c2f0-45f4-835a-801de286a484",
   "metadata": {},
   "source": [
    "#### hg38 genome\n",
    "- download \"hg38.fa.gz\" from http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d2e7a-e56e-4e93-bd10-6ab668eb55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38_genome_fasta = list(fastapy.parse('genomes/hg38.fa.gz'))\n",
    "hg38_genome = dict()\n",
    "for seq in hg38_genome_fasta:\n",
    "    try:\n",
    "        name = int(seq.id[3:])\n",
    "    except:\n",
    "        name = seq.id[3:]\n",
    "    if name in chrom_list_XY:\n",
    "        hg38_genome[name] = seq.seq.upper()\n",
    "del hg38_genome_fasta\n",
    "gc.collect()\n",
    "hg38_genome.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf9ca8-bca9-445e-82fd-1700cd63a334",
   "metadata": {},
   "source": [
    "# de novo instability rate measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0c88a-0cb8-4244-a54b-7ee6c2870e69",
   "metadata": {},
   "source": [
    "## Prepare de novo mutation database\n",
    "- Gather de novo data from all available public sources (trio/family sequencing)\n",
    "- See manuscript for DOI links to these studies\n",
    "- Place files in directory './denovo/download/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b42172-595d-4cc0-a662-137ca80c1dc8",
   "metadata": {},
   "source": [
    "### de novo data aligned to hg19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8a024-f7a7-400a-a55a-d6af6e9b7f72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### data from Goldman 2016 (hg19)\n",
    "- Parent-of-origin-specific signatures of de novo mutations\n",
    "- phased\n",
    "- 816 trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4570a-0454-4604-b861-7105353b958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_gold = pd.read_excel('./denovo/download/41588_2016_BFng3597_MOESM69_ESM_hg19.xlsx', usecols = ['Chromosome', 'Start.position', 'Reference', 'Variant', 'parentOfOrigin'])\n",
    "trio_gold.columns = ['chrom', 'pos', 'ref', 'alt', 'parent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe365e0-dced-4512-9893-2afde3f95b41",
   "metadata": {},
   "source": [
    "#### data from Goes et al 2021 (hg19)\n",
    "- De novo variation in bipolar disorder\n",
    "- unphased\n",
    "- 97 trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc6eb3-6694-4960-aa3d-ab497d5dbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "goes2019 = pd.read_excel('./denovo/download/41380_2019_611_MOESM3_ESM.xlsx', usecols = ['chr_bp_ref_alt', 'SNV'])\n",
    "goes2019[['chrom', 'pos', 'ref', 'alt']] = goes2019['chr_bp_ref_alt'].str.split('_', expand = True)\n",
    "goes2019 = goes2019.dropna()[['chrom', 'pos', 'ref', 'alt']]\n",
    "goes2019['chrom'] = ['chr' + str(chrom) for chrom in goes2019['chrom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec217f7-0224-4620-8763-3925888cff3b",
   "metadata": {},
   "source": [
    "#### data from Yuen et al. 2016 (hg19)\n",
    "- Genome-wide characteristics of de novo mutations in autism\n",
    "- 192 trios\n",
    "- phased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2b68c-b94b-4dcc-ae8d-e13845d073f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yuen_trios = pd.read_excel('./denovo/download/41525_2016_BFnpjgenmed201627_MOESM431_ESM.xlsx', sheet_name='Table S4', skiprows = 1, usecols = ['Chromosome', 'Start', 'Reference', 'Allel', 'Parental Origin'])\n",
    "yuen_trios.columns = ['chrom', 'pos', 'ref', 'alt', 'parent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae5b97-4e04-4cb2-9dad-b65546ac126c",
   "metadata": {},
   "source": [
    "#### data from Sasani 2019 (hg19)\n",
    "- Large, three-generation human families reveal post-zygotic mosaicism and variability in germline mutation accumulation\n",
    "- phased\n",
    "- 350 3rd generation offspring, 70 2nd generation offspring (420 genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bcc67-797d-478d-9a5d-d2efdd9c314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnm_ceph_gen2 = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/second_gen.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "dnm_ceph_gen3 = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/third_gen.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "dnm_ceph_gen2_gon = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/gonosomal.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "dnm_ceph_gen3_gon = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/post-pgcs.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "\n",
    "dnm_ceph = pd.concat([dnm_ceph_gen2, dnm_ceph_gen2_gon, dnm_ceph_gen3, dnm_ceph_gen3_gon])\n",
    "dnm_ceph['chrom'] = ['chr' + str(chrom) for chrom in dnm_ceph['chrom']]\n",
    "\n",
    "dnm_ceph.columns = ['chrom', 'pos', 'ref', 'alt', 'paternal_age', 'maternal_age', 'phase']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a95bf4-9c90-4bca-a571-97aa16f48d6a",
   "metadata": {},
   "source": [
    "#### Liftover hg19 data to hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6995c06-e0e3-48e2-8135-96ace2606b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_hg19 = pd.concat([trio_gold, goes2019, dnm_ceph, yuen_trios]).reset_index(drop = True)\n",
    "trio_hg19['pos'] = trio_hg19['pos'].astype(int)\n",
    "\n",
    "# Liftover to hg38\n",
    "lo = get_lifter('hg19', 'hg38')\n",
    "trio_hg19['hg38_lo'] = [lo.convert_coordinate(chrom, pos) for chrom,pos in zip(trio_hg19['chrom'], trio_hg19['pos'])]\n",
    "trio_hg19['hg38_chr'] = [pos[0][0] if len(pos) >0 else np.nan for pos in trio_hg19['hg38_lo']]\n",
    "trio_hg19['hg38_pos'] = [pos[0][1] if len(pos) >0 else np.nan for pos in trio_hg19['hg38_lo']]\n",
    "trio_hg19 = trio_hg19.dropna(subset = ['hg38_chr'], axis=0)\n",
    "trio_hg19['hg38_chr'] = [int(chrom[3:]) if (chrom[3:] not in ['X', 'Y']) & (len(chrom) < 6) else chrom[3:] if chrom[3:] in ['X', 'Y'] else np.nan for chrom in trio_hg19['hg38_chr']]\n",
    "trio_hg19 = trio_hg19.dropna(subset = ['hg38_chr'])\n",
    "trio_hg19['hg38_pos'] = trio_hg19['hg38_pos'].astype(int)\n",
    "trio_hg19['hg38_base'] = [hg38_genome[chrom][pos-1] for chrom, pos in zip(trio_hg19['hg38_chr'], trio_hg19['hg38_pos'])]\n",
    "trio_hg19 = trio_hg19.loc[trio_hg19['ref'] == trio_hg19['hg38_base']].copy()\n",
    "trio_hg19 = trio_hg19[['hg38_chr', 'hg38_pos', 'ref', 'alt', 'parent']].copy()\n",
    "trio_hg19.columns = ['chrom', 'pos', 'ref', 'alt', 'parent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1a0ce-435e-46e2-8b98-baecab176135",
   "metadata": {},
   "source": [
    "### de novo data aligned to hg38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb6032-f849-4724-87a1-e4f46421ebc3",
   "metadata": {},
   "source": [
    "#### data from Halldorsson 2019 in Science (hg38)\n",
    "- Characterizing mutagenic effects of recombination through a sequence-level genetic map\n",
    "- phased\n",
    "- 2976 trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceed5e4-338c-41ea-a285-94c824dfc404",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_set1 = pd.read_csv('./denovo/download/aau1043_DataS5_revision1.tsv', skiprows = 11, sep = '\\t', low_memory=False)\n",
    "trio_set1_ages = pd.read_csv('./denovo/download/aau1043_DataS7.tsv', skiprows = 4, sep = '\\t')\n",
    "\n",
    "trio_set1_ages.index = trio_set1_ages['Proband_id']\n",
    "trio_set1['Father_age'] = [trio_set1_ages['Father_age'][pro] for pro in trio_set1['Proband_id']]\n",
    "trio_set1['Mother_age'] = [trio_set1_ages['Mother_age'][pro] for pro in trio_set1['Proband_id']]\n",
    "\n",
    "trio_set1['Chr'] = [chrom[3:] if chrom.startswith('chr') == True else chrom for chrom in trio_set1['Chr']]\n",
    "trio_set1['Chr'] = [int(chrom) if chrom not in ['X', 'Y'] else chrom for chrom in trio_set1['Chr']]\n",
    "\n",
    "trio_set1 = trio_set1[['Chr', 'Pos', 'Ref', 'Alt', 'Phase_combined', 'Father_age', 'Mother_age']]\n",
    "trio_set1.columns = ['chrom', 'pos', 'ref', 'alt', 'parent', 'paternal_age', 'maternal_age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc467a-bf54-4186-87be-acf6cc5297de",
   "metadata": {},
   "source": [
    "#### data from Jonnson 2017 in Nature (hg38)\n",
    "- Parental influence on human germline de novo mutations in 1,548 trios from Iceland\n",
    "- 1548 trios\n",
    "- phased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126106e-36be-40b2-9021-43c2c4bb0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_set2 = pd.read_csv('./denovo/download/decode_DNMs.tsv', sep = '\\t', usecols = ['Chr', 'Pos_hg38', 'Ref', 'Alt', 'Discordant_in_3_gen_or_mz_twins', 'Fathers_age_at_conception', 'Mothers_age_at_conception', 'Phase_combined'])\n",
    "\n",
    "trio_set2['Chr'] = [chrom[3:] if chrom.startswith('chr') == True else chrom for chrom in trio_set2['Chr']]\n",
    "trio_set2['Chr'] = [int(chrom) if chrom not in ['X', 'Y'] else chrom for chrom in trio_set2['Chr']]\n",
    "\n",
    "trio_set2.columns = ['chrom', 'pos', 'ref', 'alt', 'discordant', 'paternal_age', 'maternal_age', 'parent']\n",
    "trio_set2 = trio_set2.loc[trio_set2['discordant'] != 'Discordant']\n",
    "del trio_set2['discordant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197c6ba-682b-467a-9297-9b827c58ae7e",
   "metadata": {},
   "source": [
    "#### data from AN 2018 in Science (hg38)\n",
    "- Genome-wide de novo risk score implicates promoter variation in autism spectrum disorder\n",
    "- unphased\n",
    "- 1902 quartets (3804 genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ecac7-de7c-4b91-9e3b-8402183fefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_an = pd.read_excel('./denovo/download/aat6576_Table-S2_hg38_notphased.xlsx', skiprows = 1, usecols = ['Chr', 'Pos', 'Ref', 'Alt'])\n",
    "\n",
    "trio_an['Chr'] = [chrom[3:] if chrom.startswith('chr') == True else chrom for chrom in trio_an['Chr']]\n",
    "trio_an['Chr'] = [int(chrom) if chrom not in ['X', 'Y'] else chrom for chrom in trio_an['Chr']]\n",
    "\n",
    "trio_an.columns = ['chrom', 'pos', 'ref', 'alt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8e799-0ac9-4cd2-b0fd-b4aaabfb8e3f",
   "metadata": {},
   "source": [
    "#### data from Jonsson et al 2021 (hg38)\n",
    "- Differences between germline genomes of monozygotic twins\n",
    "- 451 offspring in quads\n",
    "- 608 offspring in three-generation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75865e0-5382-4cf5-b6ee-18b6a0e39549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de novo mutations from quads\n",
    "jonsson_quads = pd.read_csv('./denovo/download/41588_2020_755_MOESM5_ESM.tsv', sep = '\\t', usecols = ['Chr', 'Pos', 'Ref', 'Alt', 'Child_Fathers_Age_at_birth', 'Child_Mothers_Age_at_birth'])\n",
    "jonsson_quads.columns = ['chrom', 'pos', 'ref', 'alt', 'paternal_age', 'maternal_age']\n",
    "\n",
    "# de novo mutations from three-generation approach\n",
    "jonsson_3gen = pd.read_csv('./denovo/download/41588_2020_755_MOESM4_ESM.tsv', sep = '\\t', usecols = ['Chr', 'Pos', 'Ref', 'Alt'])\n",
    "jonsson_3gen.columns = ['chrom', 'pos', 'ref', 'alt']\n",
    "\n",
    "jonsson_quads['chrom'] = [chrom[3:] if chrom.startswith('chr') == True else chrom for chrom in jonsson_quads['chrom']]\n",
    "jonsson_quads['chrom'] = [int(chrom) if chrom not in ['X', 'Y'] else chrom for chrom in jonsson_quads['chrom']]\n",
    "\n",
    "jonsson_3gen['chrom'] = [chrom[3:] if chrom.startswith('chr') == True else chrom for chrom in jonsson_3gen['chrom']]\n",
    "jonsson_3gen['chrom'] = [int(chrom) if chrom not in ['X', 'Y'] else chrom for chrom in jonsson_3gen['chrom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efe139-0ea8-4ae7-9a75-d2b9a5177b6f",
   "metadata": {},
   "source": [
    "### Combine all into single de novo database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4462b-3047-42b5-9b12-82fc2d7fe356",
   "metadata": {},
   "source": [
    "#### SNVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2fdd4-153f-48e4-80a9-e2ed42c6d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined = pd.concat([trio_set1, trio_set2, trio_an, jonsson_3gen, jonsson_quads, trio_hg19]).reset_index(drop = True)\n",
    "denovo_combined = denovo_combined.loc[(denovo_combined['ref'].str.len() == 1) & (denovo_combined['alt'].str.len() == 1)].copy()\n",
    "denovo_combined['parent'] = denovo_combined['parent'].str.lower()\n",
    "denovo_combined['parent'] = denovo_combined['parent'].fillna('unassigned')\n",
    "denovo_combined['tri'] = [hg38_genome[chrom][pos-2:pos+1] for chrom, pos in zip(denovo_combined['chrom'], denovo_combined['pos'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54bd04-92d7-4998-b8d4-413ae3f54d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save database\n",
    "denovo_combined.to_csv('./denovo/all_denovo_snvs_remake.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653c5b3-aa22-4780-9b94-1478aa3e6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_n_genomes_snv = (816 + 97 + 192 + 420 + 2976+ 1548 + 3804 + 451 + 608) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df69091-5626-4f9d-8d97-e359b5546a47",
   "metadata": {},
   "source": [
    "#### Indels\n",
    "- note: hg19 files do not contain any indels\n",
    "- all hg38 files contain indels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e0e58-25f7-43d0-9488-50f4bf95a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_indel = pd.concat([trio_set1, trio_set2, trio_an, jonsson_3gen, jonsson_quads]).reset_index(drop = True)\n",
    "denovo_combined_indel = denovo_combined_indel.loc[(denovo_combined_indel['ref'].str.len() != 1) | (denovo_combined_indel['alt'].str.len() != 1)].copy()\n",
    "denovo_combined_indel['parent'] = denovo_combined_indel['parent'].str.lower()\n",
    "denovo_combined_indel['parent'] = denovo_combined_indel['parent'].fillna('unassigned')\n",
    "\n",
    "# Save database\n",
    "denovo_combined_indel.to_csv('./denovo/all_denovo_indels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ed1e5-eb52-4e5e-9f6d-ab9942e4ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_n_genomes_indel = (2976+ 1548 + 3804 + 451 + 608) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268cc368-2ca5-4444-9887-548537271d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_n_genomes_indel / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28117f-a6ad-47e0-93c1-a3f8e5939794",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_indel = pd.read_csv('./denovo/all_denovo_indels.csv')\n",
    "denovo_combined_indel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097fc219-32f9-4609-a2a1-e404920fd89a",
   "metadata": {},
   "source": [
    "## Calculate de novo substitution rate considering context for A-mononucleotide repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d37019-ef22-4d43-813d-9c48525184ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_snv = pd.read_csv('denovo/all_denovo_snvs_remake.csv', low_memory=False)\n",
    "denovo_n_genomes_snv = (816 + 97 + 192 + 420 + 2976+ 1548 + 3804 + 451 + 608) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9212ccb-7a36-4326-b4c9-3ca762e64d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_snv['chrom'] = [int(chrom) if chrom not in ['X', 'Y'] else chrom for chrom in denovo_combined_snv['chrom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f1dad-4951-4149-a567-7ae70ae0d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_snv['tri_AB'] = denovo_combined_snv['tri'].str.replace('C', 'B').str.replace('T', 'B').str.replace('G', 'B')\n",
    "denovo_combined_snv['pos_100kb'] = ((denovo_combined_snv['pos'] / 1e5).astype(int) * 1e5).astype(int)\n",
    "count_by_100kb = denovo_combined_snv.groupby(['chrom', 'pos_100kb'])['ref'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a2d2d-6e51-4cad-b013-3a02e14664d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_counts_mutregions = dict()\n",
    "for chrom, pos in count_by_100kb.index:\n",
    "    seq = hg38_genome[chrom][int(pos):int(pos+1e5)]\n",
    "    triplet_counts_mutregions[(chrom, pos, 'A')] = pd.Series(re.findall('...', seq), dtype=object).value_counts()\n",
    "    triplet_counts_mutregions[(chrom, pos, 'B')] = pd.Series(re.findall('...', seq[1:]), dtype=object).value_counts()\n",
    "    triplet_counts_mutregions[(chrom, pos, 'C')] = pd.Series(re.findall('...', seq[2:]), dtype=object).value_counts()\n",
    "    print ('\\r' + 'finished chr'+str(chrom) + ' '+str(pos), end = ' ')\n",
    "triplet_counts_mutregions_sum = pd.concat(triplet_counts_mutregions, axis=1).sum(axis=1).reindex(denovo_combined_snv['tri'].value_counts().index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff1fc4-290a-455a-9c39-6581d235d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_counts_mutregions_sum.to_pickle('denovo/triplet_counts_mutregions_sum.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec3553-87eb-4b5b-be35-0e4056e5618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_counts_mutregions_sum = pd.read_pickle('denovo/triplet_counts_mutregions_sum.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933a3ce-c43f-4129-b275-e4b3d14e9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_counts_mutregions_AB = triplet_counts_mutregions_sum.reset_index()\n",
    "triplet_counts_mutregions_AB['tri_AB'] = triplet_counts_mutregions_AB['tri'].str.replace('C', 'B').str.replace('T', 'B').str.replace('G', 'B')\n",
    "triplet_counts_mutregions_AB = triplet_counts_mutregions_AB.groupby(['tri_AB'])[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c00bc-4f5a-4c64-9c7e-871ef4dd7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "Afusion = len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'A') & (denovo_combined_snv['tri_AB'] == 'ABA')]) / triplet_counts_mutregions_AB['ABA'] / denovo_n_genomes_snv\n",
    "Aexpansion = len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'A') & (denovo_combined_snv['tri_AB'] == 'BBB')]) / triplet_counts_mutregions_AB['BBB'] / denovo_n_genomes_snv\n",
    "A01 = len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'A') & ((denovo_combined_snv['tri_AB'] == 'ABB') | (denovo_combined_snv['tri_AB'] == 'BBA'))]) / triplet_counts_mutregions_AB[['ABB', 'BBA']].sum() / denovo_n_genomes_snv\n",
    "Afission = len(denovo_combined_snv.loc[(denovo_combined_snv['tri_AB'] == 'AAA')]) / triplet_counts_mutregions_AB['AAA'] / denovo_n_genomes_snv\n",
    "Acontraction = len(denovo_combined_snv.loc[(denovo_combined_snv['tri_AB'] == 'BAB')]) / triplet_counts_mutregions_AB['BAB'] / denovo_n_genomes_snv\n",
    "A10 = len(denovo_combined_snv.loc[((denovo_combined_snv['tri_AB'] == 'AAB') | (denovo_combined_snv['tri_AB'] == 'BAA'))]) / triplet_counts_mutregions_AB[['AAB', 'BAA']].sum() / denovo_n_genomes_snv\n",
    "\n",
    "denovo_mut_freq_AB = pd.Series([Afission, Acontraction, A10, Afusion, Aexpansion, A01], index = ['Afission', 'Acontraction', 'A10', 'Afusion', 'Aexpansion', 'A01'])\n",
    "denovo_mut_freq_AB.to_pickle('denovo/denovo_mut_freq_AB_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff85a0-8ec1-4572-99aa-a699b98c7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_AB = pd.read_pickle('denovo/denovo_mut_freq_AB_remake.pickle')\n",
    "denovo_mut_freq_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be588dda-01ff-4683-895d-f7297ff39253",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_counts_mutregions_CD = triplet_counts_mutregions_sum.reset_index()\n",
    "triplet_counts_mutregions_CD['tri_CD'] = triplet_counts_mutregions_CD['tri'].str.replace('A', 'D').str.replace('T', 'D').str.replace('G', 'D')\n",
    "triplet_counts_mutregions_CD = triplet_counts_mutregions_CD.groupby(['tri_CD'])[0].sum()\n",
    "\n",
    "denovo_combined_snv['tri_CD'] = denovo_combined_snv['tri'].str.replace('A', 'D').str.replace('T', 'D').str.replace('G', 'D')\n",
    "\n",
    "Cfusion = len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'C') & (denovo_combined_snv['tri_CD'] == 'CDC')]) / triplet_counts_mutregions_CD['CDC'] / denovo_n_genomes_snv\n",
    "Cexpansion = len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'C') & (denovo_combined_snv['tri_CD'] == 'DDD')]) / triplet_counts_mutregions_CD['DDD'] / denovo_n_genomes_snv\n",
    "C01 = len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'C') & ((denovo_combined_snv['tri_CD'] == 'CDD') | (denovo_combined_snv['tri_CD'] == 'DDC'))]) / triplet_counts_mutregions_CD[['CDD', 'DDC']].sum() / denovo_n_genomes_snv\n",
    "Cfission = len(denovo_combined_snv.loc[(denovo_combined_snv['tri_CD'] == 'CCC')]) / triplet_counts_mutregions_CD['CCC'] / denovo_n_genomes_snv\n",
    "Ccontraction = len(denovo_combined_snv.loc[(denovo_combined_snv['tri_CD'] == 'DCD')]) / triplet_counts_mutregions_CD['DCD'] / denovo_n_genomes_snv\n",
    "C10 = len(denovo_combined_snv.loc[((denovo_combined_snv['tri_CD'] == 'CCD') | (denovo_combined_snv['tri_CD'] == 'DCC'))]) / triplet_counts_mutregions_CD[['CCD', 'DCC']].sum() / denovo_n_genomes_snv\n",
    "\n",
    "denovo_mut_freq_CD = pd.Series([Cfission, Ccontraction, C10, Cfusion, Cexpansion, C01], index = ['Afission', 'Acontraction', 'A10', 'Afusion', 'Aexpansion', 'A01'])\n",
    "denovo_mut_freq_CD.to_pickle('denovo/denovo_mut_freq_CD_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ede86d-8c1b-4121-a230-baa51882c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_CD = pd.read_pickle('denovo/denovo_mut_freq_CD_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139032af-951a-4ac6-ba00-18bc442690b1",
   "metadata": {},
   "source": [
    "#### Poisson random sampling for substitution rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370eeba-b051-4ff9-a460-f248e03b4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_AB_poisson = dict()\n",
    "for i in range(200):\n",
    "    Afusion = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'A') & (denovo_combined_snv['tri_AB'] == 'ABA')])) / triplet_counts_mutregions_AB['ABA'] / denovo_n_genomes_snv\n",
    "    Aexpansion = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'A') & (denovo_combined_snv['tri_AB'] == 'BBB')])) / triplet_counts_mutregions_AB['BBB'] / denovo_n_genomes_snv\n",
    "    A01 = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'A') & ((denovo_combined_snv['tri_AB'] == 'ABB') | (denovo_combined_snv['tri_AB'] == 'BBA'))])) / triplet_counts_mutregions_AB[['ABB', 'BBA']].sum() / denovo_n_genomes_snv\n",
    "    Afission = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['tri_AB'] == 'AAA')])) / triplet_counts_mutregions_AB['AAA'] / denovo_n_genomes_snv\n",
    "    Acontraction = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['tri_AB'] == 'BAB')])) / triplet_counts_mutregions_AB['BAB'] / denovo_n_genomes_snv\n",
    "    A10 = np.random.poisson(len(denovo_combined_snv.loc[((denovo_combined_snv['tri_AB'] == 'AAB') | (denovo_combined_snv['tri_AB'] == 'BAA'))])) / triplet_counts_mutregions_AB[['AAB', 'BAA']].sum() / denovo_n_genomes_snv\n",
    "    \n",
    "    denovo_mut_freq_AB_poisson[i] = pd.Series([Afission, Acontraction, A10, Afusion, Aexpansion, A01], index = ['Afission', 'Acontraction', 'A10', 'Afusion', 'Aexpansion', 'A01'])\n",
    "denovo_mut_freq_AB_poisson = pd.concat(denovo_mut_freq_AB_poisson, axis=1)\n",
    "denovo_mut_freq_AB_poisson.to_pickle('denovo/denovo_mut_freq_AB_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1980cbec-66f2-4a8d-9ac1-48aaef510648",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_AB_poisson = pd.read_pickle('denovo/denovo_mut_freq_AB_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e9976-7319-4a4e-b76c-c7a6581d4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_CD_poisson = dict()\n",
    "for i in range(200):\n",
    "    Cfusion = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'C') & (denovo_combined_snv['tri_CD'] == 'CDC')])) / triplet_counts_mutregions_CD['CDC'] / denovo_n_genomes_snv\n",
    "    Cexpansion = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'C') & (denovo_combined_snv['tri_CD'] == 'DDD')])) / triplet_counts_mutregions_CD['DDD'] / denovo_n_genomes_snv\n",
    "    C01 = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['alt'] == 'C') & ((denovo_combined_snv['tri_CD'] == 'CDD') | (denovo_combined_snv['tri_CD'] == 'DDC'))])) / triplet_counts_mutregions_CD[['CDD', 'DDC']].sum() / denovo_n_genomes_snv\n",
    "    Cfission = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['tri_CD'] == 'CCC')])) / triplet_counts_mutregions_CD['CCC'] / denovo_n_genomes_snv\n",
    "    Ccontraction = np.random.poisson(len(denovo_combined_snv.loc[(denovo_combined_snv['tri_CD'] == 'DCD')])) / triplet_counts_mutregions_CD['DCD'] / denovo_n_genomes_snv\n",
    "    C10 = np.random.poisson(len(denovo_combined_snv.loc[((denovo_combined_snv['tri_CD'] == 'CCD') | (denovo_combined_snv['tri_CD'] == 'DCC'))])) / triplet_counts_mutregions_CD[['CCD', 'DCC']].sum() / denovo_n_genomes_snv\n",
    "    \n",
    "    denovo_mut_freq_CD_poisson[i] = pd.Series([Cfission, Ccontraction, C10, Cfusion, Cexpansion, C01], index = ['Afission', 'Acontraction', 'A10', 'Afusion', 'Aexpansion', 'A01'])\n",
    "denovo_mut_freq_CD_poisson = pd.concat(denovo_mut_freq_CD_poisson, axis=1)\n",
    "denovo_mut_freq_CD_poisson.to_pickle('denovo/denovo_mut_freq_CD_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac92a2-6761-4737-9211-8520626b69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_CD_poisson = pd.read_pickle('denovo/denovo_mut_freq_CD_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942137f-f12e-428b-8944-209ca70c71f5",
   "metadata": {},
   "source": [
    "## Calculate de novo indel rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd596358-23ae-4485-90b1-9029901f5c22",
   "metadata": {},
   "source": [
    "#### denominator for repeat lengths (count repeats in sequenceable regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4a358-c74b-494e-b9c9-c42bd9f333fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dist_1_6(seq, name, out, shuffle = False):\n",
    "    find_multi = r'([ATGC]{1,6}?)\\1+'; find_multi = re.compile(find_multi)\n",
    "    find_ind = r'([ATGC]{1,6}?)\\1{1,}'; find_ind = re.compile(find_ind)\n",
    "    find_L1 = dict()\n",
    "    find_L1[1] = r'([ATGC]{1})\\1{0}(?!\\1)'; find_L1[1] = re.compile(find_L1[1])\n",
    "    find_L1[2] = r'([ATGC]{2})\\1{0}(?!\\1)'; find_L1[2] = re.compile(find_L1[2])\n",
    "    find_L1[3] = r'([ATGC]{3})\\1{0}(?!\\1)'; find_L1[3] = re.compile(find_L1[3])\n",
    "    find_L1[4] = r'([ATGC]{4})\\1{0}(?!\\1)'; find_L1[4] = re.compile(find_L1[4])\n",
    "    find_L1[5] = r'([ATGC]{5})\\1{0}(?!\\1)'; find_L1[5] = re.compile(find_L1[5])\n",
    "    find_L1[6] = r'([ATGC]{6})\\1{0}(?!\\1)'; find_L1[6] = re.compile(find_L1[6])\n",
    "    \n",
    "    def count_L1(unit, seq, out):\n",
    "        out[unit] = pd.Series([m.group() for m in re.finditer(find_L1[unit], seq)]).value_counts()\n",
    "\n",
    "    seq = seq.upper()\n",
    "    if shuffle == True:\n",
    "        seq = ''.join(random.sample(seq, len(seq)))\n",
    "    \n",
    "    L1 = dict()\n",
    "    for unit in range(1,7):\n",
    "        count_L1(unit, seq, L1)\n",
    "    L1 = pd.concat(L1).reset_index()\n",
    "    L1.columns = ['unit_len', 'motif', 'count']\n",
    "    L1['length'] = 1\n",
    "    multi = pd.Series([m.group() for m in re.finditer(find_multi, seq, overlapped=True)]).value_counts().reset_index()\n",
    "    if len(multi) >0:\n",
    "        multi['motif'] = [re.split(find_ind, ind)[1] for ind in multi['index']]\n",
    "        multi['unit_len'] = multi['motif'].str.len()\n",
    "        multi['length'] = [index.count(motif) for index, motif in zip(multi['index'], multi['motif'])]\n",
    "    \n",
    "    counts = pd.concat([L1, multi])\n",
    "    counts['motif_RC'] = [repeat_frames_RC(motif)[0] for motif in counts['motif']]\n",
    "    counts = counts.groupby(['unit_len', 'motif_RC', 'length'])['count'].sum().unstack().transpose().sort_index(axis=0).fillna(0).astype(int)\n",
    "    counts  = counts.sub(counts.shift(-1), fill_value = 0)\n",
    "\n",
    "    out[name] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f8ee8-624b-41cc-ae89-4ca65b048478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A counts for motif length 1-6 in sequenceable regions of HG38   \n",
    "genome_counts = manager.dict()\n",
    "job = [Process(target=make_dist_1_6, args=(hg38_genome[record[0]][int(record[1]):int(record[1]+1e5)], record, genome_counts)) for record in count_by_100kb.index]\n",
    "_ = [p.start() for p in job]\n",
    "_ = [p.join() for p in job]\n",
    "_ = [p.close() for p in job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78094555-bef8-4790-949d-ff3100c8daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_counts_all = pd.concat(dict(genome_counts), axis=1).T.groupby(['unit_len', 'motif_RC']).sum().T.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6920d9-95b3-4957-b82c-2f587c10209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_counts_all.to_pickle('denovo/repeat_counts_mutregions_A_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf94b6-fc27-46f0-8a76-36ec1a8affd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need B[1] and B[2:] counts for B>A rates\n",
    "# must be run per motif\n",
    "def make_B_dist(seq, motif, out, name):\n",
    "    B_dist = dict()\n",
    "    for frame in repeat_frames_RC(motif):\n",
    "        find_B = '(?:(?!' + frame + ')[ATGC])+'\n",
    "        current = pd.DataFrame([m.span() for m in re.finditer(find_B, seq)])\n",
    "        if len(current) >0:\n",
    "            current = current[1] - current[0] - (len(motif)-1)\n",
    "            B_dist[frame] = current.value_counts()\n",
    "    if len(B_dist) > 0:\n",
    "        B_dist = pd.concat(B_dist, axis=1).fillna(0).sort_index().sum(axis=1)\n",
    "    out[name] = B_dist\n",
    "repeats_1_3 = ['A', 'C', 'AC', 'AT', 'AG', 'CG', 'AAT', 'AAG', 'AAC', 'ATC', 'ACT', 'AGG', 'AGC', 'ACG', 'ACC', 'CCG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7feb613-6761-4752-9b67-04ed682a0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_genome_counts = dict()\n",
    "counter = 0\n",
    "for motif in repeats_1_3:\n",
    "# B counts for motif length 1-3 in sequenceable regions of HG38   \n",
    "    genome_counts_B = manager.dict()\n",
    "    job = [Process(target=make_B_dist, args=(hg38_genome[record[0]][int(record[1]):int(record[1]+1e5)], motif, genome_counts_B, str(record))) for record in count_by_100kb.index]\n",
    "    _ = [p.start() for p in job]\n",
    "    _ = [p.join() for p in job]\n",
    "    _ = [p.close() for p in job]\n",
    "    B_genome_counts[motif] = pd.concat(dict(genome_counts_B), axis=1).sum(axis=1).sort_index()\n",
    "    counter +=1; print('\\r' + str(counter) + '/' + str(len(repeats_1_3)), end = '      ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c0edd-dd8a-45a5-8f2f-68435403465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_genome_counts_all = pd.concat(B_genome_counts, axis=1).fillna(0).astype(int)\n",
    "B_genome_counts_all.to_pickle('denovo/repeat_counts_mutregions_B_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900e3b4-f239-4849-8a74-8ce9ad8015f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_counts_mutregions_A_RC = pd.read_pickle('denovo/repeat_counts_mutregions_A_remake.pickle').droplevel(0, axis=1)\n",
    "repeat_counts_mutregions_B_RC = pd.read_pickle('denovo/repeat_counts_mutregions_B_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d357ef1-8f92-429e-85a2-edf1cdfda465",
   "metadata": {},
   "source": [
    "#### indel counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92770135-8870-4ed7-92a1-f9b115a7d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_indel = pd.read_csv('denovo/all_denovo_indels.csv')\n",
    "denovo_combined_indel['chrom'] = [int(chrom) if chrom not in ['X', 'Y'] else chrom for chrom in denovo_combined_indel['chrom']]\n",
    "denovo_combined_indel['REF+100'] = [get_sequence(chrom, pos, pos+101, hg38_genome) for chrom, pos in zip(denovo_combined_indel['chrom'], denovo_combined_indel['pos'])]\n",
    "denovo_combined_indel['REF-100'] = [get_sequence(chrom, pos-101, pos, hg38_genome) for chrom, pos in zip(denovo_combined_indel['chrom'], denovo_combined_indel['pos'])]\n",
    "denovo_combined_indel['indel'] = (denovo_combined_indel['ref'].str.len() > 1).replace(False, 'ins').replace(True, 'del')\n",
    "denovo_combined_indel['indel_seq'] = denovo_combined_indel['alt'].str[1:] + denovo_combined_indel['ref'].str[1:]\n",
    "denovo_combined_indel['indel_len'] = denovo_combined_indel['indel_seq'].str.len()\n",
    "\n",
    "for unit_len in range(1,7):\n",
    "    denovo_combined_indel['down_'+str(unit_len)] = denovo_combined_indel['REF+100'].str[:unit_len]\n",
    "    denovo_combined_indel['up_'+str(unit_len)] = denovo_combined_indel['REF-100'].str[-unit_len:]\n",
    "    denovo_combined_indel['repeat_seq_down_'+str(unit_len)] = [re.search('(?:' + motif + ')+', ref)[0] for ref, motif in zip(denovo_combined_indel['REF+100'], denovo_combined_indel['down_'+str(unit_len)])]\n",
    "    denovo_combined_indel['repeat_seq_up_'+str(unit_len)] = [re.search('(?:' + motif[::-1] + ')+', ref[::-1])[0] for ref, motif in zip(denovo_combined_indel['REF-100'], denovo_combined_indel['up_'+str(unit_len)])]\n",
    "    denovo_combined_indel['repeat_units_up_'+str(unit_len)] = denovo_combined_indel['repeat_seq_up_'+str(unit_len)].str.len() / unit_len\n",
    "    denovo_combined_indel['repeat_units_down_'+str(unit_len)] = denovo_combined_indel['repeat_seq_down_'+str(unit_len)].str.len() / unit_len\n",
    "    denovo_combined_indel['same_bothsides_'+str(unit_len)] = denovo_combined_indel['up_'+str(unit_len)] == denovo_combined_indel['down_'+str(unit_len)]\n",
    "    \n",
    "    # for indels in the middle of a repeat, put the total count in the 'up' category and remove the 'down' count\n",
    "    denovo_combined_indel['repeat_units_up_'+str(unit_len)] += (denovo_combined_indel['repeat_units_down_'+str(unit_len)] * denovo_combined_indel['same_bothsides_'+str(unit_len)])\n",
    "    denovo_combined_indel['repeat_units_down_'+str(unit_len)] -= (denovo_combined_indel['repeat_units_down_'+str(unit_len)] * denovo_combined_indel['same_bothsides_'+str(unit_len)])\n",
    "    denovo_combined_indel['repeat_units_down_'+str(unit_len)] = denovo_combined_indel['repeat_units_down_'+str(unit_len)].replace(0, np.nan)\n",
    "    \n",
    "    denovo_combined_indel['indel_is_rep_up_'+str(unit_len)] = [''.join(rep * int(indel_len / unit_len)) == indel_seq for rep, indel_len, indel_seq in zip(denovo_combined_indel['up_'+str(unit_len)], denovo_combined_indel['indel_len'], denovo_combined_indel['indel_seq'])]\n",
    "    denovo_combined_indel['indel_is_rep_down_'+str(unit_len)] = [''.join(rep * int(indel_len / unit_len)) == indel_seq for rep, indel_len, indel_seq in zip(denovo_combined_indel['down_'+str(unit_len)], denovo_combined_indel['indel_len'], denovo_combined_indel['indel_seq'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1030-c77e-4157-8d3d-30759379bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts = dict(); con_counts = dict(); nonexp_counts = dict()\n",
    "for unit_len in range(1,7):\n",
    "    # A>AA\n",
    "    exp_up = denovo_combined_indel.groupby(['indel', 'indel_is_rep_up_'+str(unit_len), 'indel_len', 'repeat_units_up_'+str(unit_len), 'up_'+str(unit_len)])['chrom'].count()['ins'].reindex([True], level = 0).unstack().droplevel(0)\n",
    "    exp_down = denovo_combined_indel.groupby(['indel', 'indel_is_rep_down_'+str(unit_len), 'indel_len', 'repeat_units_down_'+str(unit_len), 'down_'+str(unit_len)])['chrom'].count()['ins'].reindex([True], level = 0).unstack().droplevel(0)\n",
    "    exp_up.index.names = ['indel_len', 'repeat_units']; exp_down.index.names = ['indel_len', 'repeat_units']\n",
    "    exp_counts[unit_len] = exp_up.add(exp_down, fill_value = 0)\n",
    "    #AA>A\n",
    "    con_up = denovo_combined_indel.groupby(['indel', 'indel_is_rep_up_'+str(unit_len), 'indel_len', 'repeat_units_up_'+str(unit_len), 'up_'+str(unit_len)])['chrom'].count()['del'].reindex([True], level = 0).unstack().droplevel(0)\n",
    "    con_down = denovo_combined_indel.groupby(['indel', 'indel_is_rep_down_'+str(unit_len), 'indel_len', 'repeat_units_down_'+str(unit_len), 'down_'+str(unit_len)])['chrom'].count()['del'].reindex([True], level = 0).unstack().droplevel(0)\n",
    "    con_up.index.names = ['indel_len', 'repeat_units']; con_down.index.names = ['indel_len', 'repeat_units']\n",
    "    con_counts[unit_len] = con_up.add(con_down, fill_value = 0)\n",
    "    # AA>ABA interruptions (requires A on both sides, length is sum of both sides)\n",
    "    nonexp_counts[unit_len] = denovo_combined_indel.groupby(['indel', 'same_bothsides_'+str(unit_len), 'indel_is_rep_up_'+str(unit_len), 'indel_len', 'repeat_units_up_'+str(unit_len), 'up_'+str(unit_len)])['chrom'].count()['ins'].reindex([True], level = 0).reindex([False], level = 1).unstack().droplevel(0).droplevel(0)\n",
    "    nonexp_counts[unit_len].index.names = ['indel_len', 'repeat_units']\n",
    "exp_counts = pd.concat(exp_counts, axis=1).droplevel(0, axis=1); con_counts = pd.concat(con_counts, axis=1).droplevel(0, axis=1); nonexp_counts = pd.concat(nonexp_counts, axis=1).droplevel(0, axis=1)\n",
    "\n",
    "#BB>BAB (0-class for expansions)\n",
    "B_exp = dict()\n",
    "for unit_len in range(1,7):\n",
    "    B_exp[unit_len] = denovo_combined_indel.groupby(['indel', 'indel_is_rep_up_'+str(unit_len), 'indel_is_rep_down_'+str(unit_len), 'indel_len', 'indel_seq'])['chrom'].count()['ins'].reindex([False], level = 0).reindex([False], level = 1).droplevel(0).droplevel(0).unstack().reindex([motif for motif in exp_counts.columns if len(motif) == unit_len], axis=1)\n",
    "    B_exp[unit_len]['repeat_units'] = 0\n",
    "    B_exp[unit_len].set_index('repeat_units', append = True, inplace = True)\n",
    "B_exp = pd.concat(B_exp, axis=1).droplevel(0, axis=1)\n",
    "exp_counts = pd.concat([exp_counts, B_exp]).sort_index()\n",
    "\n",
    "# BB>B deletions (0-class for contractions)\n",
    "B_del = dict()\n",
    "B_del_counts = denovo_combined_indel.groupby(['indel', 'indel_len', 'indel_seq'])['chrom'].count()['del'].unstack().reindex([col for col in con_counts.columns], axis=1)\n",
    "for motif in con_counts.columns:\n",
    "    B_del[motif] = B_del_counts.reindex([col for col in con_counts.columns if (len(col) == len(motif)) & (col != motif)], axis=1).sum(axis=1)\n",
    "    B_del[motif] = pd.DataFrame(B_del[motif], columns = [motif])\n",
    "    B_del[motif]['repeat_units'] = 0\n",
    "    B_del[motif].set_index('repeat_units', append = True, inplace = True)\n",
    "B_del = pd.concat(B_del, axis=1).droplevel(0, axis=1)\n",
    "con_counts = pd.concat([con_counts, B_del]).sort_index()\n",
    "\n",
    "# B>BB insertions (length-independent) (0-class for non-expansions)\n",
    "B_ins = dict()\n",
    "B_ins_counts = denovo_combined_indel.groupby(['indel', 'indel_len', 'indel_seq'])['chrom'].count()['ins'].unstack().reindex([col for col in exp_counts.columns], axis=1)\n",
    "for motif in exp_counts.columns:\n",
    "    B_ins[motif] = B_ins_counts.reindex([col for col in exp_counts.columns if (len(col) == len(motif)) & (col != motif)], axis=1).sum(axis=1)\n",
    "    B_ins[motif] = pd.DataFrame(B_ins[motif], columns = [motif])\n",
    "    B_ins[motif]['repeat_units'] = 0\n",
    "    B_ins[motif].set_index('repeat_units', append = True, inplace = True)\n",
    "B_ins = pd.concat(B_ins, axis=1).droplevel(0, axis=1)\n",
    "nonexp_counts = pd.concat([nonexp_counts, B_ins]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6932d39-6979-4a0f-941c-0af453cd9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts_std = dict(); con_counts_std = dict(); nonexp_counts_std = dict()\n",
    "for repeat in exp_counts:\n",
    "    if repeat_frames_RC(repeat)[0] not in exp_counts_std.keys():\n",
    "        exp_counts_std[repeat_frames_RC(repeat)[0]] = exp_counts.reindex(repeat_frames_RC(repeat), axis=1).sum(axis=1)\n",
    "        con_counts_std[repeat_frames_RC(repeat)[0]] = con_counts.reindex(repeat_frames_RC(repeat), axis=1).sum(axis=1)\n",
    "        nonexp_counts_std[repeat_frames_RC(repeat)[0]] = nonexp_counts.reindex(repeat_frames_RC(repeat), axis=1).sum(axis=1)\n",
    "exp_counts_std = pd.concat(exp_counts_std, axis=1); con_counts_std = pd.concat(con_counts_std, axis=1); nonexp_counts_std = pd.concat(nonexp_counts_std, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f693f-de1d-4954-8b8a-5efce1fb4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts_std.to_pickle('denovo/denovo_combined_expansion_counts_all_remake.pickle')\n",
    "con_counts_std.to_pickle('denovo/denovo_combined_contraction_deletion_counts_all_remake.pickle')\n",
    "nonexp_counts_std.to_pickle('denovo/denovo_combined_nonexpansion_insertion_counts_all_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c522008-d90e-41c6-986e-c373c734f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts_std = pd.read_pickle('denovo/denovo_combined_expansion_counts_all_remake.pickle')\n",
    "con_counts_std = pd.read_pickle('denovo/denovo_combined_contraction_deletion_counts_all_remake.pickle')\n",
    "nonexp_counts_std = pd.read_pickle('denovo/denovo_combined_nonexpansion_insertion_counts_all_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208420b-1b1d-4556-939a-07c5c0a6ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts_inframe = dict(); con_counts_inframe = dict(); nonexp_counts_inframe = dict()\n",
    "for motif in exp_counts_std:\n",
    "    exp_counts_inframe[motif] = exp_counts_std[motif].loc[len(motif)]\n",
    "    con_counts_inframe[motif] = con_counts_std[motif].loc[len(motif)]\n",
    "    nonexp_counts_inframe[motif] = nonexp_counts_std[motif].loc[len(motif)]\n",
    "exp_counts_inframe = pd.concat(exp_counts_inframe, axis=1)\n",
    "con_counts_inframe = pd.concat(con_counts_inframe, axis=1)\n",
    "nonexp_counts_inframe = pd.concat(nonexp_counts_inframe, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae30af-3c5b-40bf-a94a-7335d5fcb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts_inframe.to_pickle('denovo/denovo_combined_expansion_counts_remake.pickle')\n",
    "con_counts_inframe.to_pickle('denovo/denovo_combined_contraction_deletion_counts_remake.pickle')\n",
    "nonexp_counts_inframe.to_pickle('denovo/denovo_combined_nonexpansion_insertion_counts_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5095b4-52ff-49db-b70e-0fee457d7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts_inframe = pd.read_pickle('denovo/denovo_combined_expansion_counts_remake.pickle')\n",
    "con_counts_inframe = pd.read_pickle('denovo/denovo_combined_contraction_deletion_counts_remake.pickle')\n",
    "nonexp_counts_inframe = pd.read_pickle('denovo/denovo_combined_nonexpansion_insertion_counts_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0750ef53-8552-4ec8-9044-e761c26bccc0",
   "metadata": {},
   "source": [
    "#### calculate rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c064de2-c588-41ca-a11a-895fd9bf2eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_counts_mutregions_totalbases = dict()\n",
    "repeat_counts_mutregions_totalbases['A'] = repeat_counts_mutregions_A_RC.mul(repeat_counts_mutregions_A_RC.index, axis=0) # rate per repeat unit\n",
    "repeat_counts_mutregions_totalbases['B'] = repeat_counts_mutregions_B_RC.mul(repeat_counts_mutregions_B_RC.index, axis=0)\n",
    "repeat_counts_mutregions_forexp = repeat_counts_mutregions_totalbases['A']\n",
    "repeat_counts_mutregions_forcon = repeat_counts_mutregions_totalbases['A']\n",
    "# BB>BAB, denominator is number of B bases excluding single Bs \n",
    "repeat_counts_mutregions_forexp.loc[0] = repeat_counts_mutregions_totalbases['B'][2:].sum()\n",
    "# B>BB insertions, treating as length-independent, denominator is total number of B bases\n",
    "# B>_ deletions, treating as length-independent, denominator is total number of B bases, includes fusion events (subtract later if distinguishing)\n",
    "repeat_counts_mutregions_forcon.loc[0] = repeat_counts_mutregions_totalbases['B'].sum()\n",
    "\n",
    "repeat_counts_mutregions_forexp = repeat_counts_mutregions_forexp.sort_index()\n",
    "repeat_counts_mutregions_forcon = repeat_counts_mutregions_forcon.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9e783-7aa0-4de5-828e-40c31413c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_exp_rate = (exp_counts_inframe.div(repeat_counts_mutregions_forexp.reindex(exp_counts_inframe.columns, axis=1)) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "denovo_con_rate = (con_counts_inframe.div(repeat_counts_mutregions_forcon.reindex(con_counts_inframe.columns, axis=1)) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "denovo_nonexp_rate = (nonexp_counts_inframe.div(repeat_counts_mutregions_forcon.reindex(nonexp_counts_inframe.columns, axis=1)) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca9a57-2764-4e8c-809b-39c21b05e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit_len in [1,2,3,4]:\n",
    "    current_reps = [rep for rep in denovo_exp_rate.columns if len(rep) == unit_len]\n",
    "    denovo_exp_rate['unit_'+str(unit_len)] = (exp_counts_inframe[current_reps].sum(axis=1) / repeat_counts_mutregions_forexp[current_reps].sum(axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "    denovo_con_rate['unit_'+str(unit_len)] = (con_counts_inframe[current_reps].sum(axis=1) / repeat_counts_mutregions_forcon[current_reps].sum(axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "    denovo_nonexp_rate['unit_'+str(unit_len)] = (nonexp_counts_inframe[current_reps].sum(axis=1) / repeat_counts_mutregions_forcon[current_reps].sum(axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e37dd3-a061-4ea9-bdb1-60e61ab1285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_exp_rate.to_pickle('denovo/denovo_exp_rate_remake.pickle')\n",
    "denovo_con_rate.to_pickle('denovo/denovo_con_rate_remake.pickle')\n",
    "denovo_nonexp_rate.to_pickle('denovo/denovo_nonexp_rate_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71e16a-4080-4847-9fb2-53a99dd5183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_exp_rate = pd.read_pickle('denovo/denovo_exp_rate_remake.pickle')\n",
    "denovo_con_rate = pd.read_pickle('denovo/denovo_con_rate_remake.pickle')\n",
    "denovo_nonexp_rate = pd.read_pickle('denovo/denovo_nonexp_rate_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f55a17-a574-48c5-a1e1-168b8a009534",
   "metadata": {},
   "source": [
    "#### Poisson random sampling for indel rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e9a0f-b3ae-48bf-8592-e1f52273f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_exp_rate_poisson = dict()\n",
    "denovo_con_rate_poisson = dict()\n",
    "denovo_nonexp_rate_poisson = dict()\n",
    "for i in range(200):\n",
    "    denovo_exp_rate_poisson[i] = (exp_counts_inframe.fillna(0).apply(lambda x: np.random.poisson(x)) / repeat_counts_mutregions_forexp.reindex(exp_counts_inframe.columns, axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "    denovo_con_rate_poisson[i] = (con_counts_inframe.fillna(0).apply(lambda x: np.random.poisson(x)) / repeat_counts_mutregions_forcon.reindex(con_counts_inframe.columns, axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "    denovo_nonexp_rate_poisson[i] = (nonexp_counts_inframe.fillna(0).apply(lambda x: np.random.poisson(x)) / repeat_counts_mutregions_forcon.reindex(nonexp_counts_inframe.columns, axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "\n",
    "denovo_exp_rate_poisson = pd.concat(denovo_exp_rate_poisson)\n",
    "denovo_con_rate_poisson = pd.concat(denovo_con_rate_poisson)\n",
    "denovo_nonexp_rate_poisson = pd.concat(denovo_nonexp_rate_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833ca2a-c332-4c0b-8fea-265346248486",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_exp_rate_poisson_units = dict()\n",
    "denovo_con_rate_poisson_units = dict()\n",
    "denovo_nonexp_rate_poisson_units = dict()\n",
    "for unit_len in [1,2,3,4]:\n",
    "    for i in range(200):\n",
    "        current_reps = [rep for rep in denovo_exp_rate.columns if len(rep) == unit_len]\n",
    "        denovo_exp_rate_poisson_units[i] = (exp_counts_inframe[current_reps].sum(axis=1).fillna(0).apply(lambda x: np.random.poisson(x)) / repeat_counts_mutregions_forexp[current_reps].sum(axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "        denovo_con_rate_poisson_units[i] = (con_counts_inframe[current_reps].sum(axis=1).fillna(0).apply(lambda x: np.random.poisson(x)) / repeat_counts_mutregions_forcon[current_reps].sum(axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "        denovo_nonexp_rate_poisson_units[i] = (nonexp_counts_inframe[current_reps].sum(axis=1).fillna(0).apply(lambda x: np.random.poisson(x)) / repeat_counts_mutregions_forcon[current_reps].sum(axis=1) / denovo_n_genomes_indel).dropna(how = 'all', axis=0)\n",
    "    denovo_exp_rate_poisson['unit_'+str(unit_len)] = pd.concat(denovo_exp_rate_poisson_units, axis=0).replace(0, np.nan)\n",
    "    denovo_con_rate_poisson['unit_'+str(unit_len)] = pd.concat(denovo_con_rate_poisson_units, axis=0).replace(0, np.nan)\n",
    "    denovo_nonexp_rate_poisson['unit_'+str(unit_len)] = pd.concat(denovo_nonexp_rate_poisson_units, axis=0).replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5e127-ab86-47ee-a1fb-fafdb5a97433",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_exp_rate_poisson.to_pickle('denovo/denovo_exp_rate_poisson_remake.pickle')\n",
    "denovo_con_rate_poisson.to_pickle('denovo/denovo_con_rate_poisson_remake.pickle')\n",
    "denovo_nonexp_rate_poisson.to_pickle('denovo/denovo_nonexp_rate_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b288d8-393d-4768-b2c9-1a9c5b1078d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_exp_rate_poisson = pd.read_pickle('denovo/denovo_exp_rate_poisson_remake.pickle')\n",
    "denovo_con_rate_poisson = pd.read_pickle('denovo/denovo_con_rate_poisson_remake.pickle')\n",
    "denovo_nonexp_rate_poisson = pd.read_pickle('denovo/denovo_nonexp_rate_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c93ca4d-39d5-40b2-a675-ab4aa31c5f09",
   "metadata": {},
   "source": [
    "### Insertion/deletion size per event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab985ec8-07eb-4d79-8e70-4e166e39247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_indel['indel_len_dir'] = [nt if indel == 'ins' else -nt for nt, indel in zip(denovo_combined_indel['indel_len'], denovo_combined_indel['indel'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20489b14-7b47-4a76-8272-cf73da8ec9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_fraction_of_events_per_length = dict()\n",
    "unit_fraction_of_events_per_length[1] = denovo_combined_indel.groupby(['repeat_units_down_1', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).div(denovo_combined_indel.groupby(['repeat_units_down_1', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).sum(axis=1), axis=0) \n",
    "unit_fraction_of_events_per_length[2] = denovo_combined_indel.groupby(['repeat_units_down_2', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).div(denovo_combined_indel.groupby(['repeat_units_down_2', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).sum(axis=1), axis=0)\n",
    "unit_fraction_of_events_per_length[3] = denovo_combined_indel.groupby(['repeat_units_down_3', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).div(denovo_combined_indel.groupby(['repeat_units_down_3', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).sum(axis=1), axis=0)\n",
    "unit_fraction_of_events_per_length[4] = denovo_combined_indel.groupby(['repeat_units_down_4', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).div(denovo_combined_indel.groupby(['repeat_units_down_4', 'indel_len_dir'])['chrom'].count().unstack().fillna(0).sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16dc24-1266-4a08-86ce-51a4f8458f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S4 (top)\n",
    "fig = make_subplots(rows = 4, cols = 1, vertical_spacing = 0.015, shared_xaxes = True, row_titles = ['unit=1', 'unit=2', 'unit=3', 'unit=4'], x_title = 'repeat tract length (units)', y_title = 'fraction of events per length bin')\n",
    "for unit_len in range(1,5):\n",
    "    for inslen in [1,2,3,4]:\n",
    "        fig.add_trace(go.Bar(x = unit_fraction_of_events_per_length[unit_len].index, y = unit_fraction_of_events_per_length[unit_len][inslen], name = str(np.abs(inslen)), legendgroup = str(np.abs(inslen)), showlegend = True if unit_len == 1 else False), row = unit_len, col = 1)\n",
    "    fig.add_trace(go.Bar(x = unit_fraction_of_events_per_length[unit_len].index, y = unit_fraction_of_events_per_length[unit_len][[col for col in unit_fraction_of_events_per_length[unit_len].columns if col > 4]].sum(axis=1), name = '>4', legendgroup = 'other', showlegend = True if unit_len == 1 else False), row = unit_len, col = 1)\n",
    "    for inslen in [-1,-2,-3,-4]:\n",
    "        fig.add_trace(go.Bar(x = unit_fraction_of_events_per_length[unit_len].index, y = -unit_fraction_of_events_per_length[unit_len][inslen], name = str(np.abs(inslen)), legendgroup = str(np.abs(inslen)), showlegend = False), row = unit_len, col = 1)\n",
    "    fig.add_trace(go.Bar(x = unit_fraction_of_events_per_length[unit_len].index, y = - unit_fraction_of_events_per_length[unit_len][[col for col in unit_fraction_of_events_per_length[unit_len].columns if col < -4]].sum(axis=1), name = '>4', legendgroup = 'other', showlegend = False), row = unit_len, col = 1)\n",
    "    fig.update_xaxes(range = [0.5,10.5], dtick = 1, row = unit_len, col = 1)\n",
    "fig.update_yaxes(range = [-1,1], tickvals = [-0.5, 0, 0.5])\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 14), height = 400, width = 600, title = 'de novo', colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:5], legend_title_text='nt added', margin={'t':30,'l':80,'b':60,'r':20})\n",
    "fig.update_layout(barmode = 'relative')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a35ba-6d00-46c7-945e-2b6f0a135f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/figS4a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74592d-5af9-4224-81a6-998964ea0c09",
   "metadata": {},
   "source": [
    "## Calculate substitution context rates for trinucleotide repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f087969-ab99-4b05-af06-d69cceb0f92b",
   "metadata": {},
   "source": [
    "#### Count mutations, checking each triplet frame for repeat status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590dc04-fb45-484d-8249-529687b85939",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_tri_context(seq):\n",
    "    trisplit = re.findall('.'*3, seq)\n",
    "    if trisplit[0] == trisplit[1]:\n",
    "        if trisplit[1] == trisplit[2]:\n",
    "            return 'AAA', repeat_frames_RC(trisplit[1])[0]\n",
    "        else:\n",
    "            return 'AAB', repeat_frames_RC(trisplit[1])[0]\n",
    "    else:\n",
    "        if trisplit[1] == trisplit[2]:\n",
    "            return 'BAA', repeat_frames_RC(trisplit[1])[0]\n",
    "        else:\n",
    "            return 'BAB', repeat_frames_RC(trisplit[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425e120-c1c3-432d-b2ca-89aaf16bf7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9-mer context in three frames -> 11nt context needed\n",
    "denovo_combined_snv['11nt'] = [get_sequence(chrom, pos-6, pos+5, hg38_genome) for chrom, pos in zip(denovo_combined_snv['chrom'], denovo_combined_snv['pos'])]\n",
    "denovo_combined_snv['11nt_AB_1'] = [check_tri_context(seq) for seq in denovo_combined_snv['11nt']]\n",
    "denovo_combined_snv['11nt_AB_2'] = [check_tri_context(seq[1:]) for seq in denovo_combined_snv['11nt']]\n",
    "denovo_combined_snv['11nt_AB_3'] = [check_tri_context(seq[2:]) for seq in denovo_combined_snv['11nt']]\n",
    "\n",
    "denovo_triplet_context_count = denovo_combined_snv.groupby(['11nt_AB_1'])['pos'].count().add(denovo_combined_snv.groupby(['11nt_AB_2'])['pos'].count(), fill_value = 0).add(denovo_combined_snv.groupby(['11nt_AB_3'])['pos'].count(), fill_value = 0)\n",
    "denovo_triplet_context_count.index = pd.MultiIndex.from_tuples(denovo_triplet_context_count.index)\n",
    "denovo_triplet_context_count = denovo_triplet_context_count.unstack().transpose()\n",
    "denovo_triplet_context_count['AAB'] = denovo_triplet_context_count['AAB'] + denovo_triplet_context_count['BAA']\n",
    "del denovo_triplet_context_count['BAA']\n",
    "denovo_triplet_context_count.columns = ['Afission', 'Acontraction', 'A10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84288589-7696-4f14-ba31-6e486be6368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_snv['11nt_alt'] = [el[0:5]+alt+el[6:] for el, alt in zip(denovo_combined_snv['11nt'], denovo_combined_snv['alt'])]\n",
    "denovo_combined_snv['11nt_alt_AB_1'] = [check_tri_context(seq) for seq in denovo_combined_snv['11nt_alt']]\n",
    "denovo_combined_snv['11nt_alt_AB_2'] = [check_tri_context(seq[1:]) for seq in denovo_combined_snv['11nt_alt']]\n",
    "denovo_combined_snv['11nt_alt_AB_3'] = [check_tri_context(seq[2:]) for seq in denovo_combined_snv['11nt_alt']]\n",
    "\n",
    "denovo_triplet_context_count_alt = denovo_combined_snv.groupby(['11nt_alt_AB_1'])['pos'].count().add(denovo_combined_snv.groupby(['11nt_alt_AB_2'])['pos'].count(), fill_value = 0).add(denovo_combined_snv.groupby(['11nt_alt_AB_3'])['pos'].count(), fill_value = 0)\n",
    "denovo_triplet_context_count_alt.index = pd.MultiIndex.from_tuples(denovo_triplet_context_count_alt.index)\n",
    "denovo_triplet_context_count_alt = denovo_triplet_context_count_alt.unstack().transpose()\n",
    "denovo_triplet_context_count_alt['AAB'] = denovo_triplet_context_count_alt['AAB'] + denovo_triplet_context_count_alt['BAA']\n",
    "del denovo_triplet_context_count_alt['BAA']\n",
    "denovo_triplet_context_count_alt.columns = ['Afusion', 'Aexpansion', 'A01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605b401-58b9-4683-a493-5ab2da3b92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_triplet_context_count_all = pd.concat([denovo_triplet_context_count, denovo_triplet_context_count_alt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe5afd-4c4c-4682-8761-c305beb5c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_triplet_context_count_all.to_pickle('denovo/denovo_triplet_context_count_all_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351567d-99b1-424b-b1d6-11921b041514",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_triplet_context_count_all = pd.read_pickle('denovo/denovo_triplet_context_count_all_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5c5ac3-f7c9-4fe6-92e0-4f3ee906fdf9",
   "metadata": {},
   "source": [
    "#### Count all 9-mer contexts in the sequenceable genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0cc60-1b8b-4ed6-afc6-f92afc7a6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "nine_counts_mutregions = dict()\n",
    "for chrom, pos in count_by_100kb.index:\n",
    "    seq = hg38_genome[chrom][int(pos):int(pos+1e5)]\n",
    "    nine_counts_mutregions[(chrom, pos)] = pd.Series(re.findall('.........', seq) + re.findall('.........', seq[1:]) + re.findall('.........', seq[2:]) + re.findall('.........', seq[3:]) + re.findall('.........', seq[4:]) + re.findall('.........', seq[5:]) + re.findall('.........', seq[6:]) + re.findall('.........', seq[7:]) + re.findall('.........', seq[8:]), dtype = 'object').value_counts()\n",
    "    print ('\\r' + 'finished chr'+str(chrom) + ' '+str(pos), end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1cbea-ede1-4fc0-9357-593583e7b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "nine_counts_mutregions_sum = pd.Series(dtype = 'int64')\n",
    "counter = 0\n",
    "for part in list(nine_counts_mutregions.keys()):\n",
    "    nine_counts_mutregions_sum = nine_counts_mutregions_sum.add(nine_counts_mutregions[part], fill_value = 0)\n",
    "    counter +=1; print('\\r' + str(counter), end = ' ')\n",
    "nine_counts_mutregions_sum.to_pickle('denovo/ninelet_totals_hg38_mutregions_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a4ea2-a199-461b-acd3-6b4637f217db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nine_counts_mutregions_sum = pd.read_pickle('denovo/ninelet_totals_hg38_mutregions_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4aa27a-256b-475d-a4f1-f76e4d14502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nine_counts_mutregions_sum_triindex = nine_counts_mutregions_sum.copy()\n",
    "nine_counts_mutregions_sum_triindex.index = pd.MultiIndex.from_tuples([re.findall('...', seq) for seq in nine_counts_mutregions_sum.index])\n",
    "nine_counts_mutregions_sum_triindex = nine_counts_mutregions_sum_triindex.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685393d1-de72-438a-b08b-2a940ebc2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nine_counts_triplet_context_count_all = pd.DataFrame(0, index = denovo_triplet_context_count_all.index, columns = denovo_triplet_context_count_all.columns)\n",
    "for repeat in nine_counts_triplet_context_count_all.index:\n",
    "    for motif in repeat_frames_RC(repeat):\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'Afission'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] == motif) & (nine_counts_mutregions_sum_triindex['level_1'] == motif) & (nine_counts_mutregions_sum_triindex['level_2'] == motif)][0].sum()\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'Acontraction'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] == motif) & (nine_counts_mutregions_sum_triindex['level_1'] == motif) & (nine_counts_mutregions_sum_triindex['level_2'] != motif)][0].sum()\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'Acontraction'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] != motif) & (nine_counts_mutregions_sum_triindex['level_1'] == motif) & (nine_counts_mutregions_sum_triindex['level_2'] == motif)][0].sum()\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'A10'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] != motif) & (nine_counts_mutregions_sum_triindex['level_1'] == motif) & (nine_counts_mutregions_sum_triindex['level_2'] != motif)][0].sum()\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'Afusion'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] == motif) & (nine_counts_mutregions_sum_triindex['level_1'] != motif) & (nine_counts_mutregions_sum_triindex['level_2'] == motif)][0].sum()\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'Aexpansion'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] == motif) & (nine_counts_mutregions_sum_triindex['level_1'] != motif) & (nine_counts_mutregions_sum_triindex['level_2'] != motif)][0].sum()\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'Aexpansion'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] != motif) & (nine_counts_mutregions_sum_triindex['level_1'] != motif) & (nine_counts_mutregions_sum_triindex['level_2'] == motif)][0].sum()\n",
    "        nine_counts_triplet_context_count_all.loc[repeat, 'A01'] += nine_counts_mutregions_sum_triindex.loc[(nine_counts_mutregions_sum_triindex['level_0'] != motif) & (nine_counts_mutregions_sum_triindex['level_1'] != motif) & (nine_counts_mutregions_sum_triindex['level_2'] != motif)][0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72b85d-b212-4c8e-b705-5ca65776f2f1",
   "metadata": {},
   "source": [
    "#### Calculate rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c35b5-259c-4f02-988e-a9966f5dc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_substitution_context_rate = denovo_triplet_context_count_all /3 / nine_counts_triplet_context_count_all / denovo_n_genomes_snv\n",
    "#denovo_substitution_context_rate.loc['A'] = denovo_mut_freq_AB\n",
    "#denovo_substitution_context_rate.loc['C'] = denovo_mut_freq_CD\n",
    "denovo_substitution_context_rate.to_pickle('denovo/denovo_mut_freq_triplets_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9aeb0-8117-435c-9b89-038fb0f4260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_substitution_context_rate = pd.read_pickle('denovo/denovo_mut_freq_triplets_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66136bf4-7b21-483e-a6d0-244bf42d6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_triplets_poisson = dict()\n",
    "for i in range(200):\n",
    "    denovo_mut_freq_triplets_poisson[i] = (denovo_triplet_context_count_all /3).apply(np.random.poisson) / nine_counts_triplet_context_count_all / denovo_n_genomes_snv\n",
    "denovo_mut_freq_triplets_poisson = pd.concat(denovo_mut_freq_triplets_poisson)\n",
    "denovo_mut_freq_triplets_poisson.to_pickle('denovo/denovo_mut_freq_triplets_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f536f-3f25-42d7-b4e8-e1af463fb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put triplets and As into one file\n",
    "denovo_mut_freq_triplets_poisson = pd.read_pickle('denovo/denovo_mut_freq_triplets_poisson_remake.pickle')\n",
    "denovo_mut_freq_AB_poisson = pd.read_pickle('denovo/denovo_mut_freq_AB_poisson.pickle')\n",
    "denovo_mut_freq_AB_poisson = denovo_mut_freq_AB_poisson.transpose()\n",
    "denovo_mut_freq_AB_poisson.index = pd.MultiIndex.from_tuples([(i, 'A') for i in denovo_mut_freq_AB_poisson.index])\n",
    "denovo_mut_freq_triplets_poisson = pd.concat([denovo_mut_freq_triplets_poisson, denovo_mut_freq_AB_poisson], axis=0).sort_index()\n",
    "denovo_mut_freq_triplets_poisson.to_pickle('denovo/denovo_mut_freq_triplets_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075918e-a1ef-43b6-b2a0-3b3b12c65253",
   "metadata": {},
   "source": [
    "## Calculate substitution context rates for dinucleotide repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95dc840-4cc3-4569-ae25-3d0467848b72",
   "metadata": {},
   "source": [
    "#### Count mutations, checking each triplet frame for repeat status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296afc0d-5aff-4b1d-ab85-3c0a07fed59f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_di_context(seq):\n",
    "    displit = re.findall('.'*2, seq)\n",
    "    if displit[0] == displit[1]:\n",
    "        if displit[1] == displit[2]:\n",
    "            return 'AAA', repeat_frames_RC(displit[1])[0]\n",
    "        else:\n",
    "            return 'AAB', repeat_frames_RC(displit[1])[0]\n",
    "    else:\n",
    "        if displit[1] == displit[2]:\n",
    "            return 'BAA', repeat_frames_RC(displit[1])[0]\n",
    "        else:\n",
    "            return 'BAB', repeat_frames_RC(displit[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0f660-6cb8-4171-ae59-44b0f0d36d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-mer context in two frames -> 7nt context needed\n",
    "denovo_combined_snv['7nt'] = [get_sequence(chrom, pos-4, pos+3, hg38_genome) for chrom, pos in zip(denovo_combined_snv['chrom'], denovo_combined_snv['pos'])]\n",
    "denovo_combined_snv['7nt_AB_1'] = [check_di_context(seq) for seq in denovo_combined_snv['7nt']]\n",
    "denovo_combined_snv['7nt_AB_2'] = [check_di_context(seq[1:]) for seq in denovo_combined_snv['7nt']]\n",
    "\n",
    "denovo_dinuc_context_count = denovo_combined_snv.groupby(['7nt_AB_1'])['pos'].count().add(denovo_combined_snv.groupby(['7nt_AB_2'])['pos'].count(), fill_value = 0)\n",
    "denovo_dinuc_context_count.index = pd.MultiIndex.from_tuples(denovo_dinuc_context_count.index)\n",
    "denovo_dinuc_context_count = denovo_dinuc_context_count.unstack().transpose()\n",
    "denovo_dinuc_context_count['AAB'] = denovo_dinuc_context_count['AAB'] + denovo_dinuc_context_count['BAA']\n",
    "del denovo_dinuc_context_count['BAA']\n",
    "denovo_dinuc_context_count.columns = ['Afission', 'Acontraction', 'A10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de2f09-d35f-49a7-b2ff-9eb1420654ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined_snv['7nt_alt'] = [sev[0:4]+alt+sev[5:] for sev, alt in zip(denovo_combined_snv['7nt'], denovo_combined_snv['alt'])]\n",
    "denovo_combined_snv['7nt_alt_AB_1'] = [check_di_context(seq) for seq in denovo_combined_snv['7nt_alt']]\n",
    "denovo_combined_snv['7nt_alt_AB_2'] = [check_di_context(seq[1:]) for seq in denovo_combined_snv['7nt_alt']]\n",
    "\n",
    "denovo_dinuc_context_count_alt = denovo_combined_snv.groupby(['7nt_alt_AB_1'])['pos'].count().add(denovo_combined_snv.groupby(['7nt_alt_AB_2'])['pos'].count(), fill_value = 0)\n",
    "denovo_dinuc_context_count_alt.index = pd.MultiIndex.from_tuples(denovo_dinuc_context_count_alt.index)\n",
    "denovo_dinuc_context_count_alt = denovo_dinuc_context_count_alt.unstack().transpose()\n",
    "denovo_dinuc_context_count_alt['AAB'] = denovo_dinuc_context_count_alt['AAB'] + denovo_dinuc_context_count_alt['BAA']\n",
    "del denovo_dinuc_context_count_alt['BAA']\n",
    "denovo_dinuc_context_count_alt.columns = ['Afusion', 'Aexpansion', 'A01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689a28-319e-45c0-85f9-347134a59bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_dinuc_context_count_all = pd.concat([denovo_dinuc_context_count, denovo_dinuc_context_count_alt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b447c41-d33b-43cd-9768-d72f4e5e9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_dinuc_context_count_all.to_pickle('denovo/denovo_dinuc_context_count_all_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24323960-abcd-4fdc-988d-d93769ccc905",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_dinuc_context_count_all = pd.read_pickle('denovo/denovo_dinuc_context_count_all_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db6a16-2121-47c3-aadc-f1741f64595c",
   "metadata": {},
   "source": [
    "#### Count all 6-mer contexts in the sequenceable genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da952ec6-e374-4ed3-81c5-13537648501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_counts_mutregions = dict()\n",
    "for chrom, pos in count_by_100kb.index:\n",
    "    seq = hg38_genome[chrom][int(pos):int(pos+1e5)]\n",
    "    six_counts_mutregions[(chrom, pos)] = pd.Series(re.findall('......', seq) + re.findall('......', seq[1:]) + re.findall('......', seq[2:]) + re.findall('......', seq[3:]) + re.findall('......', seq[4:]) + re.findall('......', seq[5:]), dtype = 'object').value_counts()\n",
    "    print ('\\r' + 'finished chr'+str(chrom) + ' '+str(pos), end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cddb0-9f96-405c-9156-390b6eed174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_counts_mutregions_sum = pd.Series(dtype = 'int64')\n",
    "counter = 0\n",
    "for part in list(six_counts_mutregions.keys()):\n",
    "    six_counts_mutregions_sum = six_counts_mutregions_sum.add(six_counts_mutregions[part], fill_value = 0)\n",
    "    counter +=1; print('\\r' + str(counter), end = ' ')\n",
    "six_counts_mutregions_sum.to_pickle('denovo/sixlet_totals_hg38_mutregions_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90814c8e-f96a-461d-8f41-6ee63714fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_counts_mutregions_sum = pd.read_pickle('denovo/sixlet_totals_hg38_mutregions_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee47fa-4982-4fd8-bd99-a9e27d2871ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_counts_mutregions_sum_diindex = six_counts_mutregions_sum.copy()\n",
    "six_counts_mutregions_sum_diindex.index = pd.MultiIndex.from_tuples([re.findall('..', seq) for seq in six_counts_mutregions_sum.index])\n",
    "six_counts_mutregions_sum_diindex = six_counts_mutregions_sum_diindex.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e393d29-d3a5-45c2-a480-c249c61c3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_counts_dinuc_context_count_all = pd.DataFrame(0, index = denovo_dinuc_context_count_all.index, columns = denovo_dinuc_context_count_all.columns)\n",
    "for repeat in six_counts_dinuc_context_count_all.index:\n",
    "    for motif in repeat_frames_RC(repeat):\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'Afission'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] == motif) & (six_counts_mutregions_sum_diindex['level_1'] == motif) & (six_counts_mutregions_sum_diindex['level_2'] == motif)][0].sum()\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'Acontraction'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] == motif) & (six_counts_mutregions_sum_diindex['level_1'] == motif) & (six_counts_mutregions_sum_diindex['level_2'] != motif)][0].sum()\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'Acontraction'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] != motif) & (six_counts_mutregions_sum_diindex['level_1'] == motif) & (six_counts_mutregions_sum_diindex['level_2'] == motif)][0].sum()\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'A10'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] != motif) & (six_counts_mutregions_sum_diindex['level_1'] == motif) & (six_counts_mutregions_sum_diindex['level_2'] != motif)][0].sum()\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'Afusion'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] == motif) & (six_counts_mutregions_sum_diindex['level_1'] != motif) & (six_counts_mutregions_sum_diindex['level_2'] == motif)][0].sum()\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'Aexpansion'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] == motif) & (six_counts_mutregions_sum_diindex['level_1'] != motif) & (six_counts_mutregions_sum_diindex['level_2'] != motif)][0].sum()\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'Aexpansion'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] != motif) & (six_counts_mutregions_sum_diindex['level_1'] != motif) & (six_counts_mutregions_sum_diindex['level_2'] == motif)][0].sum()\n",
    "        six_counts_dinuc_context_count_all.loc[repeat, 'A01'] += six_counts_mutregions_sum_diindex.loc[(six_counts_mutregions_sum_diindex['level_0'] != motif) & (six_counts_mutregions_sum_diindex['level_1'] != motif) & (six_counts_mutregions_sum_diindex['level_2'] != motif)][0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dae6a-c706-406d-b9ae-45aba0464262",
   "metadata": {},
   "source": [
    "#### Calculate rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c9f5d-c7ae-46de-84fb-fbe2a00a9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_substitution_context_rate_dinuc = denovo_dinuc_context_count_all /2 / six_counts_dinuc_context_count_all / denovo_n_genomes_snv\n",
    "denovo_substitution_context_rate_dinuc.loc[['AC', 'AG', 'AT', 'CG']].to_pickle('denovo/denovo_mut_freq_dinuc_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40934582-4823-41ba-8c76-a8b764ec9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_substitution_context_rate = pd.concat([denovo_substitution_context_rate, denovo_substitution_context_rate_dinuc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef135ca0-5747-4eeb-a778-7c86767e9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_substitution_context_rate.to_pickle('denovo/denovo_mut_freq_triplets_remake.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e4780-a035-4f93-a1a4-7ad8640390eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_dinuc_poisson = dict()\n",
    "for i in range(200):\n",
    "    denovo_mut_freq_dinuc_poisson[i] = (denovo_dinuc_context_count_all.dropna(axis=0) /2).apply(np.random.poisson) / six_counts_dinuc_context_count_all / denovo_n_genomes_snv\n",
    "denovo_mut_freq_dinuc_poisson = pd.concat(denovo_mut_freq_dinuc_poisson).dropna(axis=0)\n",
    "denovo_mut_freq_dinuc_poisson.to_pickle('denovo/denovo_mut_freq_dinuc_poisson_remake.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc5040-5a2e-40cd-a9fa-370197f6f26d",
   "metadata": {},
   "source": [
    "## put mono-, di- and trinucleotides into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868659e-ef7a-4b59-a46d-44a6ac5f1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_triplets = pd.read_pickle('denovo/denovo_mut_freq_triplets_remake.pickle')\n",
    "denovo_mut_freq_dinuc = pd.read_pickle('denovo/denovo_mut_freq_dinuc_remake.pickle')\n",
    "denovo_mut_freq_AB = pd.DataFrame(pd.read_pickle('denovo/denovo_mut_freq_AB_remake.pickle'), columns = ['A']).T\n",
    "denovo_mut_freq_CD = pd.DataFrame(pd.read_pickle('denovo/denovo_mut_freq_CD_remake.pickle'), columns = ['C']).T\n",
    "denovo_mut_freq_all = pd.concat([denovo_mut_freq_triplets, denovo_mut_freq_dinuc, denovo_mut_freq_AB, denovo_mut_freq_CD], axis=0).sort_index()\n",
    "\n",
    "denovo_mut_freq_all.to_pickle('denovo/denovo_mut_freq_all.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43290c3-fd41-4b05-9980-40e6be7e3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poisson\n",
    "denovo_mut_freq_triplets_poisson = pd.read_pickle('denovo/denovo_mut_freq_triplets_poisson_remake.pickle')\n",
    "denovo_mut_freq_AB_poisson = pd.read_pickle('denovo/denovo_mut_freq_AB_poisson_remake.pickle').T\n",
    "denovo_mut_freq_AB_poisson.index = pd.MultiIndex.from_tuples([(i, 'A') for i in denovo_mut_freq_AB_poisson.index])\n",
    "denovo_mut_freq_CD_poisson = pd.read_pickle('denovo/denovo_mut_freq_CD_poisson_remake.pickle').T\n",
    "denovo_mut_freq_CD_poisson.index = pd.MultiIndex.from_tuples([(i, 'C') for i in denovo_mut_freq_CD_poisson.index])\n",
    "denovo_mut_freq_all_poisson = pd.concat([denovo_mut_freq_triplets_poisson, denovo_mut_freq_dinuc_poisson, denovo_mut_freq_AB_poisson, denovo_mut_freq_CD_poisson], axis=0).sort_index()\n",
    "\n",
    "denovo_mut_freq_all_poisson.to_pickle('denovo/denovo_mut_freq_all_poisson.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4c4aa-b80d-4807-9b41-11784440fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_mut_freq_all = pd.read_pickle('denovo/denovo_mut_freq_all.pickle')\n",
    "denovo_mut_freq_all_poisson = pd.read_pickle('denovo/denovo_mut_freq_all_poisson.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573cd3e3-4c86-4675-9e4c-b2f0c76aa4d2",
   "metadata": {},
   "source": [
    "#### mu and nu rates\n",
    "- overall A>B and B>A rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db840c72-a0ad-4e53-8f50-37fde6b463ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_all = dict(); nu_all = dict()\n",
    "mu_all[1] = dict(); nu_all[1] = dict()\n",
    "mu_all[1]['A'] = rates_mu_nu['B>A']\n",
    "mu_all[1]['C'] = rates_mu_nu_CD['D>C']\n",
    "mu_all[2] = denovo_dinuc_context_count_all[['Afusion', 'Aexpansion', 'A01']].sum(axis=1) / six_counts_dinuc_context_count_all[['Afusion', 'Aexpansion', 'A01']].sum(axis=1) / denovo_n_genomes_snv\n",
    "mu_all[3] = denovo_triplet_context_count_all[['Afusion', 'Aexpansion', 'A01']].sum(axis=1) / nine_counts_triplet_context_count_all[['Afusion', 'Aexpansion', 'A01']].sum(axis=1) / denovo_n_genomes_snv\n",
    "nu_all[1]['A'] = rates_mu_nu['A>B']\n",
    "nu_all[1]['C'] = rates_mu_nu_CD['C>D']\n",
    "nu_all[2] = denovo_dinuc_context_count_all[['Afission', 'Acontraction', 'A10']].sum(axis=1) / six_counts_dinuc_context_count_all[['Afission', 'Acontraction', 'A10']].sum(axis=1) / denovo_n_genomes_snv\n",
    "nu_all[3] = denovo_triplet_context_count_all[['Afission', 'Acontraction', 'A10']].sum(axis=1) / nine_counts_triplet_context_count_all[['Afission', 'Acontraction', 'A10']].sum(axis=1) / denovo_n_genomes_snv\n",
    "\n",
    "mu_nu_all = dict()\n",
    "mu_nu_all['mu'] = pd.DataFrame(mu_all)\n",
    "mu_nu_all['nu'] = pd.DataFrame(nu_all)\n",
    "mu_nu_all = pd.concat(mu_nu_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6681a5-12d9-4e9e-a054-7f52ea55037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_nu_all.to_pickle('denovo/mu_nu_1-3.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324695f-c992-4005-a4ee-ad2cf1a4687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_nu_all = pd.read_pickle('denovo/mu_nu_1-3.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6e202-dce2-484f-89c8-3b3957119b04",
   "metadata": {},
   "source": [
    "# deCODE instability rate measurement\n",
    "- Download supplementary data from Kristmundsdottir et al 2023 (see manuscript for DOI), extract in folder named 'decode'\n",
    "- https://github.com/DecodeGenetics/mDNM_analysisAndData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9a70a-6f52-4d41-b9a6-5d0c72248f71",
   "metadata": {},
   "source": [
    "### Process original data file\n",
    "- used to calculate denominator for rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b1120-787b-4b29-80ec-3e667c0202d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = pd.read_csv('decode/mDNM_analysisAndData-main/mutRateDataAll.gz', compression = 'gzip', sep = '\\t', skiprows = 0)\n",
    "decode = decode.reset_index()\n",
    "decode.columns = ['chrom', 'start', 'end', 'motif', 'missing', 'DNMs', 'Correct', 'geneticDiversity', 'motifLength', 'refLen', 'purity', 'GCcontentInMotif']\n",
    "decode['chrom'] = [chrom[3:] if chrom[3:] in ['X', 'Y'] else int(chrom[3:]) for chrom in decode['chrom']]\n",
    "decode['motif_std'] = [repeat_frames_RC(rep)[0] for rep in decode['motif']]\n",
    "decode['seq'] = [get_sequence(chrom, start, end, hg38_genome) for chrom, start, end in zip(decode['chrom'], decode['start'], decode['end'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddfbb8-e4ea-4a38-aa7a-2a95c5d20a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find longest pure repeat in sequence\n",
    "decode['seq+-10'] = [get_sequence(chrom, start-10, end+10, hg38_genome) for chrom, start, end in zip(decode['chrom'], decode['start'], decode['end'])]\n",
    "decode['max_pure_length'] = [max([len(rep) for rep in re.findall('(?:' + motif + ')+', seq)]) for motif, seq in zip(decode['motif'], decode['seq+-10'])]\n",
    "decode['max_pure_units'] = decode['max_pure_length'] / decode['motifLength']\n",
    "decode['ref_units'] = decode['refLen'] / decode['motifLength']\n",
    "decode['ref_units_int'] = decode['ref_units'] //1\n",
    "decode.to_pickle('decode/mutRateDataAll.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8a622-1b24-41d2-8805-546b88aac431",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = pd.read_pickle('decode/mutRateDataAll.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a22b27-1b5f-414a-bea4-29806fa74dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loci where popSTR-listed reference repeat length is a perfect repeat of the appropriate motif\n",
    "decode.loc[decode['ref_units_int'] == decode['max_pure_units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff879dc-bf3a-4d76-9296-d4d04b120108",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decode), len(decode.loc[decode['ref_units_int'] == decode['max_pure_units']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d0e34-466c-4421-b51c-67e6c373ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Correct' column specifies number of families where the locus was sequenced with sufficient quality\n",
    "# denominator by motif and reference length for rate calculations\n",
    "# Because parental genotypes are not available for all loci (just for mutated loci), the denominator is approximated using this distribution of reference length counts.\n",
    "motif_counts_pure_units = decode.loc[decode['ref_units_int'] == decode['max_pure_units']].groupby(['ref_units_int', 'motif_std'])['Correct'].sum().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91412e96-c63d-4054-b08b-05747bdce466",
   "metadata": {},
   "source": [
    "### Process extended data file\n",
    "- used to calculate numerator for rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c56d1e-b865-43fe-9ea3-1f67174d148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_ext = pd.read_csv('decode/mDNM_analysisAndData-main/bpInvolved_extended', sep = '\\t')\n",
    "\n",
    "dec_ext[['Proband_1', 'Proband_2']] = (dec_ext['ProbandGt'].str.split('/', expand = True)).astype(float).round(1)\n",
    "dec_ext[['Father_1', 'Father_2']] = (dec_ext['FatherGt'].str.split('/', expand = True)).astype(float).round(1)\n",
    "dec_ext[['Mother_1', 'Mother_2']] = (dec_ext['MotherGt'].str.split('/', expand = True)).astype(float).round(1)\n",
    "dec_ext['Motif_len'] = dec_ext['Motif'].str.len()\n",
    "dec_ext['Phase'] = dec_ext['Phase'].replace('X', 0).astype(int)\n",
    "dec_ext['units_Involved'] = (dec_ext['BpInvolved'].replace('X', np.nan).astype(float) / dec_ext['Motif_len']).round(1)\n",
    "dec_ext['exp_con'] = ['exp' if change > 0 else 'con' if change < 0 else np.nan for change in dec_ext['units_Involved']]\n",
    "\n",
    "dec_ext['motif_std'] = [repeat_frames_RC(rep)[0] for rep in dec_ext['Motif']]\n",
    "dec_ext['Chrom'] = [chrom[3:] if chrom[3:] in ['X', 'Y'] else int(chrom[3:]) for chrom in dec_ext['Chrom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26553c65-5f70-455b-ac5b-a907dffee8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sequence upstream and downstream of mutation position based on given hg38 RefLen\n",
    "dec_ext['seq'] = [get_sequence(chrom, pos-reflen-10, pos+reflen+10, hg38_genome) for chrom, pos, reflen in zip(dec_ext['Chrom'], dec_ext['Pos'], dec_ext['RefLen'])]\n",
    "# Find longest pure repeat in sequence\n",
    "dec_ext['RefLen_pure'] = [max([len(rep) for rep in re.findall('(?:' + motif + ')+', seq)]) for motif, seq in zip(dec_ext['Motif'], dec_ext['seq'])]\n",
    "dec_ext['RefLen_units'] = dec_ext['RefLen'] / dec_ext['Motif_len']\n",
    "dec_ext['RefLen_units_pure'] = dec_ext['RefLen_pure'] / dec_ext['Motif_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36469f1-d22e-497d-8656-b50e0e10e6f2",
   "metadata": {},
   "source": [
    "#### Find closest parental allele\n",
    "in the absence of phasing, assume mutation originated from parental allele with nearest length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dc65b-837d-4342-a7c7-e30b04f5650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_p(F1, UI, P1):\n",
    "    return np.abs(F1+UI-P1) <= 0.11\n",
    "dec_ext['parent_allele'] = ['F1' if check_p(F1,UI,P1) & (phase == 1) else 'F2' if check_p(F2,UI,P1) & (phase == 1) else 'F1' if check_p(F1,UI,P2) & (phase == 1) else 'F2' if check_p(F2,UI,P2) & (phase == 1) else 'M1' if check_p(M1,UI,P1) & (phase == 2) else 'M2' if check_p(M2,UI,P1) & (phase == 2) else 'M1' if check_p(M1,UI,P2) & (phase == 2) else 'M2' if check_p(M2,UI,P2) & (phase == 2) else 'unknown' for F1, F2, M1, M2, P1, P2, UI, phase in zip(dec_ext['Father_1'], dec_ext['Father_2'], dec_ext['Mother_1'], dec_ext['Mother_2'], dec_ext['Proband_1'], dec_ext['Proband_2'], dec_ext['units_Involved'], dec_ext['Phase'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05133ca-79f0-4c3b-96db-d73dcfe5dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_ext['P1_in_M'] = [(P1 in [M1, M2]) for M1, M2, P1, P2 in zip(dec_ext['Mother_1'], dec_ext['Mother_2'], dec_ext['Proband_1'], dec_ext['Proband_2'])]\n",
    "dec_ext['P2_in_M'] = [(P2 in [M1, M2]) for M1, M2, P1, P2 in zip(dec_ext['Mother_1'], dec_ext['Mother_2'], dec_ext['Proband_1'], dec_ext['Proband_2'])]\n",
    "dec_ext['P1_in_F'] = [(P1 in [F1, F2]) for F1, F2, P1, P2 in zip(dec_ext['Father_1'], dec_ext['Father_2'], dec_ext['Proband_1'], dec_ext['Proband_2'])]\n",
    "dec_ext['P2_in_F'] = [(P2 in [F1, F2]) for F1, F2, P1, P2 in zip(dec_ext['Father_1'], dec_ext['Father_2'], dec_ext['Proband_1'], dec_ext['Proband_2'])]\n",
    "\n",
    "dec_ext['P1F_P2F_P1M_P2M'] = dec_ext[['P1_in_F','P2_in_F', 'P1_in_M', 'P2_in_M']].astype(int).values.tolist()\n",
    "dec_ext['P1F_P2F_P1M_P2M'] = [''.join(str(val)) for val in dec_ext['P1F_P2F_P1M_P2M']]\n",
    "\n",
    "# find probable parental allele contributing to instability\n",
    "# assumes the instable allele comes from the closest length parental allele, after identifying the stable allele by a match between any proband and parental allele\n",
    "dec_ext['probable_parent_allele'] = ['F1' if (min([abs(P1-F1), abs(P2-F1)]) == min([abs(P1-F1), abs(P1-F2), abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 1]') else \n",
    "'F2' if (min([abs(P1-F2), abs(P2-F2)]) == min([abs(P1-F1), abs(P1-F2), abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 1]') else\n",
    "'M1' if (min([abs(P1-M1), abs(P2-M1)]) == min([abs(P1-M1), abs(P1-M2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 1, 0, 0]') else \n",
    "'M2' if (min([abs(P1-M2), abs(P2-M2)]) == min([abs(P1-M1), abs(P1-M2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 1, 0, 0]') else \n",
    "'F1' if (abs(P1-F1) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'F2' if (abs(P1-F2) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'F1' if (abs(P2-F1) == min([abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 0]') else \n",
    "'F2' if (abs(P2-F2) == min([abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 0]') else \n",
    "'M1' if (abs(P1-M1) == min([abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 0]') else \n",
    "'M2' if (abs(P1-M2) == min([abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 0]') else \n",
    "'M1' if (abs(P2-M1) == min([abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 0, 0]') else \n",
    "'M2' if (abs(P2-M2) == min([abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 0, 0]') else \n",
    "'F1' if (abs(P1-F1) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'F2' if (abs(P1-F2) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'F1' if (abs(P2-F1) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'F2' if (abs(P2-F2) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'M1' if (abs(P2-M1) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'M2' if (abs(P2-M2) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'F1' if (abs(P1-F1) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else \n",
    "'F2' if (abs(P1-F2) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else \n",
    "'M1' if (abs(P1-M1) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else \n",
    "'M2' if (abs(P1-M2) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else 'unknown'\n",
    " for F1,  F2, M1,  M2, P1,  P2, FFMM in zip(dec_ext['Father_1'], dec_ext['Father_2'], dec_ext['Mother_1'], dec_ext['Mother_2'], dec_ext['Proband_1'], dec_ext['Proband_2'], dec_ext['P1F_P2F_P1M_P2M'])]\n",
    "\n",
    "# find probable proband allele contributing to instability\n",
    "# assumes the instable allele comes from the closest length parental allele, after identifying the stable allele by a match between any proband and parental allele\n",
    "dec_ext['probable_proband_allele'] = [\n",
    "'P1' if (abs(P1-F1) == min([abs(P1-F1), abs(P1-F2), abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 1]') else \n",
    "'P2' if (abs(P2-F1) == min([abs(P1-F1), abs(P1-F2), abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 1]') else \n",
    "'P1' if (abs(P1-F2) == min([abs(P1-F1), abs(P1-F2), abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 1]') else\n",
    "'P2' if (abs(P2-F2) == min([abs(P1-F1), abs(P1-F2), abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 1]') else\n",
    "'P1' if (abs(P1-M1) == min([abs(P1-M1), abs(P1-M2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 1, 0, 0]') else \n",
    "'P2' if (abs(P2-M1) == min([abs(P1-M1), abs(P1-M2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 1, 0, 0]') else \n",
    "'P1' if (abs(P1-M2) == min([abs(P1-M1), abs(P1-M2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 1, 0, 0]') else \n",
    "'P2' if (abs(P2-M2) == min([abs(P1-M1), abs(P1-M2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 1, 0, 0]') else \n",
    "'P1' if (abs(P1-F1) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'P1' if (abs(P1-F2) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'P2' if (abs(P2-F1) == min([abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 0]') else \n",
    "'P2' if (abs(P2-F2) == min([abs(P2-F1), abs(P2-F2)])) & (FFMM == '[0, 0, 1, 0]') else \n",
    "'P1' if (abs(P1-M1) == min([abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 0]') else \n",
    "'P1' if (abs(P1-M2) == min([abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 0]') else \n",
    "'P2' if (abs(P2-M1) == min([abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 0, 0]') else \n",
    "'P2' if (abs(P2-M2) == min([abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 0, 0]') else \n",
    "'P1' if (abs(P1-F1) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'P1' if (abs(P1-F2) == min([abs(P1-F1), abs(P1-F2)])) & (FFMM == '[0, 0, 0, 1]') else \n",
    "'P2' if (abs(P2-F1) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'P2' if (abs(P2-F2) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'P2' if (abs(P2-M1) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'P2' if (abs(P2-M2) == min([abs(P2-F1), abs(P2-F2), abs(P2-M1), abs(P2-M2)])) & (FFMM == '[1, 0, 1, 0]') else \n",
    "'P1' if (abs(P1-F1) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else \n",
    "'P1' if (abs(P1-F2) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else \n",
    "'P1' if (abs(P1-M1) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else \n",
    "'P1' if (abs(P1-M2) == min([abs(P1-F1), abs(P1-F2), abs(P1-M1), abs(P1-M2)])) & (FFMM == '[0, 1, 0, 1]') else 'unknown'\n",
    " for F1,  F2, M1,  M2, P1,  P2, FFMM in zip(dec_ext['Father_1'], dec_ext['Father_2'], dec_ext['Mother_1'], dec_ext['Mother_2'], dec_ext['Proband_1'], dec_ext['Proband_2'], dec_ext['P1F_P2F_P1M_P2M'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d7fb2-c5c9-4625-ba5d-ddcceab2897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use known allele when available, and likely allele if not\n",
    "dec_ext['known_or_likely_parent_allele'] = [parent if parent != 'unknown' else probable for parent, probable in zip(dec_ext['parent_allele'], dec_ext['probable_parent_allele'])]\n",
    "dec_ext['known_or_likely_parent_length'] = [F1 if likely == 'F1' else F2 if likely == 'F2' else M1 if likely == 'M1' else M2 if likely == 'M2' else np.nan for F1, F2, M1, M2, likely in zip(dec_ext['Father_1'], dec_ext['Father_2'], dec_ext['Mother_1'], dec_ext['Mother_2'], dec_ext['known_or_likely_parent_allele'])]\n",
    "# round down unit length of partial repeats\n",
    "dec_ext['known_or_likely_parent_length_int'] = dec_ext['known_or_likely_parent_length'] //1\n",
    "\n",
    "dec_ext['likely_BpInvolved'] = [P1 - parent if likely == 'P1' else P2 - parent if likely == 'P2' else np.nan for P1, P2, likely, parent, in zip(dec_ext['Proband_1'], dec_ext['Proband_2'], dec_ext['probable_proband_allele'], dec_ext['known_or_likely_parent_length'])]\n",
    "dec_ext['known_or_likely_BpInvolved'] = [float(bp) if bp != 'X' else probable for bp, probable in zip(dec_ext['BpInvolved'], dec_ext['likely_BpInvolved'])]\n",
    "dec_ext['known_or_likely_units_Involved'] = dec_ext['known_or_likely_BpInvolved'] / dec_ext['Motif_len']\n",
    "dec_ext['known_or_likely_exp_con'] = ['exp' if change > 0 else 'con' if change < 0 else 'unknown' for change in dec_ext['known_or_likely_units_Involved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aea0c0-5e60-4676-9569-9a572b5857b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_ext.to_pickle('decode/DECODE_extended_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2abb1-f1b0-4b79-8c0e-f5e675272cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_ext = pd.read_pickle('decode/DECODE_extended_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a35c8f-7045-4e1d-bcab-8563ff4429af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_ext['ref_units'] = dec_ext['RefLen'] / dec_ext['Motif_len']\n",
    "dec_ext['ref_units_int'] = dec_ext['ref_units'] //1\n",
    "dec_ext_pure = dec_ext.loc[(dec_ext['ref_units_int'] == dec_ext['RefLen_units_pure'])].copy()\n",
    "\n",
    "dec_ext_pure['Mother_1_int'] = dec_ext_pure['Mother_1'] // 1\n",
    "dec_ext_pure['Mother_2_int'] = dec_ext_pure['Mother_2'] // 1\n",
    "dec_ext_pure['Father_1_int'] = dec_ext_pure['Father_1'] // 1\n",
    "dec_ext_pure['Father_2_int'] = dec_ext_pure['Father_2'] // 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15c6ef-1272-4a32-b172-1a7e72152165",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dec_ext), len(dec_ext_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b159c1-193d-4808-bcba-b9dd39878a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose only single unit indels\n",
    "dec_ext_pure = dec_ext_pure.loc[dec_ext_pure['known_or_likely_units_Involved'].abs() == 1]\n",
    "len(dec_ext_pure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344178ce-03f2-460a-880b-82c46a767052",
   "metadata": {},
   "source": [
    "### Calculate rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60034b12-2530-4d93-883c-6832d870d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODE data\n",
    "decode_exp_rate = dict(); decode_con_rate = dict()\n",
    "decode_exp_counts = dict(); decode_con_counts = dict()\n",
    "decode_exp_rate_poisson = dict(); decode_con_rate_poisson = dict()\n",
    "for motif in reps_1_4:\n",
    "    # using closest parental allele \n",
    "    decode_exp_counts[motif] = dec_ext_pure.loc[(dec_ext_pure['motif_std'] == motif) & (dec_ext_pure['known_or_likely_exp_con'] == 'exp')]['known_or_likely_parent_length_int'].value_counts()\n",
    "    decode_con_counts[motif] = dec_ext_pure.loc[(dec_ext_pure['motif_std'] == motif) & (dec_ext_pure['known_or_likely_exp_con'] == 'con')]['known_or_likely_parent_length_int'].value_counts()\n",
    "    # assuming reference length is parental length, but size and direction of change (units_involved) is the same\n",
    "#    decode_exp_counts[motif] = dec_ext_pure.loc[(dec_ext_pure['motif_std'] == motif) & (dec_ext_pure['known_or_likely_exp_con'] == 'exp')]['ref_units_int'].value_counts()\n",
    "#    decode_con_counts[motif] = dec_ext_pure.loc[(dec_ext_pure['motif_std'] == motif) & (dec_ext_pure['known_or_likely_exp_con'] == 'con')]['ref_units_int'].value_counts()\n",
    "\n",
    "    loci_count = motif_counts_pure_units[motif] *2 # number of trios where all three members pass quality filters, multiplied by 2 parental alleles\n",
    "    # using DECODE population information for denominator, with adjustment for average number of motifs passing filters / total number of motifs\n",
    "    decode_exp_rate[motif] = decode_exp_counts[motif].div(loci_count).dropna() \n",
    "    decode_con_rate[motif] = decode_con_counts[motif].div(loci_count).dropna()\n",
    "    if len(decode_exp_rate[motif]) > 0:\n",
    "        decode_exp_rate_poisson_current = dict()\n",
    "        for i in range(200):\n",
    "            decode_exp_rate_poisson_current[i] = decode_exp_counts[motif].apply(lambda x: np.random.poisson(x)).div(loci_count)\n",
    "        decode_exp_rate_poisson[motif] = pd.concat(decode_exp_rate_poisson_current)#.div(decode_exp_rate_poisson_current.index * len(motif))\n",
    "    if len(decode_con_rate[motif]) > 0:\n",
    "        decode_con_rate_poisson_current = dict()\n",
    "        for i in range(200):\n",
    "            decode_con_rate_poisson_current[i] = decode_con_counts[motif].apply(lambda x: np.random.poisson(x)).div(loci_count)\n",
    "        decode_con_rate_poisson[motif] = pd.concat(decode_con_rate_poisson_current)\n",
    "decode_exp_counts = pd.concat(decode_exp_counts, axis=1).sort_index()\n",
    "decode_con_counts = pd.concat(decode_con_counts, axis=1).sort_index()\n",
    "decode_exp_rate = pd.concat(decode_exp_rate, axis=1).sort_index()\n",
    "decode_con_rate = pd.concat(decode_con_rate, axis=1).sort_index()\n",
    "decode_exp_rate_poisson = pd.concat(decode_exp_rate_poisson, axis=1).sort_index()\n",
    "decode_con_rate_poisson = pd.concat(decode_con_rate_poisson, axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eac090-3883-4d59-bfc3-8b5e62030bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine units\n",
    "for unit_len in [1,2,3,4]:\n",
    "    current_reps = [rep for rep in decode_exp_rate.columns if len(rep) == unit_len]\n",
    "    decode_exp_counts['unit_'+str(unit_len)] = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(current_reps)) & (dec_ext_pure['known_or_likely_exp_con'] == 'exp')]['known_or_likely_parent_length_int'].value_counts()\n",
    "    decode_con_counts['unit_'+str(unit_len)] = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(current_reps)) & (dec_ext_pure['known_or_likely_exp_con'] == 'con')]['known_or_likely_parent_length_int'].value_counts()\n",
    "    loci_count_units = motif_counts_pure_units[current_reps].sum(axis=1) *2\n",
    "    # using DECODE parental information for denominator, with adjustment for average number of motifs passing filters / total number of motifs\n",
    "    decode_exp_rate['unit_'+str(unit_len)] = decode_exp_counts['unit_'+str(unit_len)].div(loci_count_units).dropna() \n",
    "    decode_con_rate['unit_'+str(unit_len)] = decode_con_counts['unit_'+str(unit_len)].div(loci_count_units).dropna()\n",
    "    \n",
    "    decode_exp_rate_units = dict(); decode_con_rate_units = dict()\n",
    "    for i in range(200):\n",
    "        decode_exp_rate_units[i] = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(current_reps)) & (dec_ext_pure['known_or_likely_exp_con'] == 'exp')]['known_or_likely_parent_length_int'].value_counts().apply(np.random.poisson).div(loci_count_units).dropna()\n",
    "        decode_con_rate_units[i] = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(current_reps)) & (dec_ext_pure['known_or_likely_exp_con'] == 'con')]['known_or_likely_parent_length_int'].value_counts().apply(np.random.poisson).div(loci_count_units).dropna()\n",
    "    decode_exp_rate_poisson['unit_'+str(unit_len)] = pd.concat(decode_exp_rate_units, axis=0).replace(0, np.nan)\n",
    "    decode_con_rate_poisson['unit_'+str(unit_len)] = pd.concat(decode_con_rate_units, axis=0).replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae37c1-b8da-46a6-9488-2713aafb7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine non-CpG trinucleotide repeats\n",
    "decode_exp_count_tri_noCpG = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(reps_tri_noCpG)) & (dec_ext_pure['known_or_likely_exp_con'] == 'exp')]['known_or_likely_parent_length_int'].value_counts()\n",
    "decode_con_count_tri_noCpG = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(reps_tri_noCpG)) & (dec_ext_pure['known_or_likely_exp_con'] == 'con')]['known_or_likely_parent_length_int'].value_counts()\n",
    "loci_count_tri_noCpG = motif_counts_pure_units[reps_tri_noCpG].sum(axis=1) *2\n",
    "# using DECODE parental information for denominator, with adjustment for average number of motifs passing filters / total number of motifs\n",
    "decode_exp_rate['tri_noCpG'] = decode_exp_count_tri_noCpG.div(loci_count_tri_noCpG).dropna() \n",
    "decode_con_rate['tri_noCpG'] = decode_con_count_tri_noCpG.div(loci_count_tri_noCpG).dropna()\n",
    "\n",
    "decode_exp_rate_tri_noCpG = dict(); decode_con_rate_tri_noCpG = dict()\n",
    "for i in range(200):\n",
    "    decode_exp_rate_tri_noCpG[i] = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(reps_tri_noCpG)) & (dec_ext_pure['known_or_likely_exp_con'] == 'exp')]['known_or_likely_parent_length_int'].value_counts().apply(np.random.poisson).div(loci_count_tri_noCpG).dropna()\n",
    "    decode_con_rate_tri_noCpG[i] = dec_ext_pure.loc[(dec_ext_pure['motif_std'].isin(reps_tri_noCpG)) & (dec_ext_pure['known_or_likely_exp_con'] == 'con')]['known_or_likely_parent_length_int'].value_counts().apply(np.random.poisson).div(loci_count_tri_noCpG).dropna()\n",
    "decode_exp_rate_poisson['tri_noCpG'] = pd.concat(decode_exp_rate_tri_noCpG, axis=0).replace(0, np.nan)\n",
    "decode_con_rate_poisson['tri_noCpG'] = pd.concat(decode_con_rate_tri_noCpG, axis=0).replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079020e1-c333-4e91-8222-dfd8d4c69262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not adjusting for motif length here... calculate per unit instead of per nt\n",
    "decode_exp_rate = decode_exp_rate.div(decode_exp_rate.index, axis=0) \n",
    "decode_con_rate = decode_con_rate.div(decode_con_rate.index, axis=0)\n",
    "decode_exp_rate_poisson = decode_exp_rate_poisson.div(decode_exp_rate_poisson.index.get_level_values(1), axis=0)\n",
    "decode_con_rate_poisson = decode_con_rate_poisson.div(decode_con_rate_poisson.index.get_level_values(1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ed7ab-29a9-4fb4-b60e-77295028e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_exp_counts.to_pickle('decode/decode_expansion_counts.pickle')\n",
    "decode_con_counts.to_pickle('decode/decode_contraction_counts.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae7b249-a4f6-4b28-a0d3-d7f41de53322",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_exp_rate.to_pickle('decode/decode_expansion_rates.pickle')\n",
    "decode_con_rate.to_pickle('decode/decode_contraction_rates.pickle')\n",
    "\n",
    "decode_exp_rate_poisson.to_pickle('decode/decode_expansion_rates_poisson.pickle')\n",
    "decode_con_rate_poisson.to_pickle('decode/decode_contraction_rates_poisson.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41ff08-1e7f-4687-b948-8e5f73c13ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_exp_counts = pd.read_pickle('decode/decode_expansion_counts.pickle')\n",
    "decode_con_counts = pd.read_pickle('decode/decode_contraction_counts.pickle')\n",
    "\n",
    "decode_exp_rate = pd.read_pickle('decode/decode_expansion_rates.pickle')\n",
    "decode_con_rate = pd.read_pickle('decode/decode_contraction_rates.pickle')\n",
    "\n",
    "decode_exp_rate_poisson = pd.read_pickle('decode/decode_expansion_rates_poisson.pickle')\n",
    "decode_con_rate_poisson = pd.read_pickle('decode/decode_contraction_rates_poisson.pickle')\n",
    "\n",
    "decode_con_rate_poisson = decode_con_rate_poisson.reindex(decode_exp_rate_poisson.columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b68b79-2660-4481-9c05-bdae2e75346f",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21043f92-a046-4189-b229-b835fb4017ea",
   "metadata": {},
   "source": [
    "#### Units added per event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad293a-3538-42c7-aaa3-ac617214ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_ext['BpInvolved_withsign'] = dec_ext['BpInvolved'].replace('X', np.nan).astype(float)\n",
    "dec_ext['BpInvolved_abs'] = np.abs(dec_ext['BpInvolved_withsign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02af037-d1f7-4a89-a57c-34ad139c414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_unit_len_per_event = dec_ext.dropna(subset = ['BpInvolved_withsign']).groupby(['Motif_len', 'RefLen_pure', 'BpInvolved_withsign'])['Chrom'].count().unstack().div(dec_ext.groupby(['Motif_len', 'RefLen_pure', 'BpInvolved_abs'])['Chrom'].count().unstack().sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669ad8e-28f2-4eeb-9ee3-e5565e8d4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any decode measurement below 10 nt\n",
    "decode_unit_len_per_event.loc[1,[5,6,7,8,9],:] = np.nan\n",
    "decode_unit_len_per_event.loc[2,[6,8],:] = np.nan\n",
    "decode_unit_len_per_event.loc[3,[6,9],:] = np.nan\n",
    "decode_unit_len_per_event.loc[4,[4,8],:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98271e7b-fd4d-457d-a81f-ffe07d88b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S4 (bottom)\n",
    "fig = make_subplots(rows = 4, cols = 1, shared_xaxes = True, vertical_spacing = 0.015, row_titles = ['unit=1', 'unit=2', 'unit=3', 'unit=4'], x_title = 'repeat tract length (units)', y_title = 'fraction of events per length bin')\n",
    "for unit_len in range(1,5):\n",
    "    current_units = decode_unit_len_per_event.loc[unit_len]\n",
    "    for inslen in [1,2,3,4]:\n",
    "        fig.add_trace(go.Bar(x = current_units.index / unit_len, y = current_units[inslen], name = str(np.abs(inslen)), legendgroup = str(np.abs(inslen)), showlegend = True if unit_len == 1 else False), row = unit_len, col = 1)\n",
    "    fig.add_trace(go.Bar(x = current_units.index  / unit_len, y = current_units[[col for col in current_units.columns if col > 4]].sum(axis=1), name = '>4', legendgroup = 'other', showlegend = True if unit_len == 1 else False), row = unit_len, col = 1)\n",
    "    for inslen in [-1,-2,-3,-4]:\n",
    "        fig.add_trace(go.Bar(x = current_units.index / unit_len, y = -current_units[inslen], name = str(np.abs(inslen)), legendgroup = str(np.abs(inslen)), showlegend = False), row = unit_len, col = 1)\n",
    "    fig.add_trace(go.Bar(x = current_units.index  / unit_len, y = -current_units[[col for col in current_units.columns if col < -4]].sum(axis=1), name = '>4', legendgroup = 'other', showlegend = False), row = unit_len, col = 1)\n",
    "    fig.update_xaxes(range = [2.5,33.5], dtick = 1, row = unit_len, col = 1)\n",
    "fig.update_yaxes(range = [-1,1], tickvals = [-0.5, 0, 0.5])\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 14), height = 400, width = 1000, title = 'popSTR', colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:5], legend_title_text='nt added', margin={'t':30,'l':60,'b':60,'r':10})\n",
    "fig.update_layout(barmode = 'relative')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e098d4-626c-4541-870d-495f60b9ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/figS4b.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e45e4-c7cb-4dd1-ac0e-2f257fbf279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 2a\n",
    "fig = go.Figure()\n",
    "for unit in [1,2,3,4]:\n",
    "    current_focus = (unit_fraction_of_events_per_length[unit].dropna(how = 'all', axis=1)[unit] + unit_fraction_of_events_per_length[unit].dropna(how = 'all', axis=1)[-unit]) / unit_fraction_of_events_per_length[unit].dropna(how = 'all', axis=1).sum(axis=1)\n",
    "    if unit ==1:\n",
    "        current_focus = current_focus.reindex(range(1,11))\n",
    "    if unit ==2:\n",
    "        current_focus = current_focus.reindex(range(1,9))\n",
    "    if unit ==3:\n",
    "        current_focus = current_focus.reindex(range(1,8))\n",
    "    if unit ==4:\n",
    "        current_focus = current_focus.reindex(range(1,6))\n",
    "    fig.add_trace(go.Scatter(x = current_focus.index, y = current_focus, mode = 'markers', marker = dict(symbol = 'square-open', line_width = 3, size = 7), legendgroup = unit, name = 'unit=' +str(unit) + ' (pooled trios)'))\n",
    "\n",
    "for unit in [1,2,3,4]:    \n",
    "    current_focus = (decode_unit_len_per_event.loc[unit].dropna(how = 'all', axis=1)[unit] + decode_unit_len_per_event.loc[unit].dropna(how = 'all', axis=1)[-unit]) / decode_unit_len_per_event.loc[unit].dropna(how = 'all', axis=1).sum(axis=1)\n",
    "    current_focus.index /= unit\n",
    "    if unit ==1:\n",
    "        current_focus = current_focus.reindex(range(10,26))\n",
    "    if unit ==2:\n",
    "        current_focus = current_focus.reindex(range(5,31))\n",
    "    if unit ==3:\n",
    "        current_focus = current_focus.reindex(range(4,31))\n",
    "    if unit ==4:\n",
    "        current_focus = current_focus.reindex(range(4,31))\n",
    "    fig.add_trace(go.Scatter(x = current_focus.index, y = current_focus, mode = 'markers', marker = dict(symbol = 'circle-open', line_width = 3, size = 7), legendgroup = unit, name = 'unit=' +str(unit) + ' (popSTR)'))\n",
    "\n",
    "fig.update_xaxes(title = 'repeat tract length (units)')\n",
    "fig.update_yaxes(title = 'fraction +/-1 unit indels')\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 14), height = 300, width = 550, colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:4], margin={'t':30,'l':60,'b':40,'r':10})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d3a80-55d9-435c-a6bf-737af7f14e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/fig2b_unitlengthchange.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4f62a-1ca1-449b-b2fa-e3097d962a95",
   "metadata": {},
   "source": [
    "#### Rate curve plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c9f3d-dfd7-4c31-a995-47fd542a8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rate_trace(rates, name, symbol, colornum, motif='A', rowcol=None, markersize = 7, per = 'unit', xmult = 1, plot_min = 1e-12, plot_range = range(1,32)):\n",
    "    rates = rates[motif].unstack().replace(np.inf, np.nan).dropna(how='all', axis=1).loc[1:]\n",
    "    med = rates.median(axis=0).replace(0, np.nan).replace(np.inf, np.nan).dropna().reindex(plot_range)\n",
    "    low = med.sub(rates.quantile(0.025).replace(0, np.nan).replace(np.inf, np.nan)).reindex(plot_range)\n",
    "    high = (rates.quantile(0.975).replace(0, np.nan).replace(np.inf, np.nan)).sub(med).reindex(plot_range)\n",
    "    \n",
    "    if per == 'repeat':\n",
    "        med *= med.index; low *= low.index; high *= high.index\n",
    "    if per == 'nt':\n",
    "        med *= len(motif); low *= len(motif); high *= len(motif)\n",
    "\n",
    "    low = low.replace(0, plot_min)\n",
    "\n",
    "    if rowcol is None:\n",
    "        fig_rates.add_trace(go.Scatter(x = med.index * xmult, y = med, error_y = dict(type = 'data', arrayminus = low, array = high, color = 'rgba(0,0,0,0.2)', thickness = (1.8/7) * markersize, width = markersize), name = name, mode = 'markers', opacity = 0.95, marker = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[colornum], symbol= symbol, size = markersize, line_width = (3/7) * markersize)))\n",
    "    else:\n",
    "        fig_rates.add_trace(go.Scatter(x = med.index * xmult, y = med, error_y = dict(type = 'data', arrayminus = low, array = high, color = 'rgba(0,0,0,0.2)', thickness = (1.8/7) * markersize, width = markersize), name = name, mode = 'markers', opacity = 0.95, marker = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[colornum], symbol= symbol, size = markersize, line_width = (3/7) * markersize), showlegend = True if (rowcol[0]==1) & (rowcol[1]==1) else False), row = rowcol[0], col = rowcol[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f4d02-aff3-4d3c-a93e-ab24fd045a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 2b\n",
    "fig_rates = go.Figure()\n",
    "add_rate_trace(denovo_exp_rate_poisson, 'Expansion (pooled trios)', 'square-open', colornum = 0, plot_range=range(1,9))\n",
    "add_rate_trace(denovo_con_rate_poisson, 'Contraction (pooled trios)', 'square-open', colornum = 1, plot_range=range(1,9))\n",
    "add_rate_trace(denovo_nonexp_rate_poisson, 'Non-motif insertion (pooled trios)', 'square-open', colornum = 2, plot_range=range(2,11))\n",
    "add_rate_trace(decode_exp_rate_poisson, 'Expansion/insertion (popSTR)', 'circle-open', colornum = 0)\n",
    "add_rate_trace(decode_con_rate_poisson, 'Contraction (popSTR)', 'circle-open', colornum = 1)\n",
    "\n",
    "fig_rates.add_trace(go.Scatter(x = list(range(1,40)), y = [mu_nu_all['nu'][1]['A']]*40, name = 'substitutions A>B', line = dict(color = 'rgba(50,50,50,0.5)', dash = 'dash'), showlegend = False))\n",
    "fig_rates.add_trace(go.Scatter(x = list(range(1,40)), y = [mu_nu_all['mu'][1]['A']]*40, name = 'substitutions B>A', line = dict(color = 'rgba(50,50,50,0.5)', dash = 'dot'), showlegend = False))\n",
    "\n",
    "fig_rates.update_xaxes(type = 'log', title = 'repeat tract length (units)', range = [-0.03,1.6], tickvals = [1,5,10,20,30], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_rates.update_yaxes(type = 'log', title = 'rate (per nt per generation)', range = [-11.6, -4.8], exponentformat =  'e', dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_rates.update_layout(margin={'t':20,'l':80,'b':45,'r':10}, height = 360, width = 540)\n",
    "fig_rates.update_layout(font=dict(family = 'Arial', size = 15), legend=dict(yanchor=\"top\", y=1.05, xanchor=\"left\", x=0.023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5c772-5b91-470d-995f-5c3fb37f85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/fig2b_rates.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8ce20-51e2-4f24-9957-942ced7e8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S5a\n",
    "motif_list = ['A', 'C', 'AC', 'AG', 'AT', 'CG', 'AAC', 'AAG', 'AAT', 'ACC', 'ACT', 'AGC', 'AGG', 'ATC', 'CCG', 'AAAC', 'AAAG', 'AAAT', 'AAGG', 'AATG', 'ACAG', 'ACAT', 'AGAT', 'ATCC']\n",
    "fig_rates = make_subplots(rows = 6, cols = 4, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.025, vertical_spacing = 0.05, subplot_titles = motif_list, x_title = 'repeat tract length (units)', y_title = 'rate (per nt per generation)')\n",
    "col_counter = 0; row_counter = 1\n",
    "for motif in motif_list:\n",
    "    col_counter +=1\n",
    "    if col_counter ==5:\n",
    "        row_counter +=1; col_counter -=4\n",
    "    add_rate_trace(denovo_exp_rate_poisson, 'Expansion (pooled trios)', 'square-open', colornum = 0, motif = motif, markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(decode_exp_rate_poisson, 'Expansion/insertion (popSTR)', 'circle-open', colornum = 0, motif = motif, plot_range = range(round((10/len(motif)) + 0.49),30), markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(denovo_con_rate_poisson, 'Contraction (pooled trios)', 'square-open', colornum = 1, motif = motif, markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(decode_con_rate_poisson, 'Contraction (popSTR)', 'circle-open', colornum = 1, motif = motif, plot_range = range(round((10/len(motif)) + 0.49),30), markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(denovo_nonexp_rate_poisson, 'Non-motif insertion (pooled trios)', 'square-open', colornum = 2, motif = motif, markersize = 4, rowcol = (row_counter, col_counter))\n",
    "fig_rates.update_xaxes(type = 'log', range = [-0.1,2], tickvals = [1,5,10,25])\n",
    "fig_rates.update_yaxes(type = 'log', range = [-12.1, -2.4], exponentformat =  'e', dtick = 2)\n",
    "fig_rates.update_layout(font=dict(family = 'Arial', size = 12), margin={'t':20,'l':80,'b':70,'r':10}, legend = dict(orientation = 'h', xanchor = 'center', x = 0.5, y= -0.08), height = 840, width = 640, colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625342d6-816a-472b-8db0-6666b38eac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/figS5a_rates.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ab0b3-a433-4ada-96a9-5b74cbb7ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S5b\n",
    "motif_list = ['unit_1', 'unit_2', 'unit_3', 'unit_4']\n",
    "fig_rates = make_subplots(rows = 4, cols = 1, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.025, vertical_spacing = 0.05, subplot_titles = ['unit length = 1', 'unit length = 2', 'unit length = 3', 'unit length = 4'], x_title = 'repeat tract length (units)', y_title = 'rate (per nt per generation)')\n",
    "col_counter = 1; row_counter = 0\n",
    "for motif in motif_list:\n",
    "    row_counter +=1\n",
    "    add_rate_trace(denovo_exp_rate_poisson, 'Expansion (pooled trios)', 'square-open', colornum = 0, motif = motif, markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(decode_exp_rate_poisson, 'Expansion/insertion (popSTR)', 'circle-open', colornum = 0, motif = motif, plot_range = range(round((10/int(motif[-1])) + 0.49),30), markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(denovo_con_rate_poisson, 'Contraction (pooled trios)', 'square-open', colornum = 1, motif = motif, markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(decode_con_rate_poisson, 'Contraction (popSTR)', 'circle-open', colornum = 1, motif = motif, plot_range = range(round((10/int(motif[-1])) + 0.49),30), markersize = 4, rowcol = (row_counter, col_counter))\n",
    "    add_rate_trace(denovo_nonexp_rate_poisson, 'Non-motif insertion (pooled trios)', 'square-open', colornum = 2, motif = motif, markersize = 4, rowcol = (row_counter, col_counter))\n",
    "fig_rates.update_xaxes(type = 'log', range = [-0.1,2], tickvals = [1,5,10,25])\n",
    "fig_rates.update_yaxes(type = 'log', range = [-12.1, -2.4], exponentformat =  'e', dtick = 2)\n",
    "fig_rates.update_layout(font=dict(family = 'Arial', size = 12), margin={'t':20,'l':80,'b':70,'r':10}, legend = dict(orientation = 'h', xanchor = 'center', x = 0.5, y= -0.08), height = 840, width = 540, colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ef2b2-da9c-4606-8b2b-b1de60bfdbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/figS5b_rates.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128e2a4-360a-4d8a-8024-244eb09447d0",
   "metadata": {},
   "source": [
    "#### save rate data for Supplementary File SF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c184094-fecc-4556-98ab-648e201878ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "SF2_data = dict()\n",
    "SF2_data['denovo_substitutions'] = denovo_mut_freq_all.transpose()\n",
    "SF2_data['denovo_expansions'] = denovo_exp_rate_poisson.unstack().median(axis=0).unstack().transpose().replace(0, np.nan).replace(np.inf, np.nan).dropna(how='all')\n",
    "SF2_data['denovo_contractions'] = denovo_con_rate_poisson.unstack().median(axis=0).unstack().transpose().replace(0, np.nan).replace(np.inf, np.nan).dropna(how='all')\n",
    "SF2_data['denovo_non_motif_insertions'] = denovo_nonexp_rate_poisson.unstack().median(axis=0).unstack().transpose().replace(0, np.nan).replace(np.inf, np.nan).dropna(how='all')\n",
    "SF2_data['popSTR_insertions'] = decode_exp_rate_poisson.unstack().median(axis=0).unstack().transpose().replace(0, np.nan).replace(np.inf, np.nan).dropna(how='all')\n",
    "SF2_data['popSTR_contractions'] = decode_con_rate_poisson.unstack().median(axis=0).unstack().transpose().replace(0, np.nan).replace(np.inf, np.nan).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4744f-a1c3-42a7-a5a6-d938f07d294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SF2_data['denovo_substitutions'].index = ['AAA>ABA', 'AAB>ABB', 'BAB>BBB', 'ABA>AAA', 'ABB>AAB', 'BBB>BAB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68a655-c286-4b6d-b2f6-0f4d8c3d990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('decode/SF2_rate_data.xlsx')\n",
    "for sheet, frame in  SF2_data.items():\n",
    "    frame.to_excel(writer, sheet_name = sheet)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb453fc9-25d8-4184-9a3d-4b1d4fca4e12",
   "metadata": {},
   "source": [
    "# regression on popSTR data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbe1a2-594f-47be-840f-1936b994fa12",
   "metadata": {},
   "source": [
    "## setup for all curve fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7247ac1-b69c-4285-91ca-22ad8398c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0995d2-efe4-415a-ad91-9703c043fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: combination of two lists\n",
    "intercept_list = [denovo_con_rate['A'][8]] + [denovo_exp_rate['A'][8] * (denovo_exp_rate['A'][8]/ denovo_con_rate['A'][8])**x for x in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8322c-236f-4124-8ef4-e0788660bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all popSTR points, inflate error on untrusted points\n",
    "exp_std = decode_exp_rate_poisson['A'].unstack().std().dropna()\n",
    "exp_std.loc[22:] *=100\n",
    "exp_std.loc[11:12] *=100\n",
    "\n",
    "con_std = decode_con_rate_poisson['A'].unstack().std().dropna()\n",
    "con_std.loc[20:] *=100\n",
    "con_std.loc[11:12] *=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff38eac-778a-4bdb-a99f-8201763c7370",
   "metadata": {},
   "source": [
    "## Linear curve fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdad4e-d7b8-40b2-b613-188bb116c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_lin(x, m, c):\n",
    "    return m * x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6bce6-ae7a-414c-a0d8-25ad476c2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fit, exp_pcov = curve_fit(func_lin, np.log10(decode_exp_rate['A'].dropna().index), np.log10(decode_exp_rate['A'].dropna()), sigma = np.log10(exp_std))\n",
    "con_fit, con_pcov = curve_fit(func_lin, np.log10(decode_con_rate['A'].dropna().index), np.log10(decode_con_rate['A'].dropna()), sigma = np.log10(con_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d7c96-fca4-4ece-adfe-a881249dd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S6a\n",
    "fig_rates = go.Figure()\n",
    "add_rate_trace(denovo_exp_rate_poisson, 'Exp. (pooled trios)', 'square-open', colornum = 0, plot_range=range(1,9))\n",
    "add_rate_trace(denovo_con_rate_poisson, 'Con. (pooled trios)', 'square-open', colornum = 1, plot_range=range(1,9))\n",
    "#add_rate_trace(denovo_nonexp_rate_poisson, 'Ins. (de novo)', 'square-open')\n",
    "add_rate_trace(decode_exp_rate_poisson, 'Exp. (popSTR)', 'circle-open', colornum = 0)\n",
    "add_rate_trace(decode_con_rate_poisson, 'Con. (popSTR)', 'circle-open', colornum = 1)\n",
    "fig_rates.update_xaxes(type = 'log', title = 'repeat tract length (nt)', range = [-0.03,1.8], tickvals = [1,2,5,10,20,50], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_rates.update_yaxes(type = 'log', title = 'rate (per nt per generation)', range = [-11.6, -4.5], exponentformat =  'e', dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig_rates.update_layout(margin={'t':20,'l':60,'b':35,'r':10}, height = 450, width = 600, colorway = plotly.colors.DEFAULT_PLOTLY_COLORS[:2])\n",
    "#fig_rates.update_layout(legend=dict(yanchor=\"top\", y=0.97, xanchor=\"left\", x=0.075))\n",
    "\n",
    "mean_exp = pd.Series([10**(func_lin(np.log10(L), (exp_fit[0]), (exp_fit[1]))) for L in range(5,60)], index = list(range(5,60)))\n",
    "upper_exp = pd.Series([10**func_lin(np.log10(L), exp_fit[0] + 2*np.sqrt(exp_pcov[0][0]), exp_fit[1] - 2*np.sqrt(exp_pcov[1][1])) for L in range(5,60)], index = list(range(5,60)))\n",
    "lower_exp = pd.Series([10**func_lin(np.log10(L), exp_fit[0] - 2*np.sqrt(exp_pcov[0][0]), exp_fit[1] + 2*np.sqrt(exp_pcov[1][1])) for L in range(5,60)], index = list(range(5,60)))\n",
    "\n",
    "fig_rates.add_trace(go.Scatter(x = upper_exp.index, y = upper_exp, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], width = 0), name = 'CI', showlegend = False, legendgroup = 'exp_regress'))\n",
    "fig_rates.add_trace(go.Scatter(x = mean_exp.index, y = mean_exp, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0]), name = 'Exp. PL fit', legendgroup = 'exp_regress', fill = 'tonexty'))\n",
    "fig_rates.add_trace(go.Scatter(x = lower_exp.index, y = lower_exp, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[0], width = 0), name = 'CI', showlegend = False,  legendgroup = 'exp_regress', fill = 'tonexty'))\n",
    "\n",
    "mean_con = pd.Series([10**func_lin(np.log10(L), con_fit[0], con_fit[1]) for L in range(5,60)], index = list(range(5,60)))\n",
    "upper_con = pd.Series([10**func_lin(np.log10(L), con_fit[0] + 2*np.sqrt(con_pcov[0][0]), con_fit[1] - 2*np.sqrt(con_pcov[1][1])) for L in range(5,60)], index = list(range(5,60)))\n",
    "lower_con = pd.Series([10**func_lin(np.log10(L), con_fit[0] - 2*np.sqrt(con_pcov[0][0]), con_fit[1] + 2*np.sqrt(con_pcov[1][1])) for L in range(5,60)], index = list(range(5,60)))\n",
    "\n",
    "fig_rates.add_trace(go.Scatter(x = upper_con.index, y = upper_con, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], width = 0), name = 'CI', showlegend = False, legendgroup = 'con_regress'))\n",
    "fig_rates.add_trace(go.Scatter(x = mean_con.index, y = mean_con, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1]), name = 'Con. PL fit', legendgroup = 'con_regress', fill = 'tonexty'))\n",
    "fig_rates.add_trace(go.Scatter(x = lower_con.index, y = lower_con, line = dict(color = plotly.colors.DEFAULT_PLOTLY_COLORS[1], width = 0), name = 'CI', showlegend = False,  legendgroup = 'con_regress', fill = 'tonexty'))\n",
    "\n",
    "fig_rates.update_layout(font=dict(family = 'Arial', size = 14), margin={'t':20,'l':80,'b':40,'r':10}, height = 300, width = 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a298079-b920-4a50-9445-43b37798e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rates.write_image('plots/fig_rates_regression.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419a218-122a-4283-925f-13747360e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var_L9 = ((np.log10(lower_exp[9]) - np.log10(mean_exp[9]))/2)**2\n",
    "exp_cov_L9 = (exp_pcov[0][1] / (np.sqrt(np.sqrt(exp_pcov[0][0])**2 * np.sqrt(exp_pcov[1][1])**2))) * np.sqrt(exp_pcov[0][0]) * np.sqrt(exp_var_L9)\n",
    "\n",
    "con_var_L9 = ((np.log10(lower_con[9]) - np.log10(mean_con[9]))/2)**2\n",
    "con_cov_L9 = (con_pcov[0][1] / (np.sqrt(np.sqrt(con_pcov[0][0])**2 * np.sqrt(con_pcov[1][1])**2))) * np.sqrt(con_pcov[0][0]) * np.sqrt(con_var_L9)\n",
    "\n",
    "combined_pcov = np.array([[exp_pcov[0][0], exp_cov_L9, 0, 0], [exp_cov_L9, exp_var_L9, 0, 0], [0, 0, con_pcov[0][0], con_cov_L9], [0, 0, con_cov_L9, con_var_L9]])\n",
    "combined_pcov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48829954-8f54-4c5a-89be-98f6f6df1998",
   "metadata": {},
   "source": [
    "#### restrictive prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80182c32-57e3-4f15-9915-01440b7eda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mvg = scipy.stats.multivariate_normal([exp_fit[0], np.log10(mean_exp[9]), con_fit[0], np.log10(mean_con[9])], combined_pcov * 100)\n",
    "\n",
    "prob_grid = pd.DataFrame([(round(exp_p,2), round(con_p,2), exp_i,con_i) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in list(range(8)) for con_i in list(range(8))], columns = ['exp_p', 'con_p', 'exp_i', 'con_i'])\n",
    "prob_grid['prob'] = [combined_mvg.pdf([exp_p, np.log10(exp_i), con_p, np.log10(con_i)]) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in intercept_list for con_i in intercept_list]\n",
    "prob_grid.set_index( ['exp_i', 'con_i', 'exp_p', 'con_p'], inplace=True)\n",
    "prob_grid /= prob_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2ca23-24e4-4943-bf75-cf880337eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_grid.to_pickle('simulations/grid_4param_v2/prior_restrictive_a.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7f7b7-abce-49ba-b90f-12ef67262793",
   "metadata": {},
   "source": [
    "#### relaxed prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422d28e-f6e1-4559-b7df-6e36a585a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mvg = scipy.stats.multivariate_normal([exp_fit[0], np.log10(mean_exp[9]), con_fit[0], np.log10(mean_con[9])], combined_pcov * 1000)\n",
    "\n",
    "prob_grid = pd.DataFrame([(round(exp_p,2), round(con_p,2), exp_i,con_i) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in list(range(8)) for con_i in list(range(8))], columns = ['exp_p', 'con_p', 'exp_i', 'con_i'])\n",
    "prob_grid['prob'] = [combined_mvg.pdf([exp_p, np.log10(exp_i), con_p, np.log10(con_i)]) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in intercept_list for con_i in intercept_list]\n",
    "prob_grid.set_index( ['exp_i', 'con_i', 'exp_p', 'con_p'], inplace=True)\n",
    "prob_grid /= prob_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9a00d-b2bd-45f3-aa17-fc3518bb2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_grid.to_pickle('simulations/grid_4param_v2/prior_a.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d346e82-bb13-449d-a40d-e73357c4912d",
   "metadata": {},
   "source": [
    "#### plot prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be7ee5-e656-4d89-ad47-427af7718c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S6b\n",
    "fig = make_subplots(rows = 8, cols = 8, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.005, vertical_spacing = 0.005, row_titles = ['<i>c</i><sub></sub>=' + '{:.2e}'.format(x) for x in intercept_list[::-1]], column_titles = ['<i>c</i><sub></sub>=' + '{:.2e}'.format(x) for x in intercept_list], x_title = 'expansion power <sub></sub>', y_title = 'contraction power <sub></sub>')\n",
    "col_count = 0\n",
    "fig.update_xaxes(range = [0,4.3], tickvals = [0,1,2,3,4], gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "for exp_i in range(8):\n",
    "    row_count=0; col_count +=1\n",
    "    for con_i in range(7,-1,-1):\n",
    "        row_count+=1\n",
    "        fig.add_trace(go.Heatmap(x = prob_grid.loc[exp_i].loc[con_i].index.get_level_values(0), y = prob_grid.loc[exp_i].loc[con_i].index.get_level_values(1), z=(prob_grid.loc[exp_i].loc[con_i]['prob']), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "fig.update_layout(coloraxis1=dict(colorscale='deep_R', colorbar = dict(tickformat = '1.0e', title = 'prior<br>probability', len=0.2)))#, cmin = np.log(prob_grid.replace(0,np.nan).min().min()), cmax= np.log(prob_grid.max().max())))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 900, width = 1200, margin={'t':30,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.3], tickvals = [0,1,2,3], gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power <sub></sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power <sub></sub>\"}, xshift=-30, y=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a4533-2b62-4b2c-ae82-508bbbc47270",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/priorplot_4param_permissive.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741ac5e-b883-43e3-9e3c-342fa85d5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 7, shared_xaxes = True, shared_yaxes = True, horizontal_spacing = 0.02, vertical_spacing = 0.08, subplot_titles = ['<i>m</i>=' + str(round(x / intercept_list[1], 1)) for x in intercept_list[1:]], x_title = 'expansion power <sub></sub>', y_title = 'contraction power <sub></sub>')\n",
    "\n",
    "combined_mvg = scipy.stats.multivariate_normal([exp_fit[0], np.log10(mean_exp[9]), con_fit[0], np.log10(mean_con[9])], combined_pcov * 1000)\n",
    "prob_grid = pd.DataFrame([(round(exp_p,2), round(con_p,2), exp_i,con_i) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in list(range(8)) for con_i in list(range(8))], columns = ['exp_p', 'con_p', 'exp_i', 'con_i'])\n",
    "prob_grid['prob'] = [combined_mvg.pdf([exp_p, np.log10(exp_i), con_p, np.log10(con_i)]) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in intercept_list for con_i in intercept_list]\n",
    "prob_grid.set_index( ['exp_i', 'con_i', 'exp_p', 'con_p'], inplace=True)\n",
    "prob_grid /= prob_grid.sum()\n",
    "\n",
    "row_count=1; col_count = 0\n",
    "for exp_i in range(1,8):\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = prob_grid.loc[exp_i].loc[exp_i-1].index.get_level_values(0), y = prob_grid.loc[exp_i].loc[exp_i-1].index.get_level_values(1), z=(prob_grid.loc[exp_i].loc[exp_i-1]['prob']), coloraxis='coloraxis1'), row = row_count, col = col_count)\n",
    "\n",
    "combined_mvg = scipy.stats.multivariate_normal([exp_fit[0], np.log10(mean_exp[9]), con_fit[0], np.log10(mean_con[9])], combined_pcov * 100)\n",
    "prob_grid = pd.DataFrame([(round(exp_p,2), round(con_p,2), exp_i,con_i) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in list(range(8)) for con_i in list(range(8))], columns = ['exp_p', 'con_p', 'exp_i', 'con_i'])\n",
    "prob_grid['prob'] = [combined_mvg.pdf([exp_p, np.log10(exp_i), con_p, np.log10(con_i)]) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in intercept_list for con_i in intercept_list]\n",
    "prob_grid.set_index( ['exp_i', 'con_i', 'exp_p', 'con_p'], inplace=True)\n",
    "prob_grid /= prob_grid.sum()\n",
    "\n",
    "row_count=2; col_count = 0\n",
    "for exp_i in range(1,8):\n",
    "    col_count+=1\n",
    "    fig.add_trace(go.Heatmap(x = prob_grid.loc[exp_i].loc[exp_i-1].index.get_level_values(0), y = prob_grid.loc[exp_i].loc[exp_i-1].index.get_level_values(1), z=(prob_grid.loc[exp_i].loc[exp_i-1]['prob']), coloraxis='coloraxis2'), row = row_count, col = col_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee34987-9b8f-497d-9d65-510bee597788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S6c\n",
    "fig.update_layout(coloraxis1=dict(colorscale='deep_R', colorbar = dict(tickformat = '1.0e', title = 'prior<br>probability', len=0.7, x = 1, y=.85)))\n",
    "fig.update_layout(coloraxis2=dict(colorscale='deep_R', colorbar = dict(tickformat = '1.0e', len=0.45, x = 1, y=0.25)))\n",
    "fig.update_layout(font=dict(family = 'Arial', size = 16), height = 310, width = 1000, margin={'t':50,'l':60,'b':55,'r':10})\n",
    "fig.update_yaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)')\n",
    "fig.update_xaxes(range = [0,4.2], dtick = 1, gridcolor = 'rgba(0,0,0,0.2)', scaleanchor=\"y\", scaleratio=1)\n",
    "\n",
    "fig.update_annotations(selector={\"text\":\"'expansion power <sub></sub>'\"}, yshift=-30, x=0.5)\n",
    "fig.update_annotations(selector={\"text\":\"contraction power <sub></sub>\"}, xshift=-30, y=0.5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c9a46-b449-456c-ba4a-fac8b1e5cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('plots/priorplot_3mult_permissive_restrictive.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95f057-1b85-48ac-b8a9-ba93f55599d4",
   "metadata": {},
   "source": [
    "## Log curve fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900b6e8-9a5a-4b52-957e-d7f8f785f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_log(x, m, c):\n",
    "    return (10**c)*(np.log(x-7)/np.log(2))**m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c91a7-8c82-493f-848a-ffb8d3251574",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_exp_fit, log_exp_pcov = curve_fit(func_log, decode_exp_rate['A'].dropna().index, decode_exp_rate['A'].dropna(), sigma = exp_std)\n",
    "log_con_fit, log_con_pcov = curve_fit(func_log, decode_con_rate['A'].dropna().index, decode_con_rate['A'].dropna(), sigma = con_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56689d-7360-4c71-9d06-d6a232bbe3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_combined_mvg = scipy.stats.multivariate_normal([log_exp_fit[0], log_exp_fit[1], log_con_fit[0], log_con_fit[1]], combined_pcov*100) # use linear fit pcov\n",
    "prob_grid = pd.DataFrame([(round(exp_p,2), round(con_p,2), exp_i,con_i) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in list(range(8)) for con_i in list(range(8))], columns = ['exp_p', 'con_p', 'exp_i', 'con_i'])\n",
    "prob_grid['prob'] = [log_combined_mvg.pdf([exp_p, np.log10(exp_i), con_p, np.log10(con_i)]) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in intercept_list for con_i in intercept_list]\n",
    "prob_grid.set_index( ['exp_i', 'con_i', 'exp_p', 'con_p'], inplace=True)\n",
    "prob_grid /= prob_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d946c-fa76-4768-b448-28a47b01438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_grid.to_pickle('simulations/grid_4param_v2/prior_log_restrictive.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5b29d-49c4-4f4a-a0b2-154a8709aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_combined_mvg = scipy.stats.multivariate_normal([log_exp_fit[0], log_exp_fit[1], log_con_fit[0], log_con_fit[1]], combined_pcov*1000) # use linear fit pcov\n",
    "#log_combined_mvg = scipy.stats.multivariate_normal([log_exp_fit[0], log_exp_fit[1], log_con_fit[0], log_con_fit[1]], combined_pcov*580) # use linear fit pcov\n",
    "\n",
    "prob_grid = pd.DataFrame([(round(exp_p,2), round(con_p,2), exp_i,con_i) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in list(range(8)) for con_i in list(range(8))], columns = ['exp_p', 'con_p', 'exp_i', 'con_i'])\n",
    "prob_grid['prob'] = [log_combined_mvg.pdf([exp_p, np.log10(exp_i), con_p, np.log10(con_i)]) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in intercept_list for con_i in intercept_list]\n",
    "prob_grid.set_index( ['exp_i', 'con_i', 'exp_p', 'con_p'], inplace=True)\n",
    "prob_grid /= prob_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a14bd1-ee84-4f41-b371-a8e2d9abb945",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_grid.to_pickle('simulations/grid_4param_v2/prior_log_relaxed.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60335c2e-3f2e-465c-9890-4ee6d93cf577",
   "metadata": {},
   "source": [
    "### Power law only fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808aa8ff-8fba-44db-818f-917dc18d5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_denovo = range(4,9)\n",
    "range_decode = range(10,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771eb101-2f58-434c-a873-409936b1e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_combined = pd.concat([denovo_exp_rate['A'][list(range_denovo)], decode_exp_rate['A'][list(range_decode)]]).dropna()\n",
    "con_combined = pd.concat([denovo_con_rate['A'][list(range_denovo)], decode_con_rate['A'][list(range_decode)]]).dropna()\n",
    "\n",
    "exp_combined_poisson = pd.concat([denovo_exp_rate_poisson['A'].unstack()[list(range_denovo)], decode_exp_rate_poisson['A'].unstack()[list(range_decode)]], axis=1).dropna(how = 'all', axis=1)\n",
    "con_combined_poisson = pd.concat([denovo_con_rate_poisson['A'].unstack()[list(range_denovo)], decode_con_rate_poisson['A'].unstack()[list(range_decode)]], axis=1).dropna(how = 'all', axis=1)\n",
    "\n",
    "exp_std_combined = exp_combined_poisson.std().dropna()\n",
    "exp_std_combined.loc[22:] *=100\n",
    "exp_std_combined.loc[11:12] *=100\n",
    "\n",
    "con_std_combined = con_combined_poisson.std().dropna()\n",
    "con_std_combined.loc[22:] *=100\n",
    "con_std_combined.loc[11:12] *=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14f1a8-d0c8-40fa-a8a9-b7704d5b51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_lin_lam(x, m, loglam):\n",
    "    return m * (x - loglam) + np.log10(10**-8)\n",
    "def func_lin_lam_e(x, m, loglam):\n",
    "    return m * (x - loglam) + np.log10(4*10**-9)\n",
    "def func_lin_lam_c(x, m, loglam):\n",
    "    return m * (x - loglam) + np.log10(8*10**-9)\n",
    "\n",
    "func_lin_lam_e = func_lin_lam\n",
    "func_lin_lam_c = func_lin_lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6c11d-2d28-4551-aee0-a4d74c518e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fit, exp_pcov = curve_fit(func_lin_lam_e, np.log10(exp_combined.index), np.log10(exp_combined), sigma = np.log10(exp_std_combined))\n",
    "con_fit, con_pcov = curve_fit(func_lin_lam_c, np.log10(con_combined.index), np.log10(con_combined), sigma = np.log10(con_std_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d524aef-05df-4a08-bf44-27c5898fceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pcov = np.array([[exp_pcov[0][0], exp_pcov[0][1], 0, 0], [exp_pcov[1][0], exp_pcov[1][1], 0, 0], [0, 0, con_pcov[0][0], con_pcov[0][1]], [0, 0, con_pcov[1][0], con_pcov[1][1]]])\n",
    "plonly_lambda_list = list(range(5,21))\n",
    "combined_mvg = scipy.stats.multivariate_normal([exp_fit[0], exp_fit[1], con_fit[0], con_fit[1]], combined_pcov * 100)\n",
    "prob_grid = pd.DataFrame([(round(exp_p,2), round(con_p,2), exp_i,con_i) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in plonly_lambda_list for con_i in plonly_lambda_list], columns = ['exp_p', 'con_p', 'exp_i', 'con_i'])\n",
    "prob_grid['prob'] = [combined_mvg.pdf([exp_p, np.log10(exp_i), con_p, np.log10(con_i)]) for exp_p in np.linspace(0,4,41) for con_p in np.linspace(0,4,41) for exp_i in plonly_lambda_list for con_i in plonly_lambda_list]\n",
    "prob_grid = prob_grid.where(prob_grid['exp_p'] < prob_grid['con_p']).dropna(how = 'all').set_index(['exp_i', 'con_i', 'exp_p', 'con_p'])\n",
    "prob_grid /= prob_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539156d0-93c8-4d37-a00b-4986bc04269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_grid.to_pickle('simulations/priors/prior_plonly.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
